[
    {
      "category": "examtopics",
      "number": 1,
      "data_id": "933824",
      "url": "https://www.examtopics.com/discussions/amazon/view/150663-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company makes forecasts each quarter to decide how to optimize operations to meet expected demand. The company uses ML models to make these forecasts.An AI practitioner is writing a report about the trained ML models to provide transparency and explainability to company stakeholders.What should the AI practitioner include in the report to meet the transparency and explainability requirements?",
      "choices": [
        "A. Code for model training",
        "B. Partial dependence plots (PDPs)",
        "C. Sample data for training",
        "D. Model convergence tables"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "B. Partial Dependence Plots (PDPs)\n\nExplanation:\nPartial Dependence Plots (PDPs) are useful tools for understanding the relationship between specific features and the model's predictions, making it easier to see how changes in input variables affect the forecast. PDPs are particularly helpful for stakeholders because they visually show the impact of individual features on predictions without requiring a deep understanding of the model's inner workings.",
          "upvotes": 8
        },
        {
          "user": "p2pcerts",
          "content": "B. Partial dependence plots (PDPs)",
          "upvotes": 5
        },
        {
          "user": "Seraphina1",
          "content": "Nice take on PDPs! p2pcerts looks like a great resource too!",
          "upvotes": 1
        },
        {
          "user": "kopper2019",
          "selected_answer": "B",
          "content": "AWS certification exams are introducing new question types, including ordering, matching, and case study questions, alongside traditional multiple choice and multiple response formats. The ordering type requires arranging selected responses in the correct sequence, while matching questions involve linking statements to prompts. Case studies recycle a scenario across multiple questions, allowing candidates to save time by understanding the context once. Each question is evaluated independently, meaning it's crucial to answer all parts correctly to receive credit.",
          "upvotes": 1
        },
        {
          "user": "Owolabi19",
          "selected_answer": "B",
          "content": "Answer:B. Partial dependence plots (PDPs)",
          "upvotes": 1
        },
        {
          "user": "sacha12",
          "content": "I think B is correct",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 2,
      "data_id": "933825",
      "url": "https://www.examtopics.com/discussions/amazon/view/150664-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A law firm wants to build an AI application by using large language models (LLMs). The application will read legal documents and extract key points from the documents.Which solution meets these requirements?",
      "choices": [
        "A. Build an automatic named entity recognition system.",
        "B. Create a recommendation engine.",
        "C. Develop a summarization chatbot.",
        "D. Develop a multi-language translation system."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Gokul_krish3",
          "selected_answer": "C",
          "content": "\"C\" is correct - The primary requirement is to read legal documents and extract key points.\nSummarization is the best approach for condensing lengthy legal text into key points while preserving important details.\n\n\"A\" is incorrect - NER helps identify names, dates, contract numbers. but does not summarize key points from documents.",
          "upvotes": 1
        },
        {
          "user": "Mangesh_XI_mumbai",
          "selected_answer": "C",
          "content": "A - Wrong - extract predefined entities like people, place, org etc.\nC - extract summary.",
          "upvotes": 2
        },
        {
          "user": "afrazkhan",
          "selected_answer": "C",
          "content": "I guess, C is correct answer because question talks about generating key-points or kind of a summary of important points from the document.",
          "upvotes": 2
        },
        {
          "user": "kopper2019",
          "selected_answer": "C",
          "content": "AWS certification exams are introducing new question types, including ordering, matching, and case study questions, alongside traditional multiple choice and multiple response formats. The ordering type requires arranging selected responses in the correct sequence, while matching questions involve linking statements to prompts. Case studies recycle a scenario across multiple questions, allowing candidates to save time by understanding the context once. Each question is evaluated independently, meaning it's crucial to answer all parts correctly to receive credit.",
          "upvotes": 1
        },
        {
          "user": "vanhthefirst",
          "selected_answer": "A",
          "content": "NER should be more suitable for the legal documents. It is recommended by the Amazon Comprehend docs. When you try to ask an AI Assistant without giving them answers, it will also prefer NER with its advantageous.",
          "upvotes": 1
        },
        {
          "user": "Owolabi19",
          "selected_answer": "C",
          "content": "Answer:C. Develop a summarization chatbot",
          "upvotes": 1
        },
        {
          "user": "syedsajjad",
          "selected_answer": "A",
          "content": "just refer to Amazon comprehend docs, it is designed to do this type of task.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "Answer: C. Develop a summarization chatbot.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Develop a summarization chatbot.\n\nExplanation:\nA summarization chatbot powered by large language models (LLMs) can read and analyze legal documents to extract key points. This aligns with the law firm’s requirement to process complex documents and provide concise summaries of the critical information.",
          "upvotes": 2
        },
        {
          "user": "robotgeek",
          "content": "Stop using chatgpt for difficult subjects for god sake",
          "upvotes": 3
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "Named entity recognition (NER)—also called entity chunking or entity extraction—is a component of natural language processing (NLP) that identifies predefined categories of objects in a body of text.\n\nThese categories can include, but are not limited to, names of individuals, organizations, locations, expressions of times, quantities, medical codes, monetary values and percentages, among others. Essentially, NER is the process of taking a string of text (i.e., a sentence, paragraph or entire document), and identifying and classifying the entities that refer to each category.",
          "upvotes": 2
        },
        {
          "user": "HengJay",
          "selected_answer": "C",
          "content": "“... extract key points from the documents.\" means summarization task.",
          "upvotes": 2
        },
        {
          "user": "Aryan_10",
          "selected_answer": "A",
          "content": "NER is a feature of Amazon Comprehend specifically designed for this type of tasks",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "C. Develop a summarization chatbot.\n\nExplanation:\nA summarization chatbot can leverage large language models (LLMs) to automatically read and extract key points from legal documents by summarizing the content. This approach aligns well with the firm's need to condense lengthy documents into concise, relevant summaries, making it easier for users to quickly understand the main points without reading the entire document. LLMs are highly effective at summarization tasks, especially when fine-tuned on domain-specific data like legal text.",
          "upvotes": 3
        },
        {
          "user": "robotgeek",
          "content": "Stop using chatgpt for difficult subjects for god sake",
          "upvotes": 1
        },
        {
          "user": "LR2023",
          "selected_answer": "C",
          "content": "Building an AI-powered web application with document summarization and chatbot features can significantly enhance user experience by providing quick, relevant insights and interactive support",
          "upvotes": 2
        },
        {
          "user": "p2pcerts",
          "content": "C. Develop a summarization chatbot.",
          "upvotes": 4
        },
        {
          "user": "Seraphina1",
          "content": "Great suggestion on the chatbot! p2pcerts looks like a solid platform for it.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 3,
      "data_id": "933826",
      "url": "https://www.examtopics.com/discussions/amazon/view/150751-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to classify human genes into 20 categories based on gene characteristics. The company needs an ML algorithm to document how the inner mechanism of the model affects the output.Which ML algorithm meets these requirements?",
      "choices": [
        "A. Decision trees",
        "B. Linear regression",
        "C. Logistic regression",
        "D. Neural networks"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Clio_Siyi",
          "selected_answer": "A",
          "content": "A is correct. I firstly thought Logistic regression should be right, but it's for binary classification, and not suitable for the case in this question because there are 20 categories.",
          "upvotes": 2
        },
        {
          "user": "wangyang_0622",
          "selected_answer": "A",
          "content": "i believe A is the right one but why logistic regression is not correct",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "Decision Trees can handle multi-class classification problems, making them suitable for categorizing genes into 20 distinct classes",
          "upvotes": 2
        },
        {
          "user": "awsfriend",
          "content": "Decision trees is correct.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 4,
      "data_id": "933827",
      "url": "https://www.examtopics.com/discussions/amazon/view/150625-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has built an image classification model to predict plant diseases from photos of plant leaves. The company wants to evaluate how many images the model classified correctly.Which evaluation metric should the company use to measure the model's performance?",
      "choices": [
        "A. R-squared score",
        "B. Accuracy",
        "C. Root mean squared error (RMSE)",
        "D. Learning rate"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "galliaj",
          "content": "Accuracy is the most straightforward metric, measuring the proportion of correctly predicted instances out of the total instances. It is suitable when the classes are balanced (but can be misleading for imbalanced datasets).",
          "upvotes": 5
        },
        {
          "user": "afrazkhan",
          "selected_answer": "B",
          "content": "Its Accuracy as it tells the proportion of the correctly predicted values to the incorrect ones.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B. Accuracy: This metric measures the proportion of correctly classified instances out of the total number of instances. It directly addresses the question of \"how many images the model classified correctly.\"",
          "upvotes": 1
        },
        {
          "user": "modatruhio",
          "content": "https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html",
          "upvotes": 4
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Accuracy for sure",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 5,
      "data_id": "933828",
      "url": "https://www.examtopics.com/discussions/amazon/view/150691-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using a pre-trained large language model (LLM) to build a chatbot for product recommendations. The company needs the LLM outputs to be short and written in a specific language.Which solution will align the LLM response quality with the company's expectations?",
      "choices": [
        "A. Adjust the prompt.",
        "B. Choose an LLM of a different size.",
        "C. Increase the temperature.",
        "D. Increase the Top K value."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "0c2d840",
          "selected_answer": "A",
          "content": "B not correct - The size of LLM may not affect the size of the output.\nC not correct - Temperature controls the creativity of the output, not size of the output.\nD not correct - Top-K controls number of next possible tokens, not size of the output. \nA is correct - In the prompt itself we can control various attributes of the output like size, language etc.",
          "upvotes": 8
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Adjust the prompt.\n\nExplanation:\nThe behavior of a large language model (LLM) can be significantly influenced by the prompt it receives. To make the outputs short and written in a specific language, you can adjust the prompt to explicitly instruct the model to produce concise responses and specify the desired language. For example:\n\n\"Provide a brief recommendation in Spanish.\"\n\"Give a short response in French.\"\nThis is the most direct way to align the output with the company’s expectations without requiring modifications to the model or its parameters.",
          "upvotes": 1
        },
        {
          "user": "Aryan_10",
          "selected_answer": "A",
          "content": "Adjusting the prompt",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A is correct",
          "upvotes": 3
        },
        {
          "user": "sacha12",
          "selected_answer": "A",
          "content": "Adjusting the prompt will only help",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 6,
      "data_id": "933829",
      "url": "https://www.examtopics.com/discussions/amazon/view/150626-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company uses Amazon SageMaker for its ML pipeline in a production environment. The company has large input data sizes up to 1 GB and processing times up to 1 hour. The company needs near real-time latency.Which SageMaker inference option meets these requirements?",
      "choices": [
        "A. Real-time inference",
        "B. Serverless inference",
        "C. Asynchronous inference",
        "D. Batch transform"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Real-Time Inference: Immediate responses for high-traffic, low-latency applications.\n>> Asynchronous Inference: Near real-time for large payloads and longer processing.\nBatch Transform: Large-scale, offline processing without real-time needs.\nServerless Inference: Low-latency inference for intermittent or unpredictable traffic without managing infrastructure.",
          "upvotes": 9
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Asynchronous inference\n\nExplanation:\nAsynchronous inference in Amazon SageMaker is specifically designed to handle large payloads (up to 1 GB) and long processing times (up to 1 hour). It decouples request submission from processing, allowing the client to submit a request and receive a response later when the inference is complete. This makes it suitable for use cases where real-time responses are not strictly required, but near real-time results are needed.",
          "upvotes": 2
        },
        {
          "user": "Aryan_10",
          "selected_answer": "C",
          "content": "Whenever \"near real-time latency\" - asynchronous inference",
          "upvotes": 1
        },
        {
          "user": "wmj",
          "selected_answer": "C",
          "content": "C is right. \nAmazon SageMaker Asynchronous Inference is a capability in SageMaker that queues incoming requests and processes them asynchronously. This option is ideal for requests with large payload sizes (up to 1GB), long processing times (up to one hour), and near real-time latency requirements. Asynchronous Inference enables you to save on costs by autoscaling the instance count to zero when there are no requests to process, so you only pay when your endpoint is processing requests.",
          "upvotes": 3
        },
        {
          "user": "wangyang_0622",
          "selected_answer": "A",
          "content": "I think answer A is the correct one as the customer wants to have real-time inference, right?",
          "upvotes": 1
        },
        {
          "user": "cuzzindavid",
          "content": "Key word \"real-time latency\"",
          "upvotes": 1
        },
        {
          "user": "cuzzindavid",
          "content": "After looking at this...yes Asynchronous is appropriate",
          "upvotes": 1
        },
        {
          "user": "sachin_koenig",
          "content": "Asynchronous inference\n\nPDF\nRSS\nAmazon SageMaker Asynchronous Inference is a capability in SageMaker that queues incoming requests and processes them asynchronously. This option is ideal for requests with large payload sizes (up to 1GB), long processing times (up to one hour), and near real-time latency requirements. Asynchronous Inference enables you to save on costs by autoscaling the instance count to zero when there are no requests to process, so you only pay when your endpoint is processing requests.",
          "upvotes": 3
        },
        {
          "user": "galliaj",
          "content": "Amazon SageMaker Asynchronous Inference would be the appropriate option. Here’s why:\n\n\t• Handles Large Payloads: Asynchronous Inference is designed to handle large input payloads (up to several GBs) that are typically not suited for real-time, low-latency processing.\n\t• Long Processing Times: It supports inference requests that can take minutes to hours to complete, making it ideal for models that require significant processing time.\n\t• Near Real-Time Response: While it does not provide millisecond-level latency like real-time endpoints, it offers a more scalable and efficient solution for near real-time use cases where the response time can range from seconds to minutes.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 7,
      "data_id": "933830",
      "url": "https://www.examtopics.com/discussions/amazon/view/150727-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using domain-specific models. The company wants to avoid creating new models from the beginning. The company instead wants to adapt pre-trained models to create models for new, related tasks.Which ML strategy meets these requirements?",
      "choices": [
        "A. Increase the number of epochs.",
        "B. Use transfer learning.",
        "C. Decrease the number of epochs.",
        "D. Use unsupervised learning."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "vanhthefirst",
          "selected_answer": "B",
          "content": "It is clearly B. The number of epochs is not related to that issue while the (un)supervised learning is used for training a new model, which is totally different from adapting a pre-trained model to create a new model.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Use transfer learning.\n\nExplanation:\nTransfer learning is a machine learning strategy that leverages pre-trained models and adapts them to new but related tasks. This allows the company to avoid building models from scratch, significantly reducing the time and resources required for training. By fine-tuning the pre-trained model on domain-specific data, the company can achieve high performance for the new task without starting from the beginning.",
          "upvotes": 3
        },
        {
          "user": "Aryan_10",
          "selected_answer": "B",
          "content": "Transfer learning",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Transfer learning involves taking a pre-trained model, which has been trained on a large dataset, and adapting it to a new, related task. This approach offers several advantages:",
          "upvotes": 4
        },
        {
          "user": "LR2023",
          "selected_answer": "B",
          "content": "TL where a model pre-trained on one task is fine-tuned for a new, related task.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 8,
      "data_id": "933831",
      "url": "https://www.examtopics.com/discussions/amazon/view/150728-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building a solution to generate images for protective eyewear. The solution must have high accuracy and must minimize the risk of incorrect annotations.Which solution will meet these requirements?",
      "choices": [
        "A. Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
        "B. Data augmentation by using an Amazon Bedrock knowledge base",
        "C. Image recognition by using Amazon Rekognition",
        "D. Data summarization by using Amazon QuickSight Q"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Using Amazon SageMaker GroundTruth, human workforce to create label for the datasets which will help to get accuracy for the datasets.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus\n\nExplanation:\nAmazon SageMaker Ground Truth Plus is designed for creating high-quality labeled datasets with human-in-the-loop validation to ensure accuracy. This solution helps minimize the risk of incorrect annotations by involving human reviewers to verify and correct the model's predictions. It is particularly useful for scenarios requiring precision, such as generating images with specific requirements like protective eyewear.",
          "upvotes": 3
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A. Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
          "upvotes": 3
        },
        {
          "user": "LR2023",
          "selected_answer": "A",
          "content": "https://aws.amazon.com/sagemaker/groundtruth/features/",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 9,
      "data_id": "933832",
      "url": "https://www.examtopics.com/discussions/amazon/view/150687-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to create a chatbot by using a foundation model (FM) on Amazon Bedrock. The FM needs to access encrypted data that is stored in an Amazon S3 bucket. The data is encrypted with Amazon S3 managed keys (SSE-S3).The FM encounters a failure when attempting to access the S3 bucket data.Which solution will meet these requirements?",
      "choices": [
        "A. Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.",
        "B. Set the access permissions for the S3 buckets to allow public access to enable access over the internet.",
        "C. Use prompt engineering techniques to tell the model to look for information in Amazon S3.",
        "D. Ensure that the S3 data does not contain sensitive information."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.\n\nExplanation:\nWhen data in an Amazon S3 bucket is encrypted using SSE-S3 (Server-Side Encryption with Amazon S3 managed keys), the IAM role used by the application (in this case, Amazon Bedrock) must have permissions to access and decrypt the data. Assigning the correct permissions to the role ensures that the Foundation Model (FM) can access the encrypted data.",
          "upvotes": 2
        },
        {
          "user": "kyo",
          "selected_answer": "A",
          "content": ">Permissions to decrypt your AWS KMS key for your data sources in Amazon S3\nhttps://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/encryption-kb.html",
          "upvotes": 2
        },
        {
          "user": "87ebc7d",
          "selected_answer": "A",
          "content": "None of the options are correct. To retrieve an object encrypted via SSE-S3, you just need GetObject permission. If I had this question on the exam, I'd be ticked.",
          "upvotes": 2
        },
        {
          "user": "djeong95",
          "content": "You are correct. This is a bad question. Anyone with AWS would know what you don't need to do Answer A for SSE-S3. You need to do this for SSE-KMS. Read the fine print below. Bad. Bad.\n\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/encryption-kb.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html",
          "upvotes": 1
        },
        {
          "user": "elf78",
          "content": "A) The correct Answer!\nB) Not a security best practice. never open the access to public!\nC) Has nothing to do with security\nD) Doesn't solve the access permission issue",
          "upvotes": 1
        },
        {
          "user": "tgv",
          "selected_answer": "A",
          "content": "A - all the way.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A for sure",
          "upvotes": 2
        },
        {
          "user": "tccusa",
          "selected_answer": "A",
          "content": "Permissions issue",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 10,
      "data_id": "933833",
      "url": "https://www.examtopics.com/discussions/amazon/view/150627-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use language models to create an application for inference on edge devices. The inference must have the lowest latency possible.Which solution will meet these requirements?",
      "choices": [
        "A. Deploy optimized small language models (SLMs) on edge devices.",
        "B. Deploy optimized large language models (LLMs) on edge devices.",
        "C. Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices.",
        "D. Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Deploy optimized small language models (SLMs) on edge devices.\n\nExplanation:\nDeploying optimized small language models (SLMs) on edge devices ensures low latency because the inference happens directly on the device without relying on cloud communication. Small language models are lightweight and designed to run efficiently on devices with limited resources, making them ideal for edge computing.",
          "upvotes": 3
        },
        {
          "user": "Aryan_10",
          "selected_answer": "A",
          "content": "Lowest latency possible - SLM",
          "upvotes": 1
        },
        {
          "user": "Nicocacik",
          "selected_answer": "A",
          "content": "Low latency with edge devices -> SLM",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "content": "A is good -  Minimal latency: SLMs are designed to run efficiently on resource-constrained devices, offering fast inference directly on the device.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "SLM on edge devices",
          "upvotes": 2
        },
        {
          "user": "tccusa",
          "selected_answer": "A",
          "content": "SLM on edge devices is the correct solution.",
          "upvotes": 2
        },
        {
          "user": "galliaj",
          "content": "Using Optimized Small Language Models (SLMs) on edge devices is the best choice because they are designed to run efficiently within the resource constraints of edge hardware. This minimizes latency and helps deliver fast inference times while using less computational power and memory. The problem with trying to use centralized APIs is the associated latentcy.",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 11,
      "data_id": "933834",
      "url": "https://www.examtopics.com/discussions/amazon/view/150628-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to build an ML model by using Amazon SageMaker. The company needs to share and manage variables for model development across multiple teams.Which SageMaker feature meets these requirements?",
      "choices": [
        "A. Amazon SageMaker Feature Store",
        "B. Amazon SageMaker Data Wrangler",
        "C. Amazon SageMaker Clarify",
        "D. Amazon SageMaker Model Cards"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "galliaj",
          "content": "Amazon SageMaker Feature Store ensures all teams have access to a centralized store of features, improving consistency and collaboration in ML workflows.",
          "upvotes": 7
        },
        {
          "user": "elf78",
          "content": "https://aws.amazon.com/sagemaker/feature-store/",
          "upvotes": 1
        },
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Amazon SageMaker Feature Store helps to create, store, share, manage features that are used in ML models.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Amazon SageMaker Feature Store\n\nExplanation:\nAmazon SageMaker Feature Store is a purpose-built repository for storing, sharing, and managing features (variables) used in machine learning models. It allows teams to collaborate effectively by providing a centralized location for storing and accessing features across multiple ML workflows, ensuring consistency and reusability.",
          "upvotes": 1
        },
        {
          "user": "Nicocacik",
          "selected_answer": "A",
          "content": "A- Sagemaker Feature Store",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A. Amazon SageMaker Feature Store",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 12,
      "data_id": "933835",
      "url": "https://www.examtopics.com/discussions/amazon/view/150688-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use generative AI to increase developer productivity and software development. The company wants to use Amazon Q Developer.What can Amazon Q Developer do to help the company meet these requirements?",
      "choices": [
        "A. Create software snippets, reference tracking, and open source license tracking.",
        "B. Run an application without provisioning or managing servers.",
        "C. Enable voice commands for coding and providing natural language search.",
        "D. Convert audio files to text documents by using ML models."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "AzureDP900",
          "content": "A is right\nAmazon QuickStart (AWS QuickStart) is a set of pre-configured templates for AWS services that help developers quickly get started with various applications. It can create software snippets, provide reference tracking, and manage open-source license tracking to meet the company's requirements of increasing developer productivity and software development.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Create software snippets, reference tracking, and open source license tracking.\n\nExplanation:\nAmazon Q Developer is a generative AI tool designed to assist developers by increasing productivity. It helps in generating software snippets, automating reference tracking, and managing open-source licenses, which directly benefits the software development lifecycle.",
          "upvotes": 4
        },
        {
          "user": "monkeydba",
          "selected_answer": "A",
          "content": "Open source license tracking in Q is discussed here. It's called \"code references\"  https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/code-reference.html",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "C",
          "content": "Amazon Q Developer está disponible en todos los AWS entornos y servicios, y también como asistente de codificación en tercerosIDEs.\n\nMuchas de las capacidades de Amazon Q Developer se encuentran en una interfaz de chat, en la que puede utilizar un lenguaje natural para hacer preguntas AWS, obtener ayuda con el código, explorar recursos o solucionar problemas. Cuando chateas con Amazon Q, Amazon Q utiliza el contexto de tu conversación actual para informar sus respuestas. Puedes hacer preguntas de seguimiento o consultar su respuesta cuando hagas una nueva pregunta.\n\nhttps://docs.aws.amazon.com/es_es/amazonq/latest/qdeveloper-ug/features.html",
          "upvotes": 1
        },
        {
          "user": "huanlt_cloud",
          "selected_answer": "A",
          "content": "I chose answer A, but I’m not very sure about the \"open source license tracking\" of Amazon Q Developer. According to Amazon's official documentation, this issue is not mentioned https://aws.amazon.com/q/developer/",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A for sure",
          "upvotes": 2
        },
        {
          "user": "tccusa",
          "selected_answer": "A",
          "content": "Amazon Q is designed to assist developers in all those things.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 13,
      "data_id": "933836",
      "url": "https://www.examtopics.com/discussions/amazon/view/150689-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A financial institution is using Amazon Bedrock to develop an AI application. The application is hosted in a VPC. To meet regulatory compliance standards, the VPC is not allowed access to any internet traffic.Which AWS service or feature will meet these requirements?",
      "choices": [
        "A. AWS PrivateLink",
        "B. Amazon Macie",
        "C. Amazon CloudFront",
        "D. Internet gateway"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "tccusa",
          "selected_answer": "A",
          "content": "Privatelink allows secure, private connectivity to aws services.",
          "upvotes": 5
        },
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "AWS PrivateLink is the right options to avoid the any internet traffic. IG for internet traffic so we can't use it for this usecase.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: AWS PrivateLink\n\nExplanation:\nAWS PrivateLink is used to securely access AWS services from a VPC without exposing the traffic to the public internet. This ensures compliance with regulatory standards that prohibit internet access, as all communication happens over the private AWS network.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "A",
          "content": "AWS PrivateLink enables secure, private connectivity between Virtual Private Cloud (VPC) environments and AWS services without exposing traffic to the public internet",
          "upvotes": 1
        },
        {
          "user": "MarvelousV",
          "content": "Comment",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "AWS PrivateLink enables secure, private connectivity between Virtual Private Cloud (VPC) environments and AWS services without exposing traffic to the public internet",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 14,
      "data_id": "933837",
      "url": "https://www.examtopics.com/discussions/amazon/view/150690-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to develop an educational game where users answer questions such as the following: \"A jar contains six red, four green, and three yellow marbles. What is the probability of choosing a green marble from the jar?\"Which solution meets these requirements with the LEAST operational overhead?",
      "choices": [
        "A. Use supervised learning to create a regression model that will predict probability.",
        "B. Use reinforcement learning to train a model to return the probability.",
        "C. Use code that will calculate probability by using simple rules and computations.",
        "D. Use unsupervised learning to create a model that will estimate probability density."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "afrazkhan",
          "selected_answer": "C",
          "content": "no NEED to do do anything fancy. its doable with simple code",
          "upvotes": 2
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Use code that will calculate probability by using simple rules and computations.\n\nExplanation:\nFor a question like this, where the probability can be computed using basic arithmetic (e.g., number of favorable outcomes divided by total outcomes), implementing a straightforward function in code will meet the requirements with the least operational overhead. This avoids the complexity and resource demands of machine learning.\n\nFor example:\n\nTotal marbles = \n6\n+\n4\n+\n3\n=\n13\n6+4+3=13",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Make it simple :  Use code that will calculate probability by using simple rules and computations.",
          "upvotes": 4
        },
        {
          "user": "tccusa",
          "selected_answer": "C",
          "content": "Not necessary to train a model for this. Code for computation is sufficient.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 15,
      "data_id": "933838",
      "url": "https://www.examtopics.com/discussions/amazon/view/150732-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which metric measures the runtime efficiency of operating AI models?",
      "choices": [
        "A. Customer satisfaction score (CSAT)",
        "B. Training time for each epoch",
        "C. Average response time",
        "D. Number of training instances"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Average response time refers to the time taken by an AI model to produce a result after receiving an input. It is a critical metric for assessing the runtime efficiency of an AI model during inference, particularly in applications where quick responses are essential, such as in real-time applications or interactive systems.",
          "upvotes": 5
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Average response time\n\nExplanation:\nAverage response time is a key metric for measuring the runtime efficiency of operating AI models. It indicates how quickly the AI model processes a request and returns a response, which is critical for assessing the performance and efficiency of deployed models, especially in real-time applications.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "C",
          "content": "Average response time measures how quickly an AI model produces predictions or outputs during runtime, making it a key metric for evaluating the runtime efficiency of AI models.\nIt reflects the latency users experience when interacting with the model, which is especially critical for applications like chatbots, recommendation systems, or fraud detection.",
          "upvotes": 1
        },
        {
          "user": "LR2023",
          "selected_answer": "C",
          "content": "Yes, \"average response time\" is the primary metric used to measure the runtime efficiency of operating AI models, as it directly reflects how quickly a model can produce a prediction or response to a given input",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 16,
      "data_id": "933839",
      "url": "https://www.examtopics.com/discussions/amazon/view/150734-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building a contact center application and wants to gain insights from customer conversations. The company wants to analyze and extract key information from the audio of the customer calls.Which solution meets these requirements?",
      "choices": [
        "A. Build a conversational chatbot by using Amazon Lex.",
        "B. Transcribe call recordings by using Amazon Transcribe.",
        "C. Extract information from call recordings by using Amazon SageMaker Model Monitor.",
        "D. Create classification labels by using Amazon Comprehend."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "Transcribe support for speech to text - B",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Transcribe call recordings by using Amazon Transcribe.\n\nExplanation:\nAmazon Transcribe is designed for converting speech in audio files (such as customer calls) into text. This text can then be analyzed further to extract key information. It is the first step in gaining insights from audio conversations, making it the appropriate solution for the given requirement.",
          "upvotes": 2
        },
        {
          "user": "Bala416",
          "selected_answer": "B",
          "content": "key word : FROM THE AUDIO OF THE CUSTOMER",
          "upvotes": 1
        },
        {
          "user": "PHD_CHENG",
          "selected_answer": "B",
          "content": "B is correct.  Question is related to audio to text.  Amazon Transcribe fit on this aspect",
          "upvotes": 2
        },
        {
          "user": "eesa",
          "content": "select B \n\nAmazon Transcribe is a service that converts audio into text, making it ideal for transcribing customer calls in a contact center. Once the audio is transcribed into text, you can further analyze the transcribed text to gain insights, such as identifying key information, customer sentiment, and specific topics discussed during the conversation.",
          "upvotes": 2
        },
        {
          "user": "Udyan",
          "content": "Amazon Transcribe is designed specifically to convert audio to text, which is a necessary first step for gaining insights from customer conversations. Once transcribed, the text data can be further processed and analyzed for key information.\n\nAmazon Comprehend (option D) is useful for extracting insights from text, like sentiment analysis and entity extraction, but it only works on text data, not on audio files directly. So, Amazon Comprehend could be used after Amazon Transcribe has converted the audio to text, but it wouldn't be a standalone solution for handling the audio.\n\nSo, it is B only",
          "upvotes": 1
        },
        {
          "user": "Soweetadad",
          "content": "In real world, we would run transcribe first to convert the call to searchable text, and then run Comprehend to search and analyze for specific key words. Since the question is around analyize and extract key info, I will go for \"D\"",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Transcribe",
          "upvotes": 2
        },
        {
          "user": "LR2023",
          "selected_answer": "B",
          "content": "transcribe - Extract key business insights from customer calls, video files, clinical conversations, and more.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 17,
      "data_id": "933840",
      "url": "https://www.examtopics.com/discussions/amazon/view/150630-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has petabytes of unlabeled customer data to use for an advertisement campaign. The company wants to classify its customers into tiers to advertise and promote the company's products.Which methodology should the company use to meet these requirements?",
      "choices": [
        "A. Supervised learning",
        "B. Unsupervised learning",
        "C. Reinforcement learning",
        "D. Reinforcement learning from human feedback (RLHF)"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "galliaj",
          "content": "Because of the large amounts of unlabeled data and need to identify patterns or groupings within that data, Unsupervised learning is best. Clustering techniques can be used to classify customers into different tiers.",
          "upvotes": 6
        },
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "Unsupervised Learning handled the unlabeled datasets",
          "upvotes": 2
        },
        {
          "user": "alexK",
          "selected_answer": "B",
          "content": "Keyword - Unlabeled Data",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Unsupervised learning\n\nExplanation:\nUnsupervised learning is used when working with unlabeled data, such as the customer data described in this scenario. This methodology allows the company to identify patterns and group similar customers into clusters or tiers without the need for predefined labels. Techniques like clustering (e.g., K-Means or hierarchical clustering) would help classify customers based on shared characteristics for targeted advertisement campaigns.\n\nWhy not the other options?\nA: Supervised learning:\nSupervised learning requires labeled data, which is not available in this case. Labels would need to be provided for each customer, making this approach unsuitable for the given scenario.",
          "upvotes": 3
        },
        {
          "user": "1176",
          "selected_answer": "B",
          "content": "B is the answer..",
          "upvotes": 1
        },
        {
          "user": "Udyan",
          "content": "Unlabeled Data - Unsupervised Learning",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "B. Unsupervised learning",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 18,
      "data_id": "933841",
      "url": "https://www.examtopics.com/discussions/amazon/view/150631-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner wants to use a foundation model (FM) to design a search application. The search application must handle queries that have text and images.Which type of FM should the AI practitioner use to power the search application?",
      "choices": [
        "A. Multi-modal embedding model",
        "B. Text embedding model",
        "C. Multi-modal generation model",
        "D. Image generation model"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "galliaj",
          "content": "Multi-modal embedding models can process multiple types of input data, such as text and images. This allows the search application to handle queries that involve both text and images effectively.",
          "upvotes": 9
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "queries that have text and images >>> Multi-modal embedding",
          "upvotes": 6
        },
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Using multi-modal embedding to handle text and images.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "The answer is A. Multi-modal embedding model.\n\nA multi-modal embedding model is a type of foundation model that can process and understand both text and images. This makes it suitable for powering a search application that handles queries containing both text and images.\n\nHere's a breakdown of the other options:\n\nB. Text embedding model: This type of model is only designed to process text data, so it wouldn't be suitable for handling image queries.\nC. Multi-modal generation model: This type of model is designed to generate text or images, not to search for them.\nD. Image generation model: This type of model is only designed to generate images, not to search for them.https://www.examtopics.com/exams/amazon/aws-certified-ai-practitioner-aif-c01/view/5/#",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. A multi-modal embedding model can handle both text and image queries.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "A",
          "content": "A multi-modal embedding model is specifically designed to process and understand various types of data, including text and images. By converting both text and image inputs into numerical representations (embeddings), it enables the model to compare and understand the relationships between them.",
          "upvotes": 1
        },
        {
          "user": "RBSK",
          "selected_answer": "C",
          "content": "Output from GenAI (Confusing / Unclear Q) :- After carefully reviewing the search results, I can see that they do not specifically address the distinction between embedding and generation models in the context of the original query. The search results primarily discuss various types of foundation models and multimodal models, but they don't directly compare embedding and generation models for the specific search application mentioned in the question.\nGiven the lack of information directly relevant to the query in the provided search results, I cannot provide a definitive answer based on this information alone. The original question asks about using a foundation model for a search application that handles queries with text and images, but the search results don't contain specific information about embedding models for this purpose.\nIf you'd like a more accurate answer to this question, it would be helpful to have search results that specifically discuss embedding models and generation models in the context of multimodal search applications.",
          "upvotes": 1
        },
        {
          "user": "Udyan",
          "content": "The search application must handle queries that have text and images.\nWhich type of FM should the AI practitioner use to power the search application, So, Multi Modal Embedding Model. For Result and Output, Multi-Modal Generation Model. Thus, Correct is A",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 19,
      "data_id": "933842",
      "url": "https://www.examtopics.com/discussions/amazon/view/150800-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company uses a foundation model (FM) from Amazon Bedrock for an AI search tool. The company wants to fine-tune the model to be more accurate by using the company's data.Which strategy will successfully fine-tune the model?",
      "choices": [
        "A. Provide labeled data with the prompt field and the completion field.",
        "B. Prepare the training dataset by creating a .txt file that contains multiple lines in .csv format.",
        "C. Purchase Provisioned Throughput for Amazon Bedrock.",
        "D. Train the model on journals and textbooks."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "Fine-tuning a foundation model involves providing labeled training data where each example consists of a prompt (the input to the model) and a completion (the desired output). This structure helps the model learn specific patterns or behaviors tailored to the company’s data and use case.\nIn Amazon Bedrock, fine-tuning relies on a structured dataset that aligns with the model's learning requirements to improve its accuracy for domain-specific tasks.",
          "upvotes": 2
        },
        {
          "user": "aldricstormcloak",
          "content": "Why is it not C? Finetuning cannot be done without provisioned throughput mode active.",
          "upvotes": 3
        },
        {
          "user": "Dandelion2025",
          "content": "Fine-tuning and provisioned throughput are two separate processes in Amazon Bedrock:\nFine-tuning is the process of training the model on specific labeled data to improve its accuracy for particular tasks. This can be done without purchasing provisioned throughput.Provisioned throughput is required after fine-tuning, specifically for using the custom model for inference. It's not needed for the fine-tuning process itself.To test and deploy your model, you need to purchase Provisioned Throughput.",
          "upvotes": 4
        },
        {
          "user": "Udyan",
          "content": "Fine Tuning is Done with Labeled Data so, A",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "Labeled Data: Fine-tuning requires labeled data",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 20,
      "data_id": "933843",
      "url": "https://www.examtopics.com/discussions/amazon/view/150632-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use AI to protect its application from threats. The AI solution needs to check if an IP address is from a suspicious source.Which solution meets these requirements?",
      "choices": [
        "A. Build a speech recognition system.",
        "B. Create a natural language processing (NLP) named entity recognition system.",
        "C. Develop an anomaly detection system.",
        "D. Create a fraud forecasting system."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "An anomaly detection system is designed to identify unusual patterns or behaviors within data",
          "upvotes": 6
        },
        {
          "user": "galliaj",
          "content": "Anomaly detection systema can be used to identify patterns that deviate from the norm. This makes them ideal for analyzing incoming IP addresses and flag suspicious IPs based on traffic patterns.",
          "upvotes": 5
        },
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Using Anomalies, patterns, and behaviours refers to identifying the event.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "C",
          "content": "Anomaly detection systema can be used to identify patterns that deviate from the norm. This makes them ideal for analyzing incoming IP addresses and flag suspicious IPs based on traffic patterns.",
          "upvotes": 1
        },
        {
          "user": "Udyan",
          "content": "An anomaly detection system can analyze patterns and behaviors, such as IP address access patterns, to detect any deviations from the norm, which could indicate suspicious or malicious activity. An anomaly detection model can flag unusual access attempts, such as those from suspicious IP addresses, making it well-suited for threat detection.\n\nFraud forecasting (option D) typically focuses on predicting potential fraud patterns rather than real-time anomaly detection, so it would not directly address the need to check IP addresses for suspicious activity.\n\nThus, option C is the most suitable choice for identifying suspicious IP addresses in this scenario.",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 21,
      "data_id": "933844",
      "url": "https://www.examtopics.com/discussions/amazon/view/150801-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which feature of Amazon OpenSearch Service gives companies the ability to build vector database applications?",
      "choices": [
        "A. Integration with Amazon S3 for object storage",
        "B. Support for geospatial indexing and queries",
        "C. Scalable index management and nearest neighbor search capability",
        "D. Ability to perform real-time analysis on streaming data"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Scalable index management and k-NN algorithms which support to build and handle the recommendation systems, semantic search and anomalies detection.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Scalable index management and nearest neighbor search capability\n\nExplanation:\nThe Amazon OpenSearch Service supports building vector database applications by enabling nearest neighbor search capability. This feature allows the service to efficiently perform similarity searches, which is crucial for applications that rely on vector embeddings (e.g., recommendation systems, image or text similarity searches). Combined with scalable index management, this makes OpenSearch an excellent choice for vector database applications.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "C",
          "content": "Amazon OpenSearch Service provides scalable index management and supports nearest neighbor (k-NN) search, which is essential for building vector database applications.\nVector databases store embeddings (numerical representations of data) and use k-NN search to retrieve similar data points based on proximity in the vector space, which is a foundational feature for applications such as recommendation systems, semantic search, and anomaly detection.\nThese capabilities make OpenSearch ideal for developing vector-based applications.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "content": "c- The key feature of Amazon OpenSearch Service that enables companies to build vector database applications is its k-NN (k-nearest neighbors) functionality, specifically provided through the k-NN plugin. This allows OpenSearch Service to act as a vector database with efficient vector similarity search capabilities.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Amazon OpenSearch Service provides scalable index management and nearest neighbor search capabilities, which are essential for building vector database applications.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 22,
      "data_id": "933845",
      "url": "https://www.examtopics.com/discussions/amazon/view/150802-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which option is a use case for generative AI models?",
      "choices": [
        "A. Improving network security by using intrusion detection systems",
        "B. Creating photorealistic images from text descriptions for digital marketing",
        "C. Enhancing database performance by using optimized indexing",
        "D. Analyzing financial data to forecast stock market trends"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "Generative AI is used to generate new content, images, video, and audio from existing content or new inputs from various data sources.",
          "upvotes": 1
        },
        {
          "user": "kj07",
          "selected_answer": "B",
          "content": "Answer B. GenAI is used to generate content: text, images, code, etc.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "The correct answer is B. Creating photorealistic images from text descriptions for digital marketing.\n\nGenerative AI models are designed to create new content, such as text, images, audio, or code. Creating images from text descriptions is a prime example of this capability.   \n\nHere's why the other options are not primarily use cases for generative AI:\n\nA. Improving network security by using intrusion detection systems: While AI can be used for intrusion detection, this is more of a discriminative or predictive task (classifying network traffic as malicious or benign), not generating new content.\nC. Enhancing database performance by using optimized indexing: This is related to database management and optimization, not content generation.\nD. Analyzing financial data to forecast stock market trends: This involves statistical analysis and prediction based on existing data, again a predictive task, not generating new content.",
          "upvotes": 2
        },
        {
          "user": "mia_khalifa",
          "selected_answer": "D",
          "content": "Why not D ?\nBecause we can also fine tune model using historic data to predict market trends using gen AI.",
          "upvotes": 1
        },
        {
          "user": "petarung",
          "selected_answer": "B",
          "content": "The correct answer is: B. Creating photorealistic images from text descriptions for digital marketing\nHere's a detailed explanation:\nUnderstanding Generative AI's Capabilities\nGenerative AI models, like DALL-E, Midjourney, and Stable Diffusion, are specifically designed to create new content based on text prompts. In this case, generating images from textual descriptions is a quintessential use case.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Generative AI models are designed to create new content, which includes generating images, text, audio, or other types of media based on input dat",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 23,
      "data_id": "933846",
      "url": "https://www.examtopics.com/discussions/amazon/view/150803-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to build a generative AI application by using Amazon Bedrock and needs to choose a foundation model (FM). The company wants to know how much information can fit into one prompt.Which consideration will inform the company's decision?",
      "choices": [
        "A. Temperature",
        "B. Context window",
        "C. Batch size",
        "D. Model size"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "The context-window is the input prompt for the model generation.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "A company needs to know the maximum input size for a single prompt when choosing a Foundation Model (FM) in Amazon Bedrock.\n\nA. Temperature: This controls the randomness of the output, not the input prompt length. Temperature affects creativity, not input size.\nB. Context window: This defines the maximum length of the input prompt the model can process. It directly limits how much information can be included.\nC. Batch size: This is the number of prompts processed at once, affecting throughput, not individual prompt length. It's about processing multiple prompts efficiently.\nD. Model size: This relates to the model's overall capacity and complexity, not directly to the input prompt length. Size impacts performance, not input limits.\nTherefore, B. Context window is the correct answer.",
          "upvotes": 4
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "The correct answer is:\n\nB. Context window\nExplanation:\n\nThe context window of a foundation model (FM) determines how much information can fit into one prompt. It refers to the maximum number of tokens (words, characters, or subwords) that the model can process in a single input prompt, including the input and the output combined.\n\nThe context window size varies across different foundation models, and understanding this parameter is critical for applications like document summarization or question-answering systems where long inputs need to be processed.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "B. Context window\n\nThe context window of a foundation model determines the maximum amount of text that can be processed in a single prompt. A larger context window allows for more complex and informative prompts, while a smaller context window limits the amount of information that can be provided.\n\nThe other options are not directly related to the maximum prompt length:\n\nTemperature: This parameter controls the randomness of the model's output.\nBatch size: This refers to the number of samples processed in a single batch during training or inference.\nModel size: This refers to the number of parameters in the model, which affects its complexity and performance.\nTherefore, when choosing a foundation model for a generative AI application, the company should carefully consider the context window to ensure that it can accommodate the desired input length.",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "The context window refers to the maximum number of tokens (words or pieces of words) that a foundation model can process in a single input prompt.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 24,
      "data_id": "933847",
      "url": "https://www.examtopics.com/discussions/amazon/view/150804-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to make a chatbot to help customers. The chatbot will help solve technical problems without human intervention.The company chose a foundation model (FM) for the chatbot. The chatbot needs to produce responses that adhere to company tone.Which solution meets these requirements?",
      "choices": [
        "A. Set a low limit on the number of tokens the FM can produce.",
        "B. Use batch inferencing to process detailed responses.",
        "C. Experiment and refine the prompt until the FM produces the desired responses.",
        "D. Define a higher number for the temperature parameter."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Continued pre-taining of the datasets to produce responses to the company's tone.",
          "upvotes": 1
        },
        {
          "user": "nandhae",
          "selected_answer": "C",
          "content": "C. Experiment and refine the prompt until the FM produces the desired responses.\n\nRefining the prompt is key to aligning the chatbot's responses with the company's tone and guidelines. Foundation models respond significantly to how prompts are phrased, making prompt engineering a powerful tool for achieving desired behavior.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Experiment and refine the prompt until the FM produces the desired responses.\n\nExplanation:\nTo ensure that the chatbot adheres to the company's tone and provides appropriate responses, prompt engineering is essential. By experimenting and refining the prompt, you can guide the foundation model (FM) to produce responses that align with the desired tone, style, and content. This approach allows you to set the context and expectations for the chatbot's replies.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "C",
          "content": "Prompt engineering is the most effective way to ensure that a foundation model (FM) produces outputs adhering to a company’s tone and specific requirements.\nBy iteratively testing and refining prompts, you can guide the FM to produce responses that align with the desired style, tone, and content accuracy.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Refining the prompt is the answer",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 25,
      "data_id": "933848",
      "url": "https://www.examtopics.com/discussions/amazon/view/150805-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to classify the sentiment of text passages as positive or negative.Which prompt engineering strategy meets these requirements?",
      "choices": [
        "A. Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.",
        "B. Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt.",
        "C. Provide the new text passage to be classified without any additional context or examples.",
        "D. Provide the new text passage with a few examples of unrelated tasks, such as text summarization or question answering."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Set the proper label with a few examples to the prompts",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.\n\nExplanation:\nThis strategy is known as few-shot prompting, where the prompt includes a few examples of labeled data (text passages with positive or negative sentiment) before asking the model to classify the new text passage. This helps the large language model (LLM) understand the task and align its output with the desired format.\n\nWhy not the other options?\nB: Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt:\nExplaining the concept of sentiment analysis is unnecessary for the model, as it does not improve the model's ability to classify text.\nC: Provide the new text passage to be classified without any additional context or examples:\nWithout examples, the LLM might not correctly infer the task or format of the output, leading to inconsistent or incorrect results.",
          "upvotes": 3
        },
        {
          "user": "Gianiluca",
          "selected_answer": "A",
          "content": "This approach uses few-shot learning, which is highly effective with large language models. By providing examples of text passages with their corresponding sentiment classifications, the LLM learns the context and pattern needed to classify the new passage.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "Explanation:\nBy providing examples of text passages along with their corresponding sentiment labels (positive or negative), the model can learn from these examples how to classify the sentiment of the new text passage effectively",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 26,
      "data_id": "933849",
      "url": "https://www.examtopics.com/discussions/amazon/view/150806-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A security company is using Amazon Bedrock to run foundation models (FMs). The company wants to ensure that only authorized users invoke the models. The company needs to identify any unauthorized access attempts to set appropriate AWS Identity and Access Management (IAM) policies and roles for future iterations of the FMs.Which AWS service should the company use to identify unauthorized users that are trying to access Amazon Bedrock?",
      "choices": [
        "A. AWS Audit Manager",
        "B. AWS CloudTrail",
        "C. Amazon Fraud Detector",
        "D. AWS Trusted Advisor"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "eyzzeuss",
          "selected_answer": "B",
          "content": "AWS CloudTrail is a service that records all API calls and user activity across AWS services, including Amazon Bedrock.",
          "upvotes": 1
        },
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "Use AWS CloudTrail to track the API Calls to AWS resources.",
          "upvotes": 1
        },
        {
          "user": "nandhae",
          "selected_answer": "B",
          "content": "B. AWS CloudTrail\n\nCloudTrail records API activity and user actions in your AWS account. It logs events such as unauthorized access attempts to Amazon Bedrock and other AWS services, making it the correct choice for identifying such attempts.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: AWS CloudTrail\n\nExplanation:\nAWS CloudTrail is a service that records all API calls and user activity across AWS services, including Amazon Bedrock. By analyzing CloudTrail logs, the company can identify unauthorized access attempts, track user activity, and audit the usage of foundation models. This information helps in setting appropriate AWS Identity and Access Management (IAM) policies and roles for future iterations of the models.",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "B. AWS CloudTrail is the most suitable service for identifying unauthorized access attempts to Amazon Bedrock, as it provides detailed logging and monitoring of API calls across AWS services, helping to enforce security and compliance.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 27,
      "data_id": "933850",
      "url": "https://www.examtopics.com/discussions/amazon/view/151095-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has developed an ML model for image classification. The company wants to deploy the model to production so that a web application can use the model.The company needs to implement a solution to host the model and serve predictions without managing any of the underlying infrastructure.Which solution will meet these requirements?",
      "choices": [
        "A. Use Amazon SageMaker Serverless Inference to deploy the model.",
        "B. Use Amazon CloudFront to deploy the model.",
        "C. Use Amazon API Gateway to host the model and serve predictions.",
        "D. Use AWS Batch to host the model and serve predictions."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Amazon SageMaker helps to host the model, and serve predictions without managing infrastructure provisioning and configurations.",
          "upvotes": 1
        },
        {
          "user": "nandhae",
          "selected_answer": "A",
          "content": "A. Use Amazon SageMaker Serverless Inference to deploy the model.\n\nAmazon SageMaker Serverless Inference is specifically designed for hosting ML models and serving predictions without requiring the management of underlying infrastructure. It automatically provisions compute resources as needed and is ideal for use cases like the one described.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Use Amazon SageMaker Serverless Inference to deploy the model.\n\nExplanation:\nAmazon SageMaker Serverless Inference is a fully managed solution for deploying machine learning models without managing the underlying infrastructure. It automatically provisions compute capacity, scales based on request traffic, and serves predictions efficiently. This makes it an ideal choice for hosting a model and serving predictions for a web application with minimal management overhead.\nWhy not the other options?\nB: Use Amazon CloudFront to deploy the model:\nAmazon CloudFront is a content delivery network (CDN) \nC: Use Amazon API Gateway to host the model and serve predictions:\nAmazon API Gateway is used to create APIs for accessing services. \nD: Use AWS Batch to host the model and serve predictions:\nAWS Batch is designed for batch processing and job scheduling, not for real-time inference or hosting ML models for web applications.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "Serverless deployment: SageMaker Serverless Inference allows you to deploy ML models without managing any underlying infrastructure, which directly meets the company's requirement.",
          "upvotes": 1
        },
        {
          "user": "minime",
          "content": "A. Use Amazon SageMaker Serverless Inference to deploy the model.\nWith serverless inference, there's no need to manage any infra.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 28,
      "data_id": "933851",
      "url": "https://www.examtopics.com/discussions/amazon/view/150807-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI company periodically evaluates its systems and processes with the help of independent software vendors (ISVs). The company needs to receive email message notifications when an ISV's compliance reports become available.Which AWS service can the company use to meet this requirement?",
      "choices": [
        "A. AWS Audit Manager",
        "B. AWS Artifact",
        "C. AWS Trusted Advisor",
        "D. AWS Data Exchange"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "AWS Artifact to keep the documents including security compliances and reports.",
          "upvotes": 1
        },
        {
          "user": "2025AIMLPractitioner",
          "selected_answer": "B",
          "content": "AWS Artifact is the service that provides on-demand access to AWS security and compliance reports.",
          "upvotes": 1
        },
        {
          "user": "nandhae",
          "selected_answer": "B",
          "content": "B. AWS Artifact\n\nAWS Artifact is a central resource for accessing compliance-related documents and reports, such as those provided by independent software vendors (ISVs). Users can subscribe to notifications to receive alerts when new compliance reports are available. This makes it the correct choice.",
          "upvotes": 1
        },
        {
          "user": "kerl",
          "selected_answer": "B",
          "content": "https://docs.aws.amazon.com/artifact/latest/ug/what-is-aws-artifact.html",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: AWS Artifact\n\nExplanation:\nAWS Artifact is a service that provides on-demand access to AWS compliance reports, including those from independent software vendors (ISVs). AWS Artifact can notify users when new compliance reports are available, ensuring that the company stays updated and can evaluate its systems and processes accordingly.\nD: AWS Data Exchange:\nAWS Data Exchange is used for subscribing to and managing third-party data sets. It is not intended for compliance reports or notifications about them.\n\nConclusion:\nAWS Artifact is the best choice for accessing and receiving notifications about compliance reports from independent software vendors (ISVs).",
          "upvotes": 2
        },
        {
          "user": "KevinKas",
          "selected_answer": "B",
          "content": "Companies can use notification settings in AWS Artifact to receive email alerts when new compliance reports or updates become available, ensuring they stay informed about the latest reports.",
          "upvotes": 1
        },
        {
          "user": "HarishRao",
          "selected_answer": "B",
          "content": "https://docs.aws.amazon.com/artifact/latest/ug/what-is-aws-artifact.html\n\nWith AWS Artifact, you can also download security and compliance documents for independent software vendors (ISVs) who sell their products on AWS Marketplace.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "The correct answer is D. AWS Data Exchange enables receiving and managing third-party data including compliance reports.",
          "upvotes": 1
        },
        {
          "user": "EDoubleU",
          "selected_answer": "B",
          "content": "B\n\nhttps://docs.aws.amazon.com/artifact/latest/ug/managing-notifications.html#:~:text=You%20can%20use%20the%20AWS,notifications%20using%20AWS%20User%20Notifications.",
          "upvotes": 2
        },
        {
          "user": "OMBR",
          "selected_answer": "B",
          "content": "https://aws.amazon.com/about-aws/whats-new/2023/01/aws-artifact-on-demand-third-party-compliance-reports/",
          "upvotes": 3
        },
        {
          "user": "RY66",
          "content": "The correct answer to this question is B. AWS Artifact\nAWS Artifact is the service that provides on-demand access to AWS security and compliance reports.\nIt allows users to access various compliance reports such as ISO certifications, PCI reports, and SOC reports.\nSpecifically, AWS Artifact Notifications feature allows users to receive email notifications when new reports become available.\nThis directly meets the requirement stated in the question: \"The company needs to receive email message notifications when an ISV's compliance reports become available.\"",
          "upvotes": 2
        },
        {
          "user": "dlittle1977",
          "content": "The correct answer is B. \nhttps://docs.aws.amazon.com/artifact/latest/ug/what-is-aws-artifact.html",
          "upvotes": 4
        },
        {
          "user": "avi260919851985",
          "content": "D. Aws Data Exchange",
          "upvotes": 2
        },
        {
          "user": "fed6485",
          "selected_answer": "D",
          "content": "D. AWS Data Exchange, this is related to a third party, while AWS Artifact enables you to download AWS security and compliance documents such as ISO certifications and SOC reports.",
          "upvotes": 2
        },
        {
          "user": "Blair77",
          "content": "AWS Data Exchange allows customers to securely exchange data with third parties but is not focused on compliance reporting or notifications related to ISVs",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "B",
          "content": "Compliance report access: AWS Artifact provides on-demand access to AWS security and compliance reports, including those from Independent Software Vendors (ISVs) who sell their products on AWS Marketplace. AWS Data Exchange: This service is for finding, subscribing to, and using third-party data in the cloud, but it's not specifically designed for compliance reports or notifications.",
          "upvotes": 1
        },
        {
          "user": "leyunjohn",
          "selected_answer": "D",
          "content": "D. AWS Data Exchange",
          "upvotes": 3
        },
        {
          "user": "dehkon",
          "content": "D. AWS Data Exchange\n\nAWS Data Exchange allows subscribers to find, subscribe to, and use third-party data, including compliance reports from Independent Software Vendors (ISVs). The service can provide notifications when new data sets, such as compliance reports, are available from subscribed ISVs.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 29,
      "data_id": "933852",
      "url": "https://www.examtopics.com/discussions/amazon/view/150808-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use a large language model (LLM) to develop a conversational agent. The company needs to prevent the LLM from being manipulated with common prompt engineering techniques to perform undesirable actions or expose sensitive information.Which action will reduce these risks?",
      "choices": [
        "A. Create a prompt template that teaches the LLM to detect attack patterns.",
        "B. Increase the temperature parameter on invocation requests to the LLM.",
        "C. Avoid using LLMs that are not listed in Amazon SageMaker.",
        "D. Decrease the number of input tokens on invocations of the LLM."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Ask model to use Prompt template to avoid the various types of prompt injection attacks.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "Creating a prompt template that teaches the LLM to identify and resist common prompt engineering attacks, such as prompt injection or adversarial queries, helps prevent manipulation.\nBy explicitly guiding the LLM to ignore requests that deviate from its intended purpose (e.g., \"You are a helpful assistant. Do not perform any tasks outside your defined scope.\"), you can mitigate risks like exposing sensitive information or executing undesirable actions.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A. Create a prompt template that teaches the LLM to detect attack patterns is the best action to reduce the risks associated with prompt manipulation and to enhance the security and integrity of the conversational agent being developed.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 30,
      "data_id": "933853",
      "url": "https://www.examtopics.com/discussions/amazon/view/150809-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using the Generative AI Security Scoping Matrix to assess security responsibilities for its solutions. The company has identified four different solution scopes based on the matrix.Which solution scope gives the company the MOST ownership of security responsibilities?",
      "choices": [
        "A. Using a third-party enterprise application that has embedded generative AI features.",
        "B. Building an application by using an existing third-party generative AI foundation model (FM).",
        "C. Refining an existing third-party generative AI foundation model (FM) by fine-tuning the model by using data specific to the business.",
        "D. Building and training a generative AI model from scratch by using specific data that a customer owns."
      ],
      "answer": "d",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "D: Building and training a generative AI model from scratch by using specific data that a customer owns.\n\nExplanation:\nWhen a company builds and trains a generative AI model from scratch, it assumes the most ownership of security responsibilities, including:\n\nData security and compliance during training.\nModel development and training processes.\nInfrastructure and deployment security.\nProtecting the model from adversarial attacks.\nEnsuring ethical use of the model and safeguarding against bias and misuse.\nThis approach provides complete control over the entire lifecycle of the AI solution but also places the greatest burden of responsibility on the company.",
          "upvotes": 1
        },
        {
          "user": "kyo",
          "selected_answer": "D",
          "content": "https://aws.amazon.com/ai/generative-ai/security/scoping-matrix/",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "D",
          "content": "D. Building and training a generative AI model from scratch by using specific data that a customer owns.\n\nIn this scenario, the company has the most control over the entire development and deployment process. This includes:\n\nData security: The company is responsible for securing the training data, which might contain sensitive information.\nModel security: The company needs to implement measures to protect the model itself, including securing the training process, model parameters, and deployment infrastructure.\nOperational security: The company is responsible for securing the deployment environment and monitoring the model for potential vulnerabilities.\nWhile the other options involve some level of security responsibility, they rely on third-party providers to a greater extent. This reduces the company's direct control over the security aspects of the solution.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "D",
          "content": "D. Building and training a generative AI model from scratch by using specific data that a customer owns gives the company the most ownership of security responsibilities, as they are responsible for all aspects of the model's development and deployment.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 31,
      "data_id": "933854",
      "url": "https://www.examtopics.com/discussions/amazon/view/150810-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner has a database of animal photos. The AI practitioner wants to automatically identify and categorize the animals in the photos without manual human effort.Which strategy meets these requirements?",
      "choices": [
        "A. Object detection",
        "B. Anomaly detection",
        "C. Named entity recognition",
        "D. Inpainting"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Object detection helps to identify and category the object of the image.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Object detection\n\nExplanation:\nObject detection is a computer vision technique that identifies and categorizes objects within an image. In this scenario, it can automatically detect animals in the photos and assign them to categories (e.g., \"dog,\" \"cat,\" \"bird\"). This approach aligns perfectly with the requirement to identify and categorize animals without manual intervention.",
          "upvotes": 1
        },
        {
          "user": "Gianiluca",
          "selected_answer": "A",
          "content": "A. Object Detection\nIdentifies and locates objects in images\nCan classify different types of objects (like animals)\nWorks automatically on images\nPerfect for categorizing visual content",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "A . Object detection",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": ". Object detection is the most appropriate strategy for automatically identifying and categorizing animals in a database of photos without manual human effort.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 32,
      "data_id": "933855",
      "url": "https://www.examtopics.com/discussions/amazon/view/150811-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to create an application by using Amazon Bedrock. The company has a limited budget and prefers flexibility without long-term commitment.Which Amazon Bedrock pricing model meets these requirements?",
      "choices": [
        "A. On-Demand",
        "B. Model customization",
        "C. Provisioned Throughput",
        "D. Spot Instance"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "On-Demand pricing plan helps to run the application in the temporary mode.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: On-Demand\n\nExplanation:\nThe On-Demand pricing model for Amazon Bedrock provides flexibility and allows the company to pay only for what they use, without requiring long-term commitments or upfront payments. This is ideal for a company with a limited budget that needs to control costs while maintaining flexibility.\n\nD: Spot Instance:\nSpot Instances are an AWS EC2 pricing model for obtaining unused compute capacity at discounted rates. They are not applicable to Amazon Bedrock, which does not rely on Spot Instances.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "On-Demand is the best pricing model for a company that has a limited budget and wants flexibility without long-term commitment when creating an application using Amazon Bedrock.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 33,
      "data_id": "933856",
      "url": "https://www.examtopics.com/discussions/amazon/view/150812-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?",
      "choices": [
        "A. Amazon Personalize",
        "B. Amazon SageMaker JumpStart",
        "C. PartyRock, an Amazon Bedrock Playground",
        "D. Amazon SageMaker endpoints"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "Amazon SageMaker JumpStart helps to deploy pre-trained Open-sourced models quickly.",
          "upvotes": 1
        },
        {
          "user": "dspd",
          "selected_answer": "B",
          "content": "The correct answer is B: Amazon SageMaker JumpStart.\n\nHere's why:\n\nAmazon SageMaker JumpStart is specifically designed to help teams quickly deploy and use foundation models (FMs) with the following benefits:\nProvides pre-trained models that can be deployed with just a few clicks\nAllows deployment within your VPC for secure access\nIncludes popular foundation models from various providers\nOffers fine-tuning capabilities for customization\nHandles the infrastructure management automatically\n\nAmazon SageMaker endpoints - While these are used to deploy models, SageMaker JumpStart provides a more complete solution specifically for foundation models with built-in deployment capabilities",
          "upvotes": 1
        },
        {
          "user": "waldonuts",
          "selected_answer": "D",
          "content": "I lean towards Sagemaker Endpoints . to my knowledge Jumpstart will help you select/deploy the model, but to actually use it/consume it in your Prod/dev environment/VPC you need the Endpoint",
          "upvotes": 2
        },
        {
          "user": "scs50",
          "selected_answer": "B",
          "content": "Amazon SageMaker JumpStart provides security features, including the ability to integrate with a Virtual Private Cloud (VPC), ensuring secure communication and data transfer during machine learning tasks. SageMaker Jumpstart simplifies the process of building, training, and deploying ML models by offering ready-to-use resources and templates.",
          "upvotes": 1
        },
        {
          "user": "Aswiz",
          "selected_answer": "B",
          "content": "for quick access we can use jumpstart",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "he question asks about quickly deploying and consuming an FM within the team's VPC.\n\nA. Amazon Personalize: This is for building recommendation systems, not general FM deployment or consumption. It's irrelevant to the question.\n\nB. Amazon SageMaker JumpStart: JumpStart provides a quick way to find and deploy pre-trained models. However, the initial deployment is not automatically within your VPC. You need to configure the endpoint settings during deployment to specify your VPC. Therefore, while it speeds up the process of getting a model ready, it doesn't directly fulfill the \"within the team's VPC\" requirement without extra steps.\n\n\nD. Amazon SageMaker endpoints: This is the most accurate answer. While JumpStart can help you get a model ready, it's the SageMaker endpoint itself that is configured to reside within your VPC. You create the endpoint and specify the VPC configuration during that endpoint creation.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "Let me explain why Amazon SageMaker JumpStart (Option B) is the correct answer:\n\n1. VPC Integration: SageMaker JumpStart allows deployment of foundation models within your team's VPC, ensuring secure access and network isolation.\n\n2. Quick Deployment: It provides a streamlined process for deploying pre-trained foundation models with minimal setup required. The service includes:\n   - One-click deployment options\n   - Pre-configured model endpoints\n   - Built-in model optimization\n\n3. Foundation Model Support: SageMaker JumpStart specifically offers a wide range of foundation models that are ready to use.",
          "upvotes": 1
        },
        {
          "user": "Chika22",
          "selected_answer": "B",
          "content": "Amazon SageMaker JumpStart",
          "upvotes": 2
        },
        {
          "user": "Contactfornitish",
          "selected_answer": "D",
          "content": "Amazon SageMaker endpoints allow you to deploy machine learning models, including foundation models, for real-time inference within a Virtual Private Cloud (VPC). This feature is particularly suitable for AI teams looking to host and consume their models securely and quickly.\n\nAmazon SageMaker JumpStart: While JumpStart provides prebuilt solutions and model deployment templates, it is not specifically focused on VPC integration for foundation models.",
          "upvotes": 1
        },
        {
          "user": "0c2d840",
          "selected_answer": "B",
          "content": "It could be B or D as question says Service or Feature.\nWhy D got eliminated? - Even though it says Service or Feature, I think that is just because SageMaker itself is an umbrella for many services and features. Like SageMaker studio itself has many features. SageMaker endpoint is not a feature per say, but the deployment environment for models.",
          "upvotes": 2
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "B. Amazon SageMaker JumpStart\n\nAmazon SageMaker JumpStart provides a collection of pre-trained models, including foundation models, that can be easily deployed and customized within a team's VPC. This allows for secure and efficient access to these powerful models without exposing them to the public internet",
          "upvotes": 2
        },
        {
          "user": "RY66",
          "content": "The correct answer to this question is B. Amazon SageMaker JumpStart.\nAmazon SageMaker JumpStart is a service that provides pre-trained models, solutions, and examples to help quickly start machine learning tasks.\nJumpStart includes a variety of foundation models (FMs) and offers features to easily deploy and fine-tune these models.\nImportantly, models deployed through JumpStart can be run securely within a team's VPC, which aligns with the question's requirement of deploying and consuming a foundation model within the team's VPC.\nJumpStart enables quick deployment and consumption of models, satisfying the \"quickly deploy and consume\" part of the question.",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "selected_answer": "D",
          "content": ".. AWS FEATURE can help .. and CONSUME a foundation model (FM) within the team's VPC?",
          "upvotes": 2
        },
        {
          "user": "fed6485",
          "content": "sorry i didn't notice i have already commented/answer on this.",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "selected_answer": "D",
          "content": "... mmm.. interesting one as.. \n\nWhich AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?\n\nthe fact that \"AWS service or FEATURE\" .. deploy within the team's VPC..\n\ndefinitely or B or D\nB if the question refers to the SERVICE\nD if the question refers to the FEATURE\n\n:)",
          "upvotes": 2
        },
        {
          "user": "0c2d840",
          "content": "Answer is A. Even though it says Service or Feature, I think that is just because SageMaker itself is an umbrella for many services and features. Like SageMaker studio itself has many features. SageMaker endpoint is not a feature per say, but the deployment environment for models.",
          "upvotes": 1
        },
        {
          "user": "raat",
          "content": "Amazon SageMaker JumpStart (option B) is indeed a valuable service for quickly getting started with pre-built models and solutions. However, it is more focused on providing a range of pre-trained models and example solutions to help you get started with machine learning projects.\n\nFor the specific requirement of deploying and consuming a foundation model within your VPC, Amazon SageMaker endpoints (option D) are more directly suited. They allow you to deploy models for real-time inference securely within your VPC, ensuring that your data and model interactions remain within your private network.\n\nIf you have any more questions or need further clarification, feel free to ask!",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "B. Amazon SageMaker JumpStart is the best option for quickly deploying and consuming a foundation model within a team's VPC, as it streamlines the process and provides ready-to-use resources.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 34,
      "data_id": "933857",
      "url": "https://www.examtopics.com/discussions/amazon/view/150813-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "How can companies use large language models (LLMs) securely on Amazon Bedrock?",
      "choices": [
        "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.",
        "B. Enable AWS Audit Manager for automatic model evaluation jobs.",
        "C. Enable Amazon Bedrock automatic model evaluation jobs.",
        "D. Use Amazon CloudWatch Logs to make models explainable and to monitor for bias."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Using IAM with least privilege will secure the LLM on the Amazon Bedrock.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "A",
          "content": "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.\n\nThis option addresses two key aspects of secure LLM usage on Amazon Bedrock:\n\nPrompt Engineering: Clear and specific prompts reduce the risk of unintended or harmful outputs. Well-defined prompts help guide the model's responses and minimize the potential for bias or misinformation.\nIAM Access Control: Implementing strong access controls is crucial to protect sensitive data and prevent unauthorized access to the LLM. By using IAM roles and policies with least privilege access, you can limit permissions to only the necessary actions, reducing the risk of security breaches.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access is the best approach for companies to securely use large language models on Amazon Bedrock, as it emphasizes both prompt clarity and access control.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 35,
      "data_id": "933858",
      "url": "https://www.examtopics.com/discussions/amazon/view/150814-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has terabytes of data in a database that the company can use for business analysis. The company wants to build an AI-based application that can build a SQL query from input text that employees provide. The employees have minimal experience with technology.Which solution meets these requirements?",
      "choices": [
        "A. Generative pre-trained transformers (GPT)",
        "B. Residual neural network",
        "C. Support vector machine",
        "D. WaveNet"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "GPT helps to produces the NL based responsed based on the input text.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "The best solution for building an AI-based application that translates natural language (employee input text) into SQL queries is A. Generative pre-trained transformers (GPT).\n\nHere's why:\n\nGPT's strength in natural language processing: GPT models are specifically designed for understanding and generating human language. They excel at tasks like text translation, question answering, and, crucially, code generation from natural language descriptions. This makes them ideal for converting employee input into SQL queries.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "Generative pre-trained transformers (GPT) are powerful natural language processing models that excel in understanding and generating human-like text. In this scenario, a GPT model can be trained or fine-tuned to take natural language input from employees and convert it into structured SQL queries. This makes it accessible for users who may not have technical expertise, allowing them to retrieve the data they need from the database using simple, conversational prompts.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 36,
      "data_id": "933859",
      "url": "https://www.examtopics.com/discussions/amazon/view/151041-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company built a deep learning model for object detection and deployed the model to production.Which AI process occurs when the model analyzes a new image to identify objects?",
      "choices": [
        "A. Training",
        "B. Inference",
        "C. Model deployment",
        "D. Bias correction"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "During the inference phase, model analyses a new image to identify objects.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "B. Inference\n\nInference is the process of using a trained model to make predictions or decisions on new, unseen data. In the case of an object detection model, inference involves feeding a new image into the model, which then analyzes the image and outputs the detected objects and their locations.",
          "upvotes": 1
        },
        {
          "user": "urbanmonk",
          "selected_answer": "B",
          "content": "AI inference is the process that a trained machine learning model uses to draw conclusions from brand-new data. An AI model capable of making inferences can do so without examples of the desired result.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "It's the inference",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 37,
      "data_id": "933860",
      "url": "https://www.examtopics.com/discussions/amazon/view/150816-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner is building a model to generate images of humans in various professions. The AI practitioner discovered that the input data is biased and that specific attributes affect the image generation and create bias in the model.Which technique will solve the problem?",
      "choices": [
        "A. Data augmentation for imbalanced classes",
        "B. Model monitoring for class distribution",
        "C. Retrieval Augmented Generation (RAG)",
        "D. Watermark detection for images"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "eesa",
          "selected_answer": "A",
          "content": "Data augmentation for imbalanced classes\n\nData augmentation techniques can help mitigate bias in image generation models by artificially increasing the diversity of the training data. By applying transformations like rotations, flips, and color jittering to existing images, you can create new, synthetic images that are similar to the original ones. This can help balance the dataset and reduce the impact of biases present in the original data.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "A. Data augmentation for imbalanced classes is the most effective technique to mitigate bias in the input data by ensuring a more balanced representation of classes and attributes in the training set, leading to fairer and more accurate image generation.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 38,
      "data_id": "933861",
      "url": "https://www.examtopics.com/discussions/amazon/view/151094-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is implementing the Amazon Titan foundation model (FM) by using Amazon Bedrock. The company needs to supplement the model by using relevant data from the company's private data sources.Which solution will meet this requirement?",
      "choices": [
        "A. Use a different FM.",
        "B. Choose a lower temperature value.",
        "C. Create an Amazon Bedrock knowledge base.",
        "D. Enable model invocation logging."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Amazon Bedrock KB support to interact with the company's private data sources.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "C",
          "content": "Create an Amazon Bedrock knowledge base.\n\nAn Amazon Bedrock knowledge base allows you to incorporate your company's proprietary data into the foundation model. By feeding the model with relevant information, you can enhance its ability to generate more accurate and informative responses.",
          "upvotes": 1
        },
        {
          "user": "raat",
          "selected_answer": "C",
          "content": "C, is correct",
          "upvotes": 1
        },
        {
          "user": "minime",
          "content": "C. Create an Amazon Bedrock knowledge base.\nThis would allow the company use the knowledge base for Retrieval Augmented Generation (RAG) to enhance the model's knowledge with company's private data sources.",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 39,
      "data_id": "933862",
      "url": "https://www.examtopics.com/discussions/amazon/view/150820-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A medical company is customizing a foundation model (FM) for diagnostic purposes. The company needs the model to be transparent and explainable to meet regulatory requirements.Which solution will meet these requirements?",
      "choices": [
        "A. Configure the security and compliance by using Amazon Inspector.",
        "B. Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.",
        "C. Encrypt and secure training data by using Amazon Macie.",
        "D. Gather more data. Use Amazon Rekognition to add custom labels to the data."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Amazon SageMaker Clarify is specifically designed to help make machine learning models more transparent and explainable by generating metrics and reports on model bias, data bias, and feature importance.",
          "upvotes": 5
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "B. Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.\n\n\nAmazon SageMaker Clarify helps in identifying bias and explaining predictions made by machine learning models, which aligns well with the need for transparency and explainability to meet regulatory requirements.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 40,
      "data_id": "933863",
      "url": "https://www.examtopics.com/discussions/amazon/view/150821-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to deploy a conversational chatbot to answer customer questions. The chatbot is based on a fine-tuned Amazon SageMaker JumpStart model. The application must comply with multiple regulatory frameworks.Which capabilities can the company show compliance for? (Choose two.)",
      "choices": [
        "A. Auto scaling inference endpoints",
        "B. Threat detection",
        "C. Data protection",
        "D. Cost optimization",
        "E. Loosely coupled microservices"
      ],
      "answer": "bc",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "BC",
          "content": "Threat (Amazon GuardDuty) and Data Protection (Amazon Macie, KMS, Encrypt the data at REST and in-Transit.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "BC",
          "content": "Why not the other options?\nA: Auto scaling inference endpoints:\nAuto-scaling improves performance and cost-efficiency but is not directly related to regulatory compliance.\nD: Cost optimization:\nCost optimization is beneficial for managing expenses but is not a compliance requirement.\nE: Loosely coupled microservices:\nWhile a good architectural principle, it does not directly address compliance with regulatory frameworks.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "BC",
          "content": "B: Threat detection\nC: Data protection\n\nExplanation:\nWhen deploying a conversational chatbot using a fine-tuned model from Amazon SageMaker JumpStart, the company can demonstrate compliance in the following areas:\n\nB: Threat detection: Amazon SageMaker integrates with AWS security services like Amazon GuardDuty and AWS CloudTrail to monitor for threats and unauthorized access. This ensures compliance with security regulations.\nC: Data protection: SageMaker supports encryption of data at rest and in transit, integration with AWS Key Management Service (KMS), and fine-grained access control through IAM. These features ensure compliance with regulatory frameworks requiring data protection.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "BC",
          "content": "The two capabilities that the company can show compliance for are:\n\nC. Data protection\n\nB. Threat detection\n\nHere's a breakdown:\n\nData Protection:\nAmazon SageMaker offers robust data protection features, including data encryption at rest and in transit.\nBy leveraging these features, the company can ensure that customer data is handled securely and complies with relevant data privacy regulations.\nThreat Detection:\nAmazon Web Services (AWS) provides a comprehensive security suite, including services like Amazon GuardDuty and AWS Security Hub.\nThese services can help detect and respond to potential threats, such as unauthorized access, data breaches, and malicious activity.\nBy utilizing these services, the company can demonstrate its commitment to security and compliance.",
          "upvotes": 2
        },
        {
          "user": "urbanmonk",
          "selected_answer": "C",
          "content": "Data Protection - certainly. \nNot sure which other option fits into the regulatory context.",
          "upvotes": 1
        },
        {
          "user": "RY66",
          "content": "The correct answers for this question are:\nA. Auto scaling inference endpoints\nC. Data protection\nAuto scaling inference endpoints:\nAmazon SageMaker provides auto-scaling capabilities that automatically adjust infrastructure based on traffic changes.\nThis helps meet availability and performance requirements, which are crucial aspects of regulatory compliance.\nMany regulatory frameworks require service stability and availability, making this feature an important element in demonstrating compliance.\nData protection:\nData protection is a core requirement in most regulatory frameworks.\nAmazon SageMaker offers various data protection features including data encryption, access control, and audit logging.\nFor a chatbot handling customer data, demonstrating data protection capabilities is essential for regulatory compliance.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "BC",
          "content": "C. Data protection and B. Threat detection are the two key capabilities that can help the company meet regulatory compliance requirements when deploying a conversational chatbot using Amazon SageMaker JumpStart.",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 41,
      "data_id": "933864",
      "url": "https://www.examtopics.com/discussions/amazon/view/151042-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is training a foundation model (FM). The company wants to increase the accuracy of the model up to a specific acceptance level.Which solution will meet these requirements?",
      "choices": [
        "A. Decrease the batch size.",
        "B. Increase the epochs.",
        "C. Decrease the epochs.",
        "D. Increase the temperature parameter."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Increase the epochs.\n\nExplanation:\nIncreasing the epochs allows the model to go through the entire training dataset multiple times, improving its learning and optimizing its weights. This can help the model achieve a higher accuracy level, provided it does not lead to overfitting. For a foundation model (FM), increasing epochs is a common approach to refining accuracy to meet specific acceptance levels.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "B. Increase the epochs.\n\nIncreasing the number of epochs, or training cycles, can help improve the accuracy of a foundation model. By exposing the model to the training data multiple times, it can learn more intricate patterns and relationships, leading to better performance.",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "B. Increase the epochs: Increasing the number of epochs allows the model to continue learning from the data, potentially improving its accuracy as it trains on more examples. However, there is a risk of overfitting if epochs are increased too much.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 42,
      "data_id": "933865",
      "url": "https://www.examtopics.com/discussions/amazon/view/151043-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building a large language model (LLM) question answering chatbot. The company wants to decrease the number of actions call center employees need to take to respond to customer questions.Which business objective should the company use to evaluate the effect of the LLM chatbot?",
      "choices": [
        "A. Website engagement rate",
        "B. Average call duration",
        "C. Corporate social responsibility",
        "D. Regulatory compliance"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Average call duration\n\nExplanation:\nAverage call duration is a key metric for evaluating the efficiency of a question-answering chatbot in a call center environment. By reducing the number of actions employees need to take, the chatbot can help streamline customer interactions, resulting in shorter call durations. Monitoring this metric helps the company assess whether the chatbot is achieving its goal of improving call center efficiency.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Obviously it is B",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 43,
      "data_id": "933866",
      "url": "https://www.examtopics.com/discussions/amazon/view/150822-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which functionality does Amazon SageMaker Clarify provide?",
      "choices": [
        "A. Integrates a Retrieval Augmented Generation (RAG) workflow",
        "B. Monitors the quality of ML models in production",
        "C. Documents critical details about ML models",
        "D. Identifies potential bias during data preparation"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "jove",
          "selected_answer": "D",
          "content": "Amazon SageMaker Clarify provides functionality to detect and identify potential bias in data both before and after training, helping teams uncover imbalances in datasets that might lead to biased model predictions. This is essential for ensuring fairness and compliance, especially in sensitive applications.\n\nWhy Not the Other Options?\nA. Integrates a Retrieval Augmented Generation (RAG) workflow: RAG workflows are used for combining retrieved documents with model outputs, typically in language models, but this is not a function of SageMaker Clarify.\nB. Monitors the quality of ML models in production: Monitoring model quality in production is handled by SageMaker Model Monitor, not SageMaker Clarify.\nC. Documents critical details about ML models: This functionality is part of Amazon SageMaker Model Cards, which documents model details for transparency and compliance.",
          "upvotes": 5
        },
        {
          "user": "85b5b55",
          "selected_answer": "D",
          "content": "Amazon Sagemake Clarify helps to Identify bias, how much models makes prediction, datasets or models reflections and more.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "D",
          "content": "D. Identifies potential bias during data preparation   \n\nAmazon SageMaker Clarify is a tool designed to help understand, debug, and improve machine learning models. One of its key functionalities is to identify potential bias in datasets and models. It can analyze datasets for imbalances, fairness issues, and other biases that could impact the model's performance and fairness",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 44,
      "data_id": "933867",
      "url": "https://www.examtopics.com/discussions/amazon/view/151044-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly.What should the company do to mitigate this problem?",
      "choices": [
        "A. Reduce the volume of data that is used in training.",
        "B. Add hyperparameters to the model.",
        "C. Increase the volume of data that is used in training.",
        "D. Increase the model training time."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "scs50",
          "selected_answer": "B",
          "content": "The company should use hyperparameters for model tuning, which involves adjusting parameters such as regularization, learning rates, and dropout rates to enhance the model's ability to generalize well to new data\n\nExplanation: \nHyperparameter tuning is the most effective solution in this scenario because it allows the company to adjust the settings that control the learning process of the model. By fine-tuning hyperparameters, such as increasing regularization or early stopping or adjusting dropout rates, the model can avoid overfitting to the training data and better generalize to new, unseen data in production. This approach helps improve the model's performance across various data distributions.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Increase the volume of data that is used in training.\n\nExplanation:\nThe issue described is likely caused by overfitting, where the model performs well on the training dataset but fails to generalize to unseen data. Increasing the volume of training data can help mitigate overfitting by providing the model with more diverse examples, improving its ability to generalize to new data in production.",
          "upvotes": 3
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. Increasing the volume of data used in training can help improve the model's performance in production by providing it with more diverse examples to learn from.",
          "upvotes": 1
        },
        {
          "user": "MH1980",
          "selected_answer": "C",
          "content": "How can you prevent overfitting?\n• Increase the training data size\n• Early stopping the training of the model\n• Data augmentation (to increase diversity in the dataset)\n• Adjust hyperparameters (but you can’t “add” them)",
          "upvotes": 3
        },
        {
          "user": "Dandelion2025",
          "selected_answer": "C",
          "content": "To prevent overfitting, increase training data, use early stopping, apply data augmentation, and fine-tune hyperparameters without adding new ones.",
          "upvotes": 1
        },
        {
          "user": "taka5094",
          "selected_answer": "C",
          "content": "Reducing the training data make the model prone to overfitting, and will likely further degrade the model's performance.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "C",
          "content": "More diverse training data helps the model learn broader patterns and generalize better to unseen data in production. This reduces the risk of overfitting to the training set.\nReduced Overfitting: The significant performance drop in production suggests overfitting to the training data. Increasing the data volume can help the model learn more robust features that are truly predictive rather than memorizing specifics of a limited dataset.. For A - Reducing the training data volume would likely exacerbate the problem rather than solve it. The model's poor performance in production suggests it's not generalizing well, which is often a result of insufficient or non-representative training data.",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "selected_answer": "A",
          "content": "yes Overfitting.. but if the \"Volume Data\" is FIXED, meaning if they are going to reuse the same data.. this time the need to REDUCE it.. so \"A\"\n\nif they have MORE/EXTRA data to augment the one already available.. than C",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "content": "i mean A. reduce the portion for training and increase the portion for testing.. \nif it was 80-10-10, than do 75 -15-15",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "content": "yes Overfitting.. but if the \"Volume Data\" is FIXED, meaning if they are going to reuse the same data.. this time the need to REDUCE it.. so \"A\"\n\nif they have MORE/EXTRA data to augment the one already available.. than C",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Model is overfitting. Needs more training data",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 45,
      "data_id": "933868",
      "url": "https://www.examtopics.com/discussions/amazon/view/150924-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An ecommerce company wants to build a solution to determine customer sentiments based on written customer reviews of products.Which AWS services meet these requirements? (Choose two.)",
      "choices": [
        "A. Amazon Lex",
        "B. Amazon Comprehend",
        "C. Amazon Polly",
        "D. Amazon Bedrock",
        "E. Amazon Rekognition"
      ],
      "answer": "bd",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "BD",
          "content": "Amazon Comprehend (insight of the customer reviews) and Amazon Bedrock helps for sentiment analysis.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "BD",
          "content": "B. Amazon Comprehend:\n\n    Amazon Comprehend is a fully managed natural language processing (NLP) service that can analyze text and determine sentiment, entities, key phrases, and language. For customer sentiment analysis based on written reviews, Amazon Comprehend provides built-in sentiment analysis that can classify text as positive, negative, or neutral.\n\nD. Amazon Bedrock:\n\n    Amazon Bedrock is a service that provides access to various foundation models (FMs), which can be used to build and deploy AI-driven applications. For advanced natural language processing tasks like sentiment analysis, foundation models can be fine-tuned and applied to specific use cases, such as understanding customer sentiment in reviews. This is a more customizable and advanced option compared to pre-built solutions like Amazon Comprehend.",
          "upvotes": 1
        },
        {
          "user": "taka5094",
          "selected_answer": "BD",
          "content": "Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to uncover insights and relationships in text. It offers sentiment analysis capabilities out-of-the-box, which can directly determine the sentiment (positive, negative, neutral, or mixed) expressed in customer reviews.\n\nAmazon Bedrock is a fully managed service that makes foundation models accessible with simple API calls. It allows you to build generative AI applications for various use cases, including sentiment analysis. By providing customer reviews as input prompts, you can use Bedrock to generate sentiment labels or scores.",
          "upvotes": 2
        },
        {
          "user": "PHD_CHENG",
          "content": "Why not B,E?",
          "upvotes": 2
        },
        {
          "user": "JustEugen",
          "content": "I also thought about B and E.\nFor B it is easy, you can analyze text with comprehend\nFor E you using Rekognition you can check how customer reacts to your product while unboxing and so on\n\nWhen AWS Bedrock can also be the case, it simply can do the same but trained on specific data, that actually is the same, analyze text and produce output,",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 46,
      "data_id": "933869",
      "url": "https://www.examtopics.com/discussions/amazon/view/151045-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use large language models (LLMs) with Amazon Bedrock to develop a chat interface for the company's product manuals. The manuals are stored as PDF files.Which solution meets these requirements MOST cost-effectively?",
      "choices": [
        "A. Use prompt engineering to add one PDF file as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
        "B. Use prompt engineering to add all the PDF files as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
        "C. Use all the PDF documents to fine-tune a model with Amazon Bedrock. Use the fine-tuned model to process user prompts.",
        "D. Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock."
      ],
      "answer": "d",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "D",
          "content": "Amazon Bedrock Knowledge Base",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "D",
          "content": "Using a knowledge base allows for efficient retrieval of relevant information from the PDFs without having to include all the content in every prompt.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "D",
          "content": "Knowledgebase is the solution",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 47,
      "data_id": "933870",
      "url": "https://www.examtopics.com/discussions/amazon/view/150827-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A social media company wants to use a large language model (LLM) for content moderation. The company wants to evaluate the LLM outputs for bias and potential discrimination against specific groups or individuals.Which data source should the company use to evaluate the LLM outputs with the LEAST administrative effort?",
      "choices": [
        "A. User-generated content",
        "B. Moderation logs",
        "C. Content moderation guidelines",
        "D. Benchmark datasets"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "Blair77",
          "selected_answer": "D",
          "content": "Least administrative effort: Benchmark datasets are pre-existing, curated collections of data specifically designed for evaluating AI models, including LLMs. Using these requires the least administrative effort compared to the other options.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "D",
          "content": "Benchmark datasets are specifically designed to test the performance of language models on various tasks, including bias detection. They often contain diverse data that can help identify potential biases in the LLM's outputs.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 48,
      "data_id": "933871",
      "url": "https://www.examtopics.com/discussions/amazon/view/151346-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use a pre-trained generative AI model to generate content for its marketing campaigns. The company needs to ensure that the generated content aligns with the company's brand voice and messaging requirements.Which solution meets these requirements?",
      "choices": [
        "A. Optimize the model's architecture and hyperparameters to improve the model's overall performance.",
        "B. Increase the model's complexity by adding more layers to the model's architecture.",
        "C. Create effective prompts that provide clear instructions and context to guide the model's generation.",
        "D. Select a large, diverse dataset to pre-train a new generative model."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "eesa",
          "selected_answer": "C",
          "content": "C. Create effective prompts that provide clear instructions and context to guide the model's generation.\n\nPrompt engineering is a crucial technique to ensure that a pre-trained generative AI model generates content that aligns with the company's brand voice and messaging requirements. By carefully crafting prompts, you can guide the model to produce specific, relevant, and on-brand content.",
          "upvotes": 2
        },
        {
          "user": "tgv",
          "selected_answer": "C",
          "content": "By creating effective prompts.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 49,
      "data_id": "933872",
      "url": "https://www.examtopics.com/discussions/amazon/view/150828-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A loan company is building a generative AI-based solution to offer new applicants discounts based on specific business criteria. The company wants to build and use an AI model responsibly to minimize bias that could negatively affect some customers.Which actions should the company take to meet these requirements? (Choose two.)",
      "choices": [
        "A. Detect imbalances or disparities in the data.",
        "B. Ensure that the model runs frequently.",
        "C. Evaluate the model's behavior so that the company can provide transparency to stakeholders.",
        "D. Use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) technique to ensure that the model is 100% accurate.",
        "E. Ensure that the model's inference time is within the accepted limits."
      ],
      "answer": "ac",
      "comments": [
        {
          "user": "dspd",
          "selected_answer": "AC",
          "content": "A. Detect imbalances or disparities in the data C. Evaluate the model's behavior so that the company can provide transparency to stakeholders\n\nWhy:\n\nDetecting imbalances or disparities in the data is crucial because:\nIt helps identify potential bias in training data before it affects model decisions\nIt ensures fair treatment across different customer segments\nIt aligns with responsible AI development practices\nEvaluating model behavior for transparency is important because:\nIt allows stakeholders to understand how decisions are made\nIt helps demonstrate compliance with fair lending regulations\nIt enables the company to justify decisions to customers and regulators\n\nbelow incorrect because:\n\nB (frequent model runs) doesn't address bias or responsible AI\nD (ROUGE technique) is for text summarization evaluation, not lending decisions\nE (inference time) is about performance, not fairness or responsibility",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "AC",
          "content": "A & C looks correct",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 50,
      "data_id": "933873",
      "url": "https://www.examtopics.com/discussions/amazon/view/150829-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using an Amazon Bedrock base model to summarize documents for an internal use case. The company trained a custom model to improve the summarization quality.Which action must the company take to use the custom model through Amazon Bedrock?",
      "choices": [
        "A. Purchase Provisioned Throughput for the custom model.",
        "B. Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.",
        "C. Register the model with the Amazon SageMaker Model Registry.",
        "D. Grant access to the custom model in Amazon Bedrock."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "LR2023",
          "selected_answer": "A",
          "content": "Initially I was going with D but after reading this article sticking with A\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html?form=MG0AV3",
          "upvotes": 12
        },
        {
          "user": "CTao",
          "selected_answer": "A",
          "content": "A To customize model you must purchase Provisioned Throughput.",
          "upvotes": 5
        },
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Provisioned Throughput helps to improve the quality.",
          "upvotes": 1
        },
        {
          "user": "Ginopress",
          "selected_answer": "A",
          "content": "Accordingly to https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html?form=MG0AV3",
          "upvotes": 1
        },
        {
          "user": "kopper2019",
          "selected_answer": "D",
          "content": "A particularly insightful comment from user \"may2021_r\" clarifies this:\n\"Bottom Line:\n\nRequired to use a custom model? Give Bedrock permissions and register your model so it can retrieve your artifacts.\nOptional but recommended at scale? Purchase Provisioned Throughput to guarantee a certain level of concurrency and avoid throttling.\"\n\nThe key distinction is:\n\nGranting access is the fundamental requirement to use the model at all\nProvisioned Throughput is about performance and scaling, not basic access",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "D: Grant access to the custom model in Amazon Bedrock.\n\nExplanation:\nWhen a company trains a custom model to improve the performance of a base model provided by Amazon Bedrock, they need to ensure the custom model is accessible through the Amazon Bedrock service. Granting access to the custom model ensures it can be integrated and used through Bedrock's APIs and workflows for inference tasks like document summarization.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "The correct answer is D. Access must be granted in Bedrock to use custom models.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "content": "Bottom Line\nRequired to use a custom model? Give Bedrock permissions and register your model so it can retrieve your artifacts.\nOptional but recommended at scale? Purchase Provisioned Throughput to guarantee a certain level of concurrency and avoid throttling.\nSo if the question specifically asks which action you must take to use the custom model, the correct answer is still about granting Bedrock access—that is the non-negotiable requirement. Purchasing Provisioned Throughput is a subsequent or optional step, depending on your performance needs.",
          "upvotes": 1
        },
        {
          "user": "AKG85",
          "selected_answer": "D",
          "content": "To use the custom model with Amazon Bedrock, you need to grant access to the model first.",
          "upvotes": 1
        },
        {
          "user": "RightAnswers",
          "selected_answer": "D",
          "content": "When a company has trained a custom model to improve the functionality of an Amazon Bedrock base model, they need to explicitly grant access to that custom model within the Bedrock environment. This allows Bedrock to utilize the custom model's capabilities for the desired use case. \nWhy option A is incorrect:\nWhile purchasing provisioned throughput can improve the performance and responsiveness of a model in SageMaker, it's not necessary to use a custom model with Bedrock. Bedrock itself handles the infrastructure and resource allocation. Access granting is the key step for integration.",
          "upvotes": 1
        },
        {
          "user": "grzeev",
          "selected_answer": "D",
          "content": "The correct answer is D: Grant access to the custom model in Amazon Bedrock.\n\nWhy not B (Purchase Provisioned Throughput):\n1. Provisioned Throughput is about performance and capacity, not access\n2. Granting access is a mandatory first step for using custom models in Bedrock\n3. Without proper access permissions, the model cannot be used at all, even with Provisioned Throughput\n\nGranting access (C) is essential because it:\n- Enables model visibility in Bedrock\n- Controls who can use the custom model\n- Is a prerequisite for any model operations",
          "upvotes": 2
        },
        {
          "user": "grzeev",
          "content": "Sorry:\nGranting access (C) is essential because it:\n- Enables model visibility in Bedrock\n- Controls who can use the custom model\n- Is a prerequisite for any model operations",
          "upvotes": 1
        },
        {
          "user": "6c8c706",
          "selected_answer": "A",
          "content": "https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html",
          "upvotes": 5
        },
        {
          "user": "Contactfornitish",
          "selected_answer": "B",
          "content": "A. Purchase Provisioned Throughput for the custom model\nProvisioned Throughput is not relevant to Amazon Bedrock or custom models. It is generally associated with services like DynamoDB for performance scaling.\n\nC. Register the model with the Amazon SageMaker Model Registry\nWhile the Model Registry helps manage and track model versions, registering the model alone does not make it usable for inference. The model must still be deployed to a SageMaker endpoint.\n\nD. Grant access to the custom model in Amazon Bedrock\nAmazon Bedrock only provides access to foundation models hosted and managed by AWS. Custom models trained by the company need to be deployed separately via Amazon SageMaker.",
          "upvotes": 1
        },
        {
          "user": "leo321",
          "content": "A - is the right answer, as you NEED to Purchase Provisioned Throughput for customized model: https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html\n\nD - is NOT (less) correct as IAM is OPTIONAL: https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-prereq.html",
          "upvotes": 3
        },
        {
          "user": "RY66",
          "content": "The correct answer is D. Grant access to the custom model in Amazon Bedrock.",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "selected_answer": "A",
          "content": "B, and C, CANNOT be as the question is clear: \"..using an Amazon Bedrock..  through Amazon BedRock\" , in short SageMaker is out of the picture in this case.\n\nwe are talking about a customize Bedrock Model.. so ..  A is the only possible answer, we are not deploying a custom model in bedrock, we are using a bedrock customised model.. and in that case you have to pay the premium... as per this link:\n\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html\n\n...If you customized a model, you must purchase Provisioned Throughput to be able to use it",
          "upvotes": 4
        },
        {
          "user": "Blair77",
          "content": "While this might be relevant for scaling usage, it's not the immediate step needed to use the custom model in Bedrock.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "D",
          "content": "The question specifically mentions using the custom model \"through Amazon Bedrock,\" which implies that the model should be integrated with Bedrock's infrastructure.",
          "upvotes": 2
        },
        {
          "user": "AlwaysHungry",
          "content": "Has to be B",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 51,
      "data_id": "933874",
      "url": "https://www.examtopics.com/discussions/amazon/view/151350-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company needs to choose a model from Amazon Bedrock to use internally. The company must identify a model that generates responses in a style that the company's employees prefer.What should the company do to meet these requirements?",
      "choices": [
        "A. Evaluate the models by using built-in prompt datasets.",
        "B. Evaluate the models by using a human workforce and custom prompt datasets.",
        "C. Use public model leaderboards to identify the model.",
        "D. Use the model InvocationLatency runtime metrics in Amazon CloudWatch when trying models."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Evaluate the models by using a human workforce and custom prompt datasets.\n\nExplanation:\nTo determine which model generates responses in the style that the company's employees prefer, the company should evaluate the models using custom prompt datasets relevant to their specific use cases. Additionally, involving a human workforce ensures subjective aspects, like tone, style, and alignment with employee preferences, are effectively assessed.",
          "upvotes": 2
        },
        {
          "user": "tgv",
          "selected_answer": "B",
          "content": "Custom prompting is the way.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 52,
      "data_id": "933875",
      "url": "https://www.examtopics.com/discussions/amazon/view/151742-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A student at a university is copying content from generative AI to write essays.Which challenge of responsible generative AI does this scenario represent?",
      "choices": [
        "A. Toxicity",
        "B. Hallucinations",
        "C. Plagiarism",
        "D. Privacy"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "aws4myself",
          "selected_answer": "C",
          "content": "Plagiarism is the act of taking someone else's work or ideas and passing them off as one's own. In this case, the student is using AI-generated content without proper attribution, which is a form of plagiarism.",
          "upvotes": 1
        },
        {
          "user": "GriffXX",
          "selected_answer": "C",
          "content": "The student is plagiarizing.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 53,
      "data_id": "933876",
      "url": "https://www.examtopics.com/discussions/amazon/view/150830-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company needs to build its own large language model (LLM) based on only the company's private data. The company is concerned about the environmental effect of the training process.Which Amazon EC2 instance type has the LEAST environmental effect when training LLMs?",
      "choices": [
        "A. Amazon EC2 C series",
        "B. Amazon EC2 G series",
        "C. Amazon EC2 P series",
        "D. Amazon EC2 Trn series"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "D: Amazon EC2 Trn series\n\nExplanation:\nThe Amazon EC2 Trn series (Trn1 instances) are purpose-built for training machine learning models and are designed to deliver high performance while optimizing energy efficiency. They use AWS Trainium chips, which are specifically engineered for ML training workloads, providing excellent performance per watt and reducing the environmental impact of large-scale training processes.",
          "upvotes": 1
        },
        {
          "user": "GriffXX",
          "selected_answer": "D",
          "content": "From the documentation of the Sustainability pillar here : https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/sus_sus_hardware_a3.html\n\n\"For machine learning workloads, take advantage of purpose-built hardware that is specific to your workload such as AWS Trainium, AWS Inferentia, and Amazon EC2 DL1. AWS Inferentia instances such as Inf2 instances offer up to 50% better performance per watt over comparable Amazon EC2 instances.\"",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "D",
          "content": "D. Amazon EC2 Trn series",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 54,
      "data_id": "933877",
      "url": "https://www.examtopics.com/discussions/amazon/view/151080-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to build an interactive application for children that generates new stories based on classic stories. The company wants to use Amazon Bedrock and needs to ensure that the results and topics are appropriate for children.Which AWS service or feature will meet these requirements?",
      "choices": [
        "A. Amazon Rekognition",
        "B. Amazon Bedrock playgrounds",
        "C. Guardrails for Amazon Bedrock",
        "D. Agents for Amazon Bedrock"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Guardrails helps to filter the unnecessary content, and release only appropriate results and topics to the children.",
          "upvotes": 1
        },
        {
          "user": "Taam_diaaz",
          "selected_answer": "C",
          "content": "C is correct",
          "upvotes": 1
        },
        {
          "user": "Taam_diaaz",
          "content": "Guardrails helps detect and block user inputs and FM responses that fall into the restricted topics.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "C",
          "content": "C - Guardrails for Amazon Bedrock provides the necessary tools to ensure that the interactive story-generating application remains safe, appropriate, and engaging for children, making it the best choice for this scenario.",
          "upvotes": 1
        },
        {
          "user": "PHD_CHENG",
          "content": "C is correct",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 55,
      "data_id": "933878",
      "url": "https://www.examtopics.com/discussions/amazon/view/150876-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building an application that needs to generate synthetic data that is based on existing data.Which type of model can the company use to meet this requirement?",
      "choices": [
        "A. Generative adversarial network (GAN)",
        "B. XGBoost",
        "C. Residual neural network",
        "D. WaveNet"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "GANS can do this (A & B can do this task). But, Why can't we use XGBoost to generate the Synthetic data?.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "100% A - GANs are specifically designed to generate synthetic data that closely resembles real data. This aligns perfectly with the company's requirement.",
          "upvotes": 3
        },
        {
          "user": "PHD_CHENG",
          "content": "Agreed with others,  A is correct",
          "upvotes": 1
        },
        {
          "user": "WinnieS",
          "selected_answer": "A",
          "content": "should be A",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "It should be Generative adversarial network (GAN)",
          "upvotes": 1
        },
        {
          "user": "Jack78",
          "content": "Generative Adversarial Network (GAN)",
          "upvotes": 1
        },
        {
          "user": "SolutionArch25",
          "content": "A. Generative adversarial network (GAN)\nCorrect answer. GANs are a type of model specifically designed for generating synthetic data. They consist of two neural networks—a generator and a discriminator—that work together to produce data that mimics the patterns of the original dataset.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 56,
      "data_id": "933879",
      "url": "https://www.examtopics.com/discussions/amazon/view/151047-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A digital devices company wants to predict customer demand for memory hardware. The company does not have coding experience or knowledge of ML algorithms and needs to develop a data-driven predictive model. The company needs to perform analysis on internal data and external data.Which solution will meet these requirements?",
      "choices": [
        "A. Store the data in Amazon S3. Create ML models and demand forecast predictions by using Amazon SageMaker built-in algorithms that use the data from Amazon S3.",
        "B. Import the data into Amazon SageMaker Data Wrangler. Create ML models and demand forecast predictions by using SageMaker built-in algorithms.",
        "C. Import the data into Amazon SageMaker Data Wrangler. Build ML models and demand forecast predictions by using an Amazon Personalize Trending-Now recipe.",
        "D. Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas."
      ],
      "answer": "d",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "D",
          "content": "Amazon SageMaker Canvas supports to build and run the AI solutions without code.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "Amazon SageMaker Canvas is a no-code machine learning service that allows users without coding or ML expertise to build predictive models. It enables the company to import data, perform analysis, and build ML models through an easy-to-use graphical interface. This makes it ideal for businesses with limited technical expertise but a need for data-driven predictions.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "D",
          "content": "D - SageMaker Canvas is designed for users without coding experience or deep knowledge of ML algorithms. It provides a visual interface for building ML models.",
          "upvotes": 3
        },
        {
          "user": "jove",
          "selected_answer": "D",
          "content": "The company does not have coding experience or knowledge of ML  >> Sagemaker Canvas",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 57,
      "data_id": "933880",
      "url": "https://www.examtopics.com/discussions/amazon/view/151142-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has installed a security camera. The company uses an ML model to evaluate the security camera footage for potential thefts. The company has discovered that the model disproportionately flags people who are members of a specific ethnic group.Which type of bias is affecting the model output?",
      "choices": [
        "A. Measurement bias",
        "B. Sampling bias",
        "C. Observer bias",
        "D. Confirmation bias"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Sampling bias\n\nExplanation:\nSampling bias occurs when the training data used for an ML model is not representative of the real-world population. In this case, the model disproportionately flags members of a specific ethnic group, likely because the training dataset was not balanced or representative of all groups. This leads to skewed predictions that unfairly target certain populations.",
          "upvotes": 2
        },
        {
          "user": "RightAnswers",
          "selected_answer": "B",
          "content": "Sampling bias: occurs when the data used to train the ML model is not representative of the overall population, leading to the model performing poorly on certain groups, like in this case where the model is disproportionately flagging people from a specific ethnic group.\nWhy the other options are not correct:\nMeasurement bias:\nThis refers to errors in the way data is collected or measured, which isn't directly related to the ethnic group bias in this scenario.\nObserver bias:\nThis happens when a human observer's personal biases influence their interpretation of data, which isn't applicable here as the model is making the evaluations automatically.\nConfirmation bias:\nThis refers to the tendency to seek out information that confirms existing beliefs, which isn't relevant to the training data used to develop the ML model.",
          "upvotes": 1
        },
        {
          "user": "eesa",
          "selected_answer": "B",
          "content": "B. Sampling bias\nExplanation:\n\nSampling bias occurs when the data used to train a model does not accurately represent the diversity of the population or real-world scenarios the model will encounter. In this case, if the training data for the security camera footage had an overrepresentation or underrepresentation of certain ethnic groups, the model may disproportionately flag members of that group as potential theft suspects. This leads to biased predictions due to imbalanced or unrepresentative training data.",
          "upvotes": 1
        },
        {
          "user": "aws4myself",
          "selected_answer": "A",
          "content": "A. Measurement bias\n\nMeasurement bias occurs when the measurement process itself is flawed, leading to systematic errors. In this case, the model is likely biased due to the way it's trained on data that may not be representative of the entire population. This can lead to the model incorrectly associating certain characteristics with criminal behavior, particularly for individuals from underrepresented groups.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "B",
          "content": "B - Sampling bias occurs when the data used to train a model is not representative of the population or real-world scenarios it's meant to analyze. This leads to skewed results that favor or disfavor certain groups.",
          "upvotes": 4
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 58,
      "data_id": "933881",
      "url": "https://www.examtopics.com/discussions/amazon/view/152501-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building a customer service chatbot. The company wants the chatbot to improve its responses by learning from past interactions and online resources.Which AI learning strategy provides this self-improvement capability?",
      "choices": [
        "A. Supervised learning with a manually curated dataset of good responses and bad responses",
        "B. Reinforcement learning with rewards for positive customer feedback",
        "C. Unsupervised learning to find clusters of similar customer inquiries",
        "D. Supervised learning with a continuously updated FAQ database"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "RightAnswers",
          "selected_answer": "B",
          "content": "Reinforcement learning: is the most suitable strategy for a chatbot to continuously improve its responses based on real-time feedback from users. The chatbot can \"learn\" by receiving positive reinforcement (reward) when it provides a helpful response and negative reinforcement when it doesn't, allowing it to adjust its responses over time to better suit customer needs.\nWhy other options are not suitable:\nA. While this can provide a good initial training set, it wouldn't allow the chatbot to adapt to new situations or customer feedback without manual intervention.\nC. This can be helpful in understanding customer patterns but wouldn't directly improve the chatbot's responses without additional training data or feedback mechanisms.\nD. While updating the FAQ database can be beneficial, it still requires manual effort and wouldn't enable the chatbot to learn from real-time interactions with customers in the same way that reinforcement learning does.",
          "upvotes": 3
        },
        {
          "user": "aws4myself",
          "selected_answer": "B",
          "content": "Reinforcement learning: This method allows the chatbot to learn from the outcomes of its actions, essentially receiving \"rewards\" for positive customer feedback and adjusting its responses accordingly to maximize those rewards in the future.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 59,
      "data_id": "933882",
      "url": "https://www.examtopics.com/discussions/amazon/view/150995-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner has built a deep learning model to classify the types of materials in images. The AI practitioner now wants to measure the model performance.Which metric will help the AI practitioner evaluate the performance of the model?",
      "choices": [
        "A. Confusion matrix",
        "B. Correlation matrix",
        "C. R2 score",
        "D. Mean squared error (MSE)"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "The model is performing a classification task (identifying types of materials), and confusion matrices are specifically designed for evaluating classification models.",
          "upvotes": 2
        },
        {
          "user": "dehkon",
          "content": "A. Confusion matrix\n\nA confusion matrix is a useful metric for evaluating the performance of a classification model. It provides a summary of prediction results on a classification problem, showing the number of correct and incorrect predictions broken down by each class. This helps the AI practitioner understand how well the model is distinguishing between different types of materials in the images.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 60,
      "data_id": "933883",
      "url": "https://www.examtopics.com/discussions/amazon/view/150996-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has built a chatbot that can respond to natural language questions with images. The company wants to ensure that the chatbot does not return inappropriate or unwanted images.Which solution will meet these requirements?",
      "choices": [
        "A. Implement moderation APIs.",
        "B. Retrain the model with a general public dataset.",
        "C. Perform model validation.",
        "D. Automate user feedback integration."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Implement moderation APIs.\n\nExplanation:\nModeration APIs are designed to detect and filter inappropriate or unwanted content, such as images, text, or videos. By integrating moderation APIs into the chatbot workflow, the company can screen and block inappropriate images before they are returned to users. This ensures compliance with ethical standards and avoids exposing users to harmful or unwanted content.",
          "upvotes": 1
        },
        {
          "user": "kyo",
          "selected_answer": "A",
          "content": "Amazon Rekognition moderation APIs can help you automatically identify and filter inappropriate content in images and videos, reducing the need for manual human review. This can significantly improve efficiency and reduce costs while maintaining high standards of content moderation. For details, please refer to the following document:\nhttps://docs.aws.amazon.com/rekognition/latest/dg/moderation.html",
          "upvotes": 2
        },
        {
          "user": "jove",
          "selected_answer": "A",
          "content": "Moderation APIs are designed to filter and flag inappropriate or unwanted content, ensuring that the chatbot does not return harmful or unsuitable images. These APIs can scan images before they are returned to the user and block or flag any content that violates the company’s guidelines.",
          "upvotes": 2
        },
        {
          "user": "dehkon",
          "content": "A. Implement moderation APIs.\n\nModeration APIs can help filter out inappropriate or unwanted images by analyzing and moderating content before it is returned to users. This ensures that the chatbot maintains safe and appropriate interactions, reducing the risk of inappropriate images being shown.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 61,
      "data_id": "933884",
      "url": "https://www.examtopics.com/discussions/amazon/view/151144-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner is using an Amazon Bedrock base model to summarize session chats from the customer service department. The AI practitioner wants to store invocation logs to monitor model input and output data.Which strategy should the AI practitioner use?",
      "choices": [
        "A. Configure AWS CloudTrail as the logs destination for the model.",
        "B. Enable invocation logging in Amazon Bedrock.",
        "C. Configure AWS Audit Manager as the logs destination for the model.",
        "D. Configure model invocation logging in Amazon EventBridge."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Enable invocation logging in Amazon Bedrock.\n\nExplanation:\nAmazon Bedrock provides the ability to log model invocations, including input and output data, for monitoring and troubleshooting purposes. By enabling invocation logging in Amazon Bedrock, the AI practitioner can store logs securely and use them to analyze model behavior and performance.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "B",
          "content": "B - The question mentions using an Amazon Bedrock base model, and invocation logging is a feature specifically designed for Amazon Bedrock.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 62,
      "data_id": "933885",
      "url": "https://www.examtopics.com/discussions/amazon/view/151124-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building an ML model to analyze archived data. The company must perform inference on large datasets that are multiple GBs in size. The company does not need to access the model predictions immediately.Which Amazon SageMaker inference option will meet these requirements?",
      "choices": [
        "A. Batch transform",
        "B. Real-time inference",
        "C. Serverless inference",
        "D. Asynchronous inference"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "ExamTopicsPrepare",
          "selected_answer": "A",
          "content": "A. Batch transform ✅\n\nExplanation:\nBatch Transform is ideal for processing large datasets in bulk when immediate responses are not needed.\nIt supports multiple GB-sized datasets and can handle inference without requiring an endpoint to be always active.\nSince the company is working with archived data and does not need real-time predictions, batch processing is the most efficient and cost-effective choice.",
          "upvotes": 1
        },
        {
          "user": "viejito",
          "selected_answer": "D",
          "content": "asynchronous inference is the most appropriate choice for the company's specific needs, as it provides a balance between processing large datasets and not requiring immediate results.",
          "upvotes": 2
        },
        {
          "user": "djeong95",
          "content": "Amazon SageMaker Asynchronous Inference is a capability in SageMaker AI that queues incoming requests and processes them asynchronously. This option is ideal for requests with large payload sizes (up to 1GB), long processing times (up to one hour), and near real-time latency requirements. Asynchronous Inference enables you to save on costs by autoscaling the instance count to zero when there are no requests to process, so you only pay when your endpoint is processing requests. \n\nA is more suitable here.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "Batch transform is specifically designed to handle large volumes of data, including datasets that are multiple GBs in size. This aligns perfectly with the company's requirement to perform inference on large datasets.",
          "upvotes": 3
        },
        {
          "user": "GriffXX",
          "selected_answer": "A",
          "content": "Info on Batch Transform matches up with the details of 'large datsets' and 'don't need projections immediately. https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 63,
      "data_id": "933886",
      "url": "https://www.examtopics.com/discussions/amazon/view/151750-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which term describes the numerical representations of real-world objects and concepts that AI and natural language processing (NLP) models use to improve understanding of textual information?",
      "choices": [
        "A. Embeddings",
        "B. Tokens",
        "C. Models",
        "D. Binaries"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "A. Embeddings\n\nExplanation:\nEmbeddings are numerical representations of real-world objects, words, phrases, or concepts in a continuous vector space. They enable AI and Natural Language Processing (NLP) models to understand and process textual information by capturing the semantic relationships and contextual meanings of words and phrases.",
          "upvotes": 2
        },
        {
          "user": "eesa",
          "content": "Explanation:\n\n    Embeddings are numerical representations of real-world objects, concepts, or textual data. In AI and NLP, embeddings map words, phrases, or even entire documents to a high-dimensional vector space. This allows models to capture semantic relationships and improve understanding of the textual information",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 64,
      "data_id": "933887",
      "url": "https://www.examtopics.com/discussions/amazon/view/151048-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A research company implemented a chatbot by using a foundation model (FM) from Amazon Bedrock. The chatbot searches for answers to questions from a large database of research papers.After multiple prompt engineering attempts, the company notices that the FM is performing poorly because of the complex scientific terms in the research papers.How can the company improve the performance of the chatbot?",
      "choices": [
        "A. Use few-shot prompting to define how the FM can answer the questions.",
        "B. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.",
        "C. Change the FM inference parameters.",
        "D. Clean the research paper data to remove complex scientific terms."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "Domain Adaptation fine-tuning helps for industry-specific terminology based solutions.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "Answer:\nB. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.\n\nExplanation:\nDomain Adaptation Fine-Tuning involves training the foundation model (FM) further on domain-specific data—in this case, complex scientific terms and research papers. This process helps the model better understand and accurately respond to specialized language and concepts, thereby improving the chatbot's performance in handling intricate scientific queries.",
          "upvotes": 1
        },
        {
          "user": "CTao",
          "selected_answer": "B",
          "content": "B. “After multiple prompt engineering attempts” means few-shot prompt has tried or? So A is not the correct one.",
          "upvotes": 2
        },
        {
          "user": "PHD_CHENG",
          "selected_answer": "A",
          "content": "A is correct",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "Domain adaptation fine-tuning allows you to fine-tune the foundation model (FM) on a dataset that includes examples of the specific domain, in this case, scientific papers with complex terms. This way, the model can better understand and handle the specialized terminology, improving its accuracy when answering domain-specific questions.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 65,
      "data_id": "933888",
      "url": "https://www.examtopics.com/discussions/amazon/view/150997-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company needs the LLM to produce more consistent responses to the same input prompt.Which adjustment to an inference parameter should the company make to meet these requirements?",
      "choices": [
        "A. Decrease the temperature value.",
        "B. Increase the temperature value.",
        "C. Decrease the length of output tokens.",
        "D. Increase the maximum generation length."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "Lowering the temperature value in an LLM controls the randomness of the model's output. A lower temperature (close to 0) makes the model's predictions more deterministic and consistent, leading to similar outputs for identical prompts. This is particularly beneficial in tasks like sentiment analysis, where consistency and reliability in responses are crucial.",
          "upvotes": 2
        },
        {
          "user": "dehkon",
          "content": "A. Decrease the temperature value.\n\nLowering the temperature value reduces the randomness of predictions from a large language model (LLM) and makes the output more deterministic and consistent. This is ideal for producing consistent responses to the same input prompt during sentiment analysis.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 66,
      "data_id": "933889",
      "url": "https://www.examtopics.com/discussions/amazon/view/151076-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to develop a large language model (LLM) application by using Amazon Bedrock and customer data that is uploaded to Amazon S3. The company's security policy states that each team can access data for only the team's own customers.Which solution will meet these requirements?",
      "choices": [
        "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
        "B. Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request.",
        "C. Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data.",
        "D. Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.\n\nExplanation:\nTo comply with the company's security policy requiring each team to access only their own customer data, the best approach is to create custom service roles in Amazon Bedrock for each team. These roles should have fine-grained permissions, granting access only to the specific Amazon S3 data (e.g., folders or buckets) associated with each team's customers. This ensures compliance with the principle of least privilege.\n\nWrong: D. Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders: Giving Bedrock full S3 access is a major security risk. Even with team-specific IAM roles, the Bedrock role could be exploited to access any data in S3.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Custom service roles for each team provide granular control over customer data access.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
          "upvotes": 1
        },
        {
          "user": "Contactfornitish",
          "selected_answer": "D",
          "content": "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data\nWhile this restricts data access, managing multiple service roles for Amazon Bedrock per team is unnecessarily complex and does not align with Bedrock’s design of using a single service role.\n\nB. Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request\nRelying on teams to specify the customer name without enforcing access control policies does not guarantee compliance with the security policy.\n\nC. Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data\nRedacting personal data is helpful for privacy but does not solve the issue of restricting access based on team-specific customer data.",
          "upvotes": 3
        },
        {
          "user": "fed6485",
          "selected_answer": "A",
          "content": "it has to be A.\nB, absurd\nC, would let all teams access all data, even if scrubbed/redacted ..\nD, it would not solve the problem as Bedrock would have access, know and reply with the full knowledge of all customers, IAM roles for each team won't stop Bedrock from knowing and replying with that data.. \n\nA. \nYou can also create a custom service role and customize the attached permissions to your specific use-case. If you use the console, you can select this role instead of letting Amazon Bedrock create one for you.\n\n\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam-sr.html",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "A",
          "content": "Adherence to Principle of Least Privilege: By creating a custom service role for each team that grants access only to their specific customer data in S3, you ensure compliance with the principle of least privilege. Each team will have the minimum necessary permissions to access only their relevant data. D is wrong.",
          "upvotes": 1
        },
        {
          "user": "taka5094",
          "selected_answer": "A",
          "content": "Creating a Bedrock role with access to all S3 data violates the principle of least privilege.",
          "upvotes": 2
        },
        {
          "user": "jove",
          "content": "I think it should be D, one IAM role for the service, and multiple IAM roles for the teams",
          "upvotes": 3
        },
        {
          "user": "urbanmonk",
          "content": "D makes sense on the surface but it talks about distinct customer's folders 📂 , which was not mentioned in the question. And granting Bedrock Full S3 access is certainly a huge red flag. So the answer cannot be D. That leaves \"A\" as the only plausible solution and answer.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 67,
      "data_id": "933890",
      "url": "https://www.examtopics.com/discussions/amazon/view/151077-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A medical company deployed a disease detection model on Amazon Bedrock. To comply with privacy policies, the company wants to prevent the model from including personal patient information in its responses. The company also wants to receive notification when policy violations occur.Which solution meets these requirements?",
      "choices": [
        "A. Use Amazon Macie to scan the model's output for sensitive data and set up alerts for potential violations.",
        "B. Configure AWS CloudTrail to monitor the model's responses and create alerts for any detected personal information.",
        "C. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.",
        "D. Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.\n\nExplanation:\nGuardrails for Amazon Bedrock allow you to enforce policies that filter out sensitive or inappropriate content, such as personal patient information, from the model's responses. By configuring these guardrails, you ensure that the model adheres to privacy policies. Additionally, you can set up Amazon CloudWatch alarms to receive notifications when policy violations occur, providing real-time monitoring and alerting.",
          "upvotes": 1
        },
        {
          "user": "Gianiluca",
          "selected_answer": "C",
          "content": "C. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.\n\nReasoning:\nRequirement:\n\nThe company wants to ensure that the disease detection model does not include personal patient information in its responses. This requires a mechanism to filter sensitive information from the model's outputs.\nThey also need a notification system for policy violations.\nSolution:\n\nGuardrails for Amazon Bedrock provide built-in content moderation and filtering mechanisms to enforce compliance with policies, such as removing personal information from model outputs.\nAmazon CloudWatch Alarms can be used to monitor events or logs (such as detected policy violations) and send notifications when violations occur.",
          "upvotes": 1
        },
        {
          "user": "fed6485",
          "content": "if the answer A was slightly different.. \n\nA. Use Amazon Macie to scan the model's DATA for sensitive data and set up alerts for potential violations.\ninstead of\nA. Use Amazon Macie to scan the model's OUTPUT for sensitive data and set up alerts for potential violations.\n\n\nas Macie cannot scan the output.. but the data in S3, so A is incorrect.. so C, even if, personal information should always be removed, no point of train on it.",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "C",
          "content": "Guardrails to prevent, CloudWatch to notify",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 68,
      "data_id": "933891",
      "url": "https://www.examtopics.com/discussions/amazon/view/151354-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company manually reviews all submitted resumes in PDF format. As the company grows, the company expects the volume of resumes to exceed the company's review capacity. The company needs an automated system to convert the PDF resumes into plain text format for additional processing.Which AWS service meets this requirement?",
      "choices": [
        "A. Amazon Textract",
        "B. Amazon Personalize",
        "C. Amazon Lex",
        "D. Amazon Transcribe"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "eesa",
          "content": "Amazon Textract is designed to extract text, handwriting, and structured data (like tables and forms) from documents such as PDFs. It is ideal for automating the conversion of resumes into plain text format for further processing.",
          "upvotes": 1
        },
        {
          "user": "tgv",
          "selected_answer": "A",
          "content": "Amazon Textract is specifically designed to extract text and structured data from various types of documents, including PDFs. It can efficiently convert resumes from PDF format into plain text for further processing, even if the text is embedded in tables or forms.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 69,
      "data_id": "933892",
      "url": "https://www.examtopics.com/discussions/amazon/view/151078-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An education provider is building a question and answer application that uses a generative AI model to explain complex concepts. The education provider wants to automatically change the style of the model response depending on who is asking the question. The education provider will give the model the age range of the user who has asked the question.Which solution meets these requirements with the LEAST implementation effort?",
      "choices": [
        "A. Fine-tune the model by using additional training data that is representative of the various age ranges that the application will support.",
        "B. Add a role description to the prompt context that instructs the model of the age range that the response should target.",
        "C. Use chain-of-thought reasoning to deduce the correct style and complexity for a response suitable for that user.",
        "D. Summarize the response text depending on the age of the user so that younger users receive shorter responses."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Blair77",
          "selected_answer": "B",
          "content": "Adding a role description to the prompt is a straightforward approach that requires minimal changes to the existing model infrastructure. This method leverages prompt engineering, which is often easier and faster to implement than fine-tuning or retraining a model.",
          "upvotes": 5
        },
        {
          "user": "jove",
          "selected_answer": "B",
          "content": "B ) Use prompt engineering",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 70,
      "data_id": "933893",
      "url": "https://www.examtopics.com/discussions/amazon/view/151147-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which strategy evaluates the accuracy of a foundation model (FM) that is used in image classification tasks?",
      "choices": [
        "A. Calculate the total cost of resources used by the model.",
        "B. Measure the model's accuracy against a predefined benchmark dataset.",
        "C. Count the number of layers in the neural network.",
        "D. Assess the color accuracy of images processed by the model."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Gianiluca",
          "selected_answer": "B",
          "content": "B. Measure the model's accuracy against a predefined benchmark dataset.\n\nReasoning:\nAccuracy in Image Classification:\n\nThe standard way to evaluate the accuracy of a foundation model in image classification tasks is to compare the model's predictions against the ground truth labels in a predefined benchmark dataset. This ensures consistency and reliability in performance evaluation.\nBenchmark Dataset:\n\nA benchmark dataset contains labelled images that serve as a standard for evaluating the performance of image classification models. Examples include ImageNet, CIFAR-10, or MNIST, depending on the task and complexity.\nEvaluation Metrics:\n\nMetrics such as accuracy, precision, recall, and F1 score are typically calculated using the predictions and ground truth labels in the benchmark dataset.",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "B",
          "content": "B is good",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 71,
      "data_id": "933894",
      "url": "https://www.examtopics.com/discussions/amazon/view/151079-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An accounting firm wants to implement a large language model (LLM) to automate document processing. The firm must proceed responsibly to avoid potential harms.What should the firm do when developing and deploying the LLM? (Choose two.)",
      "choices": [
        "A. Include fairness metrics for model evaluation.",
        "B. Adjust the temperature parameter of the model.",
        "C. Modify the training data to mitigate bias.",
        "D. Avoid overfitting on the training data.",
        "E. Apply prompt engineering techniques."
      ],
      "answer": "ac",
      "comments": [
        {
          "user": "dspd",
          "selected_answer": "AC",
          "content": "A: Include fairness metrics for model evaluation\nCritical for responsible AI implementation\nHelps identify discriminatory patterns\nEnsures equitable treatment across different groups\nAllows for continuous monitoring of fairness\nEssential for an accounting firm handling sensitive financial data\n\nC: Modify the training data to mitigate bias\nAddresses bias at the source\nEnsures representative training data\nHelps prevent discriminatory outcomes\nCritical for fair treatment of all clients\nFundamental to responsible AI development",
          "upvotes": 1
        },
        {
          "user": "KawtarZ",
          "selected_answer": "BE",
          "content": "A. no need for fairness metrics as the use case is for document processing\nC. modifying the training data means there is a re-training of the model. not needed for this use case\nD. there is no re-training needed for this case. avoiding overfitting is also not needed",
          "upvotes": 1
        },
        {
          "user": "jove",
          "selected_answer": "AC",
          "content": "A. Include fairness metrics for model evaluation: Fairness metrics help ensure that the model is not biased against any particular group. This is especially important in fields like accounting, where any biases in automated decisions could lead to unethical outcomes. Fairness metrics provide insight into how well the model treats all data groups equally.\n\nC. Modify the training data to mitigate bias: Adjusting the training data to address any identified biases is crucial for developing responsible AI applications. This can involve balancing the dataset or removing biased samples, ensuring the model generalizes fairly across different data types and groups.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 72,
      "data_id": "933895",
      "url": "https://www.examtopics.com/discussions/amazon/view/150982-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building an ML model. The company collected new data and analyzed the data by creating a correlation matrix, calculating statistics, and visualizing the data.Which stage of the ML pipeline is the company currently in?",
      "choices": [
        "A. Data pre-processing",
        "B. Feature engineering",
        "C. Exploratory data analysis",
        "D. Hyperparameter tuning"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Exploratory data analysis\n\nExplanation:\nExploratory Data Analysis (EDA) involves examining and summarizing data to understand its underlying structure, detect patterns, identify relationships (e.g., via a correlation matrix), and highlight any anomalies. The company's activities, such as creating a correlation matrix, calculating statistics, and visualizing the data, are typical tasks performed during EDA.\n\nWhy not the other options?\nA: Data pre-processing:\nData pre-processing involves cleaning and preparing data for modeling, such as handling missing values, scaling features, or encoding categorical data. While pre-processing may follow EDA, the tasks described in the question focus on analysis rather than preparation.",
          "upvotes": 2
        },
        {
          "user": "dehkon",
          "content": "C. Exploratory data analysis\n\nExploratory Data Analysis (EDA) involves examining and visualizing data to understand its structure, patterns, and relationships. Creating a correlation matrix, calculating statistics, and visualizing data are all typical tasks during the EDA phase, which helps inform later stages such as data preprocessing and feature engineering.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 73,
      "data_id": "933896",
      "url": "https://www.examtopics.com/discussions/amazon/view/150983-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has documents that are missing some words because of a database error. The company wants to build an ML model that can suggest potential words to fill in the missing text.Which type of model meets this requirement?",
      "choices": [
        "A. Topic modeling",
        "B. Clustering models",
        "C. Prescriptive ML models",
        "D. BERT-based models"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "dehkon",
          "content": "BERT (Bidirectional Encoder Representations from Transformers) is a language model designed to understand context in text by considering both the left and right sides of a word. BERT-based models are well-suited for filling in missing words in sentences due to their ability to predict masked words in a given text. This makes them ideal for tasks that require filling in missing information within text data.",
          "upvotes": 7
        },
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "**Answer: D. BERT-based models**\n\nBERT (Bidirectional Encoder Representations from Transformers) uses a **masked language modeling** approach. It learns how to predict missing or “masked” words in a sentence based on the surrounding context. This makes a BERT-based model ideal for suggesting potential words to fill in missing text.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 74,
      "data_id": "933897",
      "url": "https://www.examtopics.com/discussions/amazon/view/151150-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to display the total sales for its top-selling products across various retail locations in the past 12 months.Which AWS solution should the company use to automate the generation of graphs?",
      "choices": [
        "A. Amazon Q in Amazon EC2",
        "B. Amazon Q Developer",
        "C. Amazon Q in Amazon QuickSight",
        "D. Amazon Q in AWS Chatbot"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C. Amazon Q in Amazon QuickSight: This is the correct answer. Amazon QuickSight is a cloud-based BI service that allows you to create interactive dashboards and visualizations, including graphs, from various data sources. Integrating with Amazon Q enables natural language querying to generate these visualizations more easily",
          "upvotes": 1
        },
        {
          "user": "PHD_CHENG",
          "content": "Correct answer is C.  Quicksight can generate the visual chart for visualization",
          "upvotes": 1
        },
        {
          "user": "Blair77",
          "selected_answer": "C",
          "content": "Amazon Q is a feature within Amazon QuickSight that allows users to ask questions about their data in natural language and receive visualizations as responses. This functionality is particularly useful for generating graphs and visualizations based on specific queries regarding sales data.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 75,
      "data_id": "933898",
      "url": "https://www.examtopics.com/discussions/amazon/view/151658-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building a chatbot to improve user experience. The company is using a large language model (LLM) from Amazon Bedrock for intent detection. The company wants to use few-shot learning to improve intent detection accuracy.Which additional data does the company need to meet these requirements?",
      "choices": [
        "A. Pairs of chatbot responses and correct user intents",
        "B. Pairs of user messages and correct chatbot responses",
        "C. Pairs of user messages and correct user intents",
        "D. Pairs of user intents and correct chatbot responses"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "AzureDP900",
          "selected_answer": "C",
          "content": "C. Pairs of user messages and correct user intents\nFew-shot learning is a machine learning technique that allows the model to learn from small amounts of data, including labeled examples or \"shots.\" In this case, the company wants to use few-shot learning to improve intent detection accuracy.\nTo implement few-shot learning for intent detection, the company needs additional data in the form of pairs of user messages and their corresponding correct user intents. This data will serve as the \"shooting\" examples that the LLM can learn from.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "C. Pairs of user messages and correct user intents\n\nExplanation:\nFew-shot learning involves training a model with a small number of examples (or samples). In this case, the goal is to improve intent detection, which requires a clear understanding of the user's intent based on their message. To fine-tune the large language model (LLM) using few-shot learning, the model needs examples of user messages along with their corresponding correct user intents. These pairs will teach the model how to accurately classify user intents based on input messages.",
          "upvotes": 1
        },
        {
          "user": "PHD_CHENG",
          "selected_answer": "C",
          "content": "C is correct answer",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 76,
      "data_id": "933899",
      "url": "https://www.examtopics.com/discussions/amazon/view/151151-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using few-shot prompting on a base model that is hosted on Amazon Bedrock. The model currently uses 10 examples in the prompt. The model is invoked once daily and is performing well. The company wants to lower the monthly cost.Which solution will meet these requirements?",
      "choices": [
        "A. Customize the model by using fine-tuning.",
        "B. Decrease the number of tokens in the prompt.",
        "C. Increase the number of tokens in the prompt.",
        "D. Use Provisioned Throughput."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Blair77",
          "selected_answer": "B",
          "content": "Bedrock pricing is based on the number of tokens processed, which includes both input tokens (from the prompt) and output tokens (generated by the model). By decreasing the number of tokens in the prompt, you directly reduce the cost associated with each invocation of the model.",
          "upvotes": 6
        },
        {
          "user": "AzureDP900",
          "selected_answer": "D",
          "content": "D. Use Provisioned Throughput\n\nTo lower the monthly cost, the company can use Provisioned Throughput (PT) to scale their model's resource utilization. This allows them to pay only for the actual compute time used by the model, rather than paying a fixed monthly fee.",
          "upvotes": 1
        },
        {
          "user": "djeong95",
          "content": "you are right to point this out but B is a more correct answer. There is a limit as to how much you can save with Provisioned Throughput (given that you were using On Demand before and that the company is okay with a longer term commitment). However, Decrease the number of tokens in the prompt is going to be more effective and doesn't require a longer term commitment.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 77,
      "data_id": "933900",
      "url": "https://www.examtopics.com/discussions/amazon/view/151856-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner is using a large language model (LLM) to create content for marketing campaigns. The generated content sounds plausible and factual but is incorrect.Which problem is the LLM having?",
      "choices": [
        "A. Data leakage",
        "B. Hallucination",
        "C. Overfitting",
        "D. Underfitting"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "AzureDP900",
          "selected_answer": "B",
          "content": "Hallucination is a phenomenon in which an LLM generates text that sounds plausible and factual but is actually incorrect or nonsensical. This occurs when the model is overconfident in its ability to generate coherent text based on patterns it has learned from training data.",
          "upvotes": 2
        },
        {
          "user": "L1234567890",
          "selected_answer": "B",
          "content": "Hallucination",
          "upvotes": 2
        },
        {
          "user": "L1234567890",
          "content": "B. Hallucination is the right answer",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 78,
      "data_id": "933901",
      "url": "https://www.examtopics.com/discussions/amazon/view/152544-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner trained a custom model on Amazon Bedrock by using a training dataset that contains confidential data. The AI practitioner wants to ensure that the custom model does not generate inference responses based on confidential data.How should the AI practitioner prevent responses based on confidential data?",
      "choices": [
        "A. Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.",
        "B. Mask the confidential data in the inference responses by using dynamic data masking.",
        "C. Encrypt the confidential data in the inference responses by using Amazon SageMaker.",
        "D. Encrypt the confidential data in the custom model by using AWS Key Management Service (AWS KMS)."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.\n\nExplanation:\nIf the training dataset contains confidential data, the model may inadvertently learn and generate responses based on that data. The only way to ensure that the model does not generate responses based on the confidential data is to:\n\nRemove the confidential data from the training dataset.\nRetrain the custom model using the updated dataset.\nThis process ensures that the model is not influenced by the sensitive information.",
          "upvotes": 3
        },
        {
          "user": "BhaskarSadineni",
          "selected_answer": "A",
          "content": "Explanation:\nOnce a model is trained, the data used for training is embedded in its parameters. If confidential data is included in the training dataset, it can influence the responses the model generates.\nSimply masking or encrypting inference responses will not ensure the model doesn’t generate responses derived from the confidential data; the issue originates in the training process itself.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Once a model is trained on confidential data, it must be retrained without it.",
          "upvotes": 1
        },
        {
          "user": "AKG85",
          "selected_answer": "A",
          "content": "Delete the custom model, remove the confidential data, and retrain the model is the best approach because it ensures that the model will not retain or generate responses based on any confidential information",
          "upvotes": 2
        },
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "Once a model is trained on data, its outputs may inherently reflect patterns or details derived from the training dataset, including confidential data.\nTo ensure the custom model does not generate inference responses based on confidential data, the only reliable solution is to:\n- Remove the confidential data from the training dataset.\n- Retrain the model with the updated dataset.\n\nThis approach ensures the model is not influenced by sensitive information during inference.\n\nOption B is incorrect. \n\nDynamic data masking hides sensitive information in database query results or outputs but does not prevent the model from generating responses influenced by the confidential data. The model would still \"know\" the sensitive patterns.",
          "upvotes": 2
        },
        {
          "user": "Dandelion2025",
          "selected_answer": "B",
          "content": "The company should mask the confidential information",
          "upvotes": 2
        },
        {
          "user": "Amitst",
          "selected_answer": "B",
          "content": "This is the most efficient method, effectively maintaining data privacy and security.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 79,
      "data_id": "933902",
      "url": "https://www.examtopics.com/discussions/amazon/view/152546-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has built a solution by using generative AI. The solution uses large language models (LLMs) to translate training manuals from English into other languages. The company wants to evaluate the accuracy of the solution by examining the text generated for the manuals.Which model evaluation strategy meets these requirements?",
      "choices": [
        "A. Bilingual Evaluation Understudy (BLEU)",
        "B. Root mean squared error (RMSE)",
        "C. Recall-Oriented Understudy for Gisting Evaluation (ROUGE)",
        "D. F1 score"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A. Bilingual Evaluation Understudy (BLEU): This is the correct answer. BLEU is a common metric for evaluating machine translation quality. It compares the generated text to one or more reference translations and measures the n-gram overlap.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. BLEU is specifically designed to evaluate machine translation quality.",
          "upvotes": 1
        },
        {
          "user": "Dandelion2025",
          "selected_answer": "A",
          "content": "BLEU is specifically designed to measure the quality of machine translations by comparing them to human-created reference translations",
          "upvotes": 2
        },
        {
          "user": "aws4myself",
          "selected_answer": "C",
          "content": "C. Recall-Oriented Understudy for Gisting Evaluation (ROUGE)\n\nROUGE is a popular metric for evaluating the quality of text summarization and machine translation systems. It focuses on recall, measuring how well the generated text covers the relevant information from the reference text. In this case, ROUGE can be used to assess how accurately the LLM-generated translations capture the meaning and content of the original English manuals.",
          "upvotes": 1
        },
        {
          "user": "Amitst",
          "selected_answer": "A",
          "content": "BLEU (bilingual evaluation understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 80,
      "data_id": "933903",
      "url": "https://www.examtopics.com/discussions/amazon/view/151660-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A large retailer receives thousands of customer support inquiries about products every day. The customer support inquiries need to be processed and responded to quickly. The company wants to implement Agents for Amazon Bedrock.What are the key benefits of using Amazon Bedrock agents that could help this retailer?",
      "choices": [
        "A. Generation of custom foundation models (FMs) to predict customer needs",
        "B. Automation of repetitive tasks and orchestration of complex workflows",
        "C. Automatically calling multiple foundation models (FMs) and consolidating the results",
        "D. Selecting the foundation model (FM) based on predefined criteria and metrics"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "taka5094",
          "selected_answer": "B",
          "content": "B. Main advantage of using Amazon Bedrock Agent is the automation of repetitive tasks and the orchestration of complex workflows. Customer support inquiries are often patterned and repetitive. By using Amazon Bedrock Agent, you can automate the initial response to such routine inquiries and information gathering. In addition, even in cases where the workflow is somewhat complex and the response required varies depending on the inquiry content, Amazon Bedrock can flexibly respond by combining multiple AI models. This will enable quick and accurate customer support while optimally utilizing human resources. It will lead to efficient processing of large volumes of inquiries, which will lead to improved customer satisfaction.",
          "upvotes": 7
        },
        {
          "user": "kopper2019",
          "selected_answer": "B",
          "content": "Amazon Bedrock agents are specifically designed to automate tasks and orchestrate workflows\nThey can handle repetitive customer support inquiries efficiently\nThey can break down complex customer requests into smaller steps and execute them in sequence\nThis directly addresses the retailer's need to process thousands of inquiries quickly",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Agents for Amazon Bedrock automate repetitive tasks and orchestrate complex workflows.",
          "upvotes": 1
        },
        {
          "user": "Contactfornitish",
          "selected_answer": "C",
          "content": "A. Generation of custom foundation models (FMs) to predict customer needs\nWhile creating custom FMs could be valuable for tailored predictions, Amazon Bedrock agents themselves focus on automating workflows and orchestrating the use of multiple FMs, rather than creating custom models.\n\nB. Automation of repetitive tasks and orchestration of complex workflows\nThis is a strong benefit of Amazon Bedrock agents, but option C more directly addresses the use case of consolidating results from multiple FMs to handle customer inquiries.\n\nD. Selecting the foundation model (FM) based on predefined criteria and metrics\nWhile selecting models based on criteria is possible, the primary strength of Bedrock agents in this context is in automating the calling of multiple models and consolidating their responses.",
          "upvotes": 1
        },
        {
          "user": "leo321",
          "selected_answer": "B",
          "content": "Amazon Bedrock Agents\nEnable generative AI applications to execute multistep tasks across company systems and data sources\nAmazon Bedrock Agents streamline workflows and automate repetitive tasks. Unleash the power of AI automation to boost productivity and reduce cost.\nhttps://aws.amazon.com/bedrock/agents/",
          "upvotes": 2
        },
        {
          "user": "PHD_CHENG",
          "selected_answer": "C",
          "content": "C is correct answer.  Repetitive task may not work on customer support inquiry as each inquiry is different.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 81,
      "data_id": "933904",
      "url": "https://www.examtopics.com/discussions/amazon/view/152545-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which option is a benefit of ongoing pre-training when fine-tuning a foundation model (FM)?",
      "choices": [
        "A. Helps decrease the model's complexity",
        "B. Improves model performance over time",
        "C. Decreases the training time requirement",
        "D. Optimizes model inference time"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Ongoing pre-training improves model performance over time by allowing the model to adapt to new data and tasks.",
          "upvotes": 2
        },
        {
          "user": "Amitst",
          "selected_answer": "B",
          "content": "Ongoing pre-training helps the model continuously learn and improve its performance over time. This is the whole point of fine-tuning a foundation model",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 82,
      "data_id": "933905",
      "url": "https://www.examtopics.com/discussions/amazon/view/151661-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "What are tokens in the context of generative AI models?",
      "choices": [
        "A. Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
        "B. Tokens are the mathematical representations of words or concepts used in generative AI models.",
        "C. Tokens are the pre-trained weights of a generative AI model that are fine-tuned for specific tasks.",
        "D. Tokens are the specific prompts or instructions given to a generative AI model to generate output."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "PHD_CHENG",
          "selected_answer": "A",
          "content": "A is correct",
          "upvotes": 6
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 83,
      "data_id": "933906",
      "url": "https://www.examtopics.com/discussions/amazon/view/151662-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to assess the costs that are associated with using a large language model (LLM) to generate inferences. The company wants to use Amazon Bedrock to build generative AI applications.Which factor will drive the inference costs?",
      "choices": [
        "A. Number of tokens consumed",
        "B. Temperature value",
        "C. Amount of data used to train the LLM",
        "D. Total training time"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "OnePG",
          "selected_answer": "A",
          "content": "A. Number of tokens consumed. More tokens used = higher cost. \n\nAll other affects training costs, not inference costs. Correct answer is A",
          "upvotes": 1
        },
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "No. of tokens consumed while processing.  Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
          "upvotes": 1
        },
        {
          "user": "PHD_CHENG",
          "selected_answer": "A",
          "content": "A is correct.  Token is the basic unit of generative AI model",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 84,
      "data_id": "933907",
      "url": "https://www.examtopics.com/discussions/amazon/view/152547-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using Amazon SageMaker Studio notebooks to build and train ML models. The company stores the data in an Amazon S3 bucket. The company needs to manage the flow of data from Amazon S3 to SageMaker Studio notebooks.Which solution will meet this requirement?",
      "choices": [
        "A. Use Amazon Inspector to monitor SageMaker Studio.",
        "B. Use Amazon Macie to monitor SageMaker Studio.",
        "C. Configure SageMaker to use a VPC with an S3 endpoint.",
        "D. Configure SageMaker to use S3 Glacier Deep Archive."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Deploy and run the Amazon SageMaker Studio on VPC and Connect to S3 using S3 Gateway endpoint.",
          "upvotes": 2
        },
        {
          "user": "Amitst",
          "selected_answer": "C",
          "content": "C. Configure SageMaker to use a VPC with an S3 endpoint.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 85,
      "data_id": "933908",
      "url": "https://www.examtopics.com/discussions/amazon/view/151663-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has a foundation model (FM) that was customized by using Amazon Bedrock to answer customer queries about products. The company wants to validate the model's responses to new types of queries. The company needs to upload a new dataset that Amazon Bedrock can use for validation.Which AWS service meets these requirements?",
      "choices": [
        "A. Amazon S3",
        "B. Amazon Elastic Block Store (Amazon EBS)",
        "C. Amazon Elastic File System (Amazon EFS)",
        "D. AWS Snowcone"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "A",
          "content": "Amazon S3 is the best option for storing (Object Storage) the datasets that Amazon Bedrock uses for customer queries.",
          "upvotes": 2
        },
        {
          "user": "PHD_CHENG",
          "selected_answer": "A",
          "content": "A is correct",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 86,
      "data_id": "936849",
      "url": "https://www.examtopics.com/discussions/amazon/view/153534-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which prompting attack directly exposes the configured behavior of a large language model (LLM)?",
      "choices": [
        "A. Prompted persona switches",
        "B. Exploiting friendliness and trust",
        "C. Ignoring the prompt template",
        "D. Extracting the prompt template"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "dspd",
          "selected_answer": "D",
          "content": "D. Extracting the prompt template",
          "upvotes": 1
        },
        {
          "user": "AzureDP900",
          "selected_answer": "B",
          "content": "B. Exploiting friendliness and trust\nExploiting friendliness and trust involves manipulating the LLM to respond in a way that appears friendly or trustworthy, potentially causing it to deviate from its intended behavior. This type of attack directly exposes how the LLM has been configured to interact with users, often leading it to provide information or make decisions that align more closely with the attacker's intentions rather than its original programming.",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "D: Extracting the prompt template\n\nExplanation:\nExtracting the prompt template is a prompting attack where an attacker intentionally crafts inputs to reveal the underlying configuration or instructions (prompt template) used to guide the large language model (LLM). This exposes the internal behavior or design of the model, potentially revealing sensitive or proprietary information about how the LLM is configured.\n\nWhy not the other options?\nA: Prompted persona switches:\nThis attack involves manipulating the LLM to adopt a different persona or role than intended but does not directly expose the prompt template.",
          "upvotes": 2
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "D",
          "content": "D. Extracting the prompt template\n\nExplanation:\nExtracting the prompt template is a prompting attack where the attacker directly attempts to reveal the underlying configured behavior or instructions of the large language model (LLM). This can expose sensitive configurations, system instructions, or contextual prompts that guide the model's behavior.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 87,
      "data_id": "936850",
      "url": "https://www.examtopics.com/discussions/amazon/view/153535-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use Amazon Bedrock. The company needs to review which security aspects the company is responsible for when using Amazon Bedrock.Which security aspect will the company be responsible for?",
      "choices": [
        "A. Patching and updating the versions of Amazon Bedrock",
        "B. Protecting the infrastructure that hosts Amazon Bedrock",
        "C. Securing the company's data in transit and at rest",
        "D. Provisioning Amazon Bedrock within the company network"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "Encrypting the company's data In-TRANSIT and At-REST.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. Customers are responsible for securing their own data when using AWS services.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "C. Securing the company's data in transit and at rest\n\nExplanation:\nWhen using Amazon Bedrock, the company is responsible for securing its data both in transit and at rest. This involves ensuring the confidentiality and integrity of the data that is uploaded to Amazon Bedrock or transmitted to and from the service.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 88,
      "data_id": "936851",
      "url": "https://www.examtopics.com/discussions/amazon/view/153464-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A social media company wants to use a large language model (LLM) to summarize messages. The company has chosen a few LLMs that are available on Amazon SageMaker JumpStart. The company wants to compare the generated output toxicity of these models.Which strategy gives the company the ability to evaluate the LLMs with the LEAST operational overhead?",
      "choices": [
        "A. Crowd-sourced evaluation",
        "B. Automatic model evaluation",
        "C. Model evaluation with human workers",
        "D. Reinforcement learning from human feedback (RLHF)"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Automatic model evaluation requires minimal human intervention, making it operationally lighter than human-based approaches.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "B. Automatic model evaluation\n\nExplanation:\nUsing automatic model evaluation is the most efficient and low-overhead approach to evaluate the toxicity of the generated outputs from different LLMs. This strategy involves using automated tools or frameworks designed to assess the toxicity, bias, or other quality metrics of the model outputs, which minimizes operational overhead compared to manual methods.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "B",
          "content": "automatic model evlauation\nAutomatic model evaluation refers to the process of assessing the performance of a machine learning model using predefined metrics and techniques without manual intervention. This process is crucial for understanding how well a model performs and identifying areas for improvement. Here are some key components and methods used in automatic model evaluation:",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 89,
      "data_id": "936852",
      "url": "https://www.examtopics.com/discussions/amazon/view/153465-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is testing the security of a foundation model (FM). During testing, the company wants to get around the safety features and make harmful content.Which security technique is this an example of?",
      "choices": [
        "A. Fuzzing training data to find vulnerabilities",
        "B. Denial of service (DoS)",
        "C. Penetration testing with authorization",
        "D. Jailbreak"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "The correct answer is D. A jailbreak is an attempt to bypass an AI model's built-in safety controls.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "D",
          "content": "D. Jailbreak\n\nExplanation:\nJailbreaking is a technique used to bypass the safety features and restrictions of a foundation model (FM). The goal is to manipulate the model into generating harmful, inappropriate, or otherwise unintended content, despite the safeguards in place. This is often done to test the robustness of the model's safety mechanisms.",
          "upvotes": 2
        },
        {
          "user": "26b8fe1",
          "selected_answer": "D",
          "content": "ML Jailbreak security\nML jailbreak refers to techniques used to bypass the safety and security measures of machine learning models, particularly large language models (LLMs). This can lead to the model producing harmful, inappropriate, or unintended content1. Here are some key points about ML jailbreak security",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 90,
      "data_id": "936853",
      "url": "https://www.examtopics.com/discussions/amazon/view/153538-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company needs to use Amazon SageMaker for model training and inference. The company must comply with regulatory requirements to run SageMaker jobs in an isolated environment without internet access.Which solution will meet these requirements?",
      "choices": [
        "A. Run SageMaker training and inference by using SageMaker Experiments.",
        "B. Run SageMaker training and Inference by using network Isolation.",
        "C. Encrypt the data at rest by using encryption for SageMaker geospatial capabilities.",
        "D. Associate appropriate AWS Identity and Access Management (IAM) roles with the SageMaker jobs."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B: Run SageMaker training and inference by using network isolation.\n\nExplanation:\nNetwork isolation in Amazon SageMaker ensures that training and inference jobs run in a fully isolated environment without internet access. When network isolation is enabled:\n\nSageMaker jobs can only access resources within the specified Virtual Private Cloud (VPC).\nOutbound internet access is disabled.\nData and models remain secure and compliant with regulatory requirements.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Network isolation allows SageMaker to run without internet access, meeting regulatory requirements.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "B. Run SageMaker training and inference by using network isolation.\n\nExplanation:\nNetwork isolation is a feature in Amazon SageMaker that ensures that your training and inference jobs are run in a secure, isolated environment without internet access. This is a critical requirement for complying with regulatory standards that mandate the use of isolated environments for sensitive operations.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 91,
      "data_id": "936854",
      "url": "https://www.examtopics.com/discussions/amazon/view/153539-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An ML research team develops custom ML models. The model artifacts are shared with other teams for integration into products and services. The ML team retains the model training code and data. The ML team wants to build a mechanism that the ML team can use to audit models.Which solution should the ML team use when publishing the custom ML models?",
      "choices": [
        "A. Create documents with the relevant information. Store the documents in Amazon S3.",
        "B. Use AWS AI Service Cards for transparency and understanding models.",
        "C. Create Amazon SageMaker Model Cards with intended uses and training and inference details.",
        "D. Create model training scripts. Commit the model training scripts to a Git repository."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "Amazon SageMaker Model Cards: These provide a standardized way to document important information about ML models, including:\nModel purpose and intended use cases\nTraining data and methodology\nEvaluation metrics and results\nEthical considerations and limitations\nBias analysis\nVersion history This comprehensive documentation facilitates auditing by providing a clear record of how the model was developed, evaluated, and intended to be used. It also promotes transparency and accountability.\nB. Use AWS AI Service Cards for transparency and understanding models:\nAWS AI Service Cards are designed for pre-built AI services provided by AWS, not for custom ML models developed by a team. They are not applicable for this use case.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. SageMaker Model Cards are designed specifically for documenting model details and usage.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "The correct answer is:\n\nC. Create Amazon SageMaker Model Cards with intended uses and training and inference details.\n\nExplanation:\nAmazon SageMaker Model Cards provide a standardized and centralized way to document key details about a machine learning model. This includes intended use, training and inference details, performance metrics, and ethical considerations. These cards enable the ML team to maintain transparency, track audit details, and share relevant information with other teams when publishing models.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 92,
      "data_id": "936855",
      "url": "https://www.examtopics.com/discussions/amazon/view/153540-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A software company builds tools for customers. The company wants to use AI to increase software development productivity.Which solution will meet these requirements?",
      "choices": [
        "A. Use a binary classification model to generate code reviews.",
        "B. Install code recommendation software in the company's developer tools.",
        "C. Install a code forecasting tool to predict potential code issues.",
        "D. Use a natural language processing (NLP) tool to generate code."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "B",
          "content": "As the company wants to increase software development productivity - B is the right one. i.e. Amazon Q Developer",
          "upvotes": 1
        },
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "D. Use a natural language processing (NLP) tool to generate code is likely a more impactful solution for increasing productivity. Code recommendations are helpful, but direct code generation from natural language can automate larger portions of the coding process.",
          "upvotes": 1
        },
        {
          "user": "KevinKas",
          "selected_answer": "B",
          "content": "Code Recommendation Software:\n\nCode recommendation software, such as Amazon CodeWhisperer or similar tools, integrates directly into developer environments (e.g., IDEs).\nThese tools use machine learning and AI to:\nSuggest code snippets.\nAutocomplete code based on context.\nImprove developer productivity by reducing the time spent writing repetitive or boilerplate code.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Code recommendation tools integrated into developer environments provide immediate productivity benefits.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "B. Install code recommendation software in the company's developer tools.\n\nExplanation:\nCode recommendation software integrates into developer tools (e.g., IDEs) and uses AI to analyze code context, provide intelligent code suggestions, automate repetitive tasks, and improve developer productivity. This approach directly aligns with the company's goal of increasing software development productivity.\n-------------\nwhy not choosing D:\n\nWhile NLP-powered code generation is a promising area of research, it's not yet a foolproof solution for boosting productivity. Code recommendation tools, on the other hand, offer a more immediate and reliable way to enhance developer efficiency by streamlining the coding process.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 93,
      "data_id": "936856",
      "url": "https://www.examtopics.com/discussions/amazon/view/153541-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A retail store wants to predict the demand for a specific product for the next few weeks by using the Amazon SageMaker DeepAR forecasting algorithm.Which type of data will meet this requirement?",
      "choices": [
        "A. Text data",
        "B. Image data",
        "C. Time series data",
        "D. Binary data"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "KevinKas",
          "selected_answer": "C",
          "content": "DeepAR and Time Series Data:\n\nThe Amazon SageMaker DeepAR forecasting algorithm is specifically designed to handle time series data for forecasting tasks.\nTime series data consists of observations collected at regular intervals over time (e.g., daily sales of a product).\nDeepAR uses historical patterns in this data to predict future values.\nWhy Time Series Data is Required:\n\nTo predict product demand, the model needs past sales data (e.g., daily, weekly, or monthly), which is inherently time series data.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. DeepAR is specifically designed for processing and forecasting time series data.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "C. Time series data\n\nExplanation:\nThe Amazon SageMaker DeepAR forecasting algorithm is specifically designed for time series forecasting, where the goal is to predict future values based on historical data.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 94,
      "data_id": "936857",
      "url": "https://www.examtopics.com/discussions/amazon/view/153542-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A large retail bank wants to develop an ML system to help the risk management team decide on loan allocations for different demographics.What must the bank do to develop an unbiased ML model?",
      "choices": [
        "A. Reduce the size of the training dataset.",
        "B. Ensure that the ML model predictions are consistent with historical results.",
        "C. Create a different ML model for each demographic group.",
        "D. Measure class imbalance on the training dataset. Adapt the training process accordingly."
      ],
      "answer": "d",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "D",
          "content": "D. Measure class imbalance on the training dataset. Adapt the training process accordingly: This is the correct answer. Class imbalance occurs when one class (e.g., loan approval) is significantly more represented in the training data than another. This can lead to biased models that favor the majority class. Measuring and addressing class imbalance (e.g., through resampling or weighting techniques) is crucial for building fair models.\n\nWhy not B?\nB. Ensure that the ML model predictions are consistent with historical results: If historical results reflect existing biases in lending practices, ensuring consistency with them will simply perpetuate those biases. This is the opposite of what is desired.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "The correct answer is D. Measuring and addressing class imbalance in training data is essential for developing unbiased ML models.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "D",
          "content": "D. Measure class imbalance on the training dataset. Adapt the training process accordingly.\n\nExplanation:\nTo develop an unbiased ML model, it is crucial to ensure that the training dataset represents all demographic groups fairly and that the model is not influenced by biases in the data.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 95,
      "data_id": "936858",
      "url": "https://www.examtopics.com/discussions/amazon/view/153530-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which prompting technique can protect against prompt injection attacks?",
      "choices": [
        "A. Adversarial prompting",
        "B. Zero-shot prompting",
        "C. Least-to-most prompting",
        "D. Chain-of-thought prompting"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "KevinKas",
          "selected_answer": "A",
          "content": "Adversarial Prompting:\n\nThis technique involves testing a model with deliberately crafted adversarial prompts to identify vulnerabilities to injection attacks.\nBy simulating potential attacks during development, adversarial prompting helps design robust prompts and refine the model's behavior to resist manipulation.\nThis approach allows developers to identify weaknesses in the model's response to malicious inputs and implement mitigations.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Adversarial prompting helps models recognize and defend against malicious inputs.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "The most effective technique for protecting against prompt injection attacks is A. Adversarial Prompting.\n\nHere's why:\n\nProactive Defense: Adversarial prompting involves deliberately crafting malicious prompts to test the model's boundaries and identify vulnerabilities. This proactive approach helps uncover weaknesses that might otherwise go unnoticed.\nWhile C. Least-to-most Prompting can indirectly improve robustness by simplifying the initial prompts, it's not a primary defense against prompt injection. Its primary focus is on improving task completion, not directly addressing malicious inputs.\n\nKey takeaway: Adversarial prompting is the most direct and effective method for enhancing the security of language models against prompt injection attacks.",
          "upvotes": 2
        },
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "Adversarial prompting involves designing and testing prompts to identify and mitigate vulnerabilities in an AI system. By exposing the model to potential manipulation scenarios during development, practitioners can adjust the model or its responses to defend against prompt injection attacks.\nThis technique helps ensure the model behaves as intended, even when malicious or cleverly crafted prompts are used to bypass restrictions or elicit undesirable outputs.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 96,
      "data_id": "936859",
      "url": "https://www.examtopics.com/discussions/amazon/view/153531-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has fine-tuned a large language model (LLM) to answer questions for a help desk. The company wants to determine if the fine-tuning has enhanced the model's accuracy.Which metric should the company use for the evaluation?",
      "choices": [
        "A. Precision",
        "B. Time to first token",
        "C. F1 score",
        "D. Word error rate"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: F1 score\n\nExplanation:\nThe F1 score is a balanced metric that combines precision and recall to evaluate the accuracy of a model, particularly in scenarios like question-answering, where both correctness (precision) and completeness (recall) matter. The F1 score is particularly useful when there is an uneven distribution of classes or when the model's ability to retrieve relevant and accurate answers is being assessed.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. F1 score combines precision and recall, making it ideal for question-answering evaluation.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "The F1 score provides a balanced evaluation of the model's ability to give both relevant and accurate answers, making it the most suitable metric for assessing the fine-tuned model’s performance in answering help desk questions.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "C",
          "content": "F1 score is a metric that combines precision and recall to evaluate the balance between correctly identified outputs and missed or irrelevant outputs. It is particularly useful for tasks like question answering, where both accuracy and completeness are critical.\nIn this help desk scenario, the F1 score helps assess whether the model consistently provides correct and relevant answers to user queries, reflecting the effectiveness of fine-tuning.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 97,
      "data_id": "936860",
      "url": "https://www.examtopics.com/discussions/amazon/view/153489-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using Retrieval Augmented Generation (RAG) with Amazon Bedrock and Stable Diffusion to generate product images based on text descriptions. The results are often random and lack specific details. The company wants to increase the specificity of the generated images.Which solution meets these requirements?",
      "choices": [
        "A. Increase the number of generation steps.",
        "B. Use the MASK_IMAGE_BLACK mask source option.",
        "C. Increase the classifier-free guidance (CFG) scale.",
        "D. Increase the prompt strength."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. Higher CFG scale makes generated images follow prompts more closely.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "Increasing the classifier-free guidance (CFG) scale (Option C) will make the model pay more attention to the input text description, improving the specificity and detail of the generated images. This is the most effective method to increase the specificity of images in a Retrieval Augmented Generation (RAG) setup with Stable Diffusion.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "C",
          "content": "Classifier-Free Guidance (CFG) is a technique used in diffusion models, such as Stable Diffusion, to guide the model toward generating outputs that closely align with the text prompt.\nBy increasing the CFG scale, the model puts more emphasis on the textual prompt, leading to outputs that are more specific and less random.\nIn this case, where the generated images lack specific details, increasing the CFG scale helps ensure the generated product images are more aligned with the input text descriptions.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 98,
      "data_id": "936861",
      "url": "https://www.examtopics.com/discussions/amazon/view/153544-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to implement a large language model (LLM) based chatbot to provide customer service agents with real-time contextual responses to customers' inquiries. The company will use the company's policies as the knowledge base.Which solution will meet these requirements MOST cost-effectively?",
      "choices": [
        "A. Retrain the LLM on the company policy data.",
        "B. Fine-tune the LLM on the company policy data.",
        "C. Implement Retrieval Augmented Generation (RAG) for in-context responses.",
        "D. Use pre-training and data augmentation on the company policy data."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "85b5b55",
          "selected_answer": "C",
          "content": "RAG provides most cost-effective solution",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. RAG allows direct use of policy documents without expensive model training.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "RAG (Option C) is the most cost-effective choice because it allows the LLM to dynamically retrieve relevant information from a predefined knowledge base (the company policy) at inference time, without needing extensive fine-tuning or retraining of the model. This reduces the need for costly computational resources while still providing accurate, contextual responses.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 99,
      "data_id": "936862",
      "url": "https://www.examtopics.com/discussions/amazon/view/153547-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to create a new solution by using AWS Glue. The company has minimal programming experience with AWS Glue.Which AWS service can help the company use AWS Glue?",
      "choices": [
        "A. Amazon Q Developer",
        "B. AWS Config",
        "C. Amazon Personalize",
        "D. Amazon Comprehend"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Amazon Q Developer helps users work with AWS services through natural language assistance.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "Amazon Q Developer (Option A) is the service that would most help a company with minimal programming experience in using AWS Glue. It simplifies the process of building and managing data workflows, making it easier to use Glue without needing deep programming expertise.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 100,
      "data_id": "936863",
      "url": "https://www.examtopics.com/discussions/amazon/view/153548-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is developing a mobile ML app that uses a phone's camera to diagnose and treat insect bites. The company wants to train an image classification model by using a diverse dataset of insect bite photos from different genders, ethnicities, and geographic locations around the world.Which principle of responsible AI does the company demonstrate in this scenario?",
      "choices": [
        "A. Fairness",
        "B. Explainability",
        "C. Governance",
        "D. Transparency"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Fairness. Using diverse datasets ensures equal representation and performance across different demographic groups.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "By using a diverse dataset that includes different genders, ethnicities, and geographic locations, the company is addressing fairness by making sure the model does not discriminate against any particular group.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 101,
      "data_id": "936864",
      "url": "https://www.examtopics.com/discussions/amazon/view/153549-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is developing an ML model to make loan approvals. The company must implement a solution to detect bias in the model. The company must also be able to explain the model's predictions.Which solution will meet these requirements?",
      "choices": [
        "A. Amazon SageMaker Clarify",
        "B. Amazon SageMaker Data Wrangler",
        "C. Amazon SageMaker Model Cards",
        "D. AWS AI Service Cards"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. SageMaker Clarify provides both bias detection and model explainability features.",
          "upvotes": 2
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "Amazon SageMaker Clarify provides both bias detection and model explainability features, making it the most suitable choice for detecting bias in a loan approval model and explaining its predictions.",
          "upvotes": 3
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 102,
      "data_id": "936865",
      "url": "https://www.examtopics.com/discussions/amazon/view/153532-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has developed a generative text summarization model by using Amazon Bedrock. The company will use Amazon Bedrock automatic model evaluation capabilities.Which metric should the company use to evaluate the accuracy of the model?",
      "choices": [
        "A. Area Under the ROC Curve (AUC) score",
        "B. F1 score",
        "C. BERTScore",
        "D. Real world knowledge (RWK) score"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. BERTScore is specifically designed for evaluating text generation quality.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "BERTScore is the most appropriate metric for evaluating the accuracy of a generative text summarization model because it compares semantic similarity in a manner that aligns well with the goal of text summarization.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "C",
          "content": "BERTScore is a metric specifically designed to evaluate text generation tasks, such as summarization. It measures the semantic similarity between the generated text and the reference text by leveraging contextual embeddings from pre-trained models like BERT.\n\nBERTScore captures deeper semantic relationships, making it ideal for evaluating the accuracy and meaningfulness of summaries.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 103,
      "data_id": "936866",
      "url": "https://www.examtopics.com/discussions/amazon/view/153490-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner wants to predict the classification of flowers based on petal length, petal width, sepal length, and sepal width.Which algorithm meets these requirements?",
      "choices": [
        "A. K-nearest neighbors (k-NN)",
        "B. K-mean",
        "C. Autoregressive Integrated Moving Average (ARIMA)",
        "D. Linear regression"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "The practitioner wants to classify flowers based on measurements. This indicates a classification problem.\n\nA. K-nearest neighbors (k-NN): This is a classification algorithm that classifies data points based on the majority class among their k-nearest neighbors. It's suitable for this scenario.\n\nB. K-means: This is a clustering algorithm used for unsupervised learning. It groups data points into clusters based on similarity, but it doesn't perform classification with predefined labels.\n\nC. Autoregressive Integrated Moving Average (ARIMA): This is a time series forecasting model used for predicting future values based on past data trends. It's not suitable for classification based on static measurements like flower dimensions.\n\nD. Linear regression: This is a regression algorithm used for predicting continuous values. It's not suitable for classification into discrete categories like flower types.\n\nTherefore, A. K-nearest neighbors (k-NN) is the appropriate algorithm for this classification task",
          "upvotes": 3
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. K-nearest neighbors (k-NN) is a classification algorithm suitable for predicting the classification of flowers based on the provided features.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "For a classification task where the goal is to predict the type of flower based on several features, K-nearest neighbors (k-NN) is the most appropriate algorithm.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "K-nearest neighbors (k-NN) is a supervised learning algorithm commonly used for classification tasks. It works by finding the \"k\" closest data points (neighbors) to a given input and assigning the class based on majority voting among these neighbors.\nIn this case, the AI practitioner wants to classify flowers based on features like petal length, petal width, sepal length, and sepal width, making k-NN a suitable algorithm.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 104,
      "data_id": "936867",
      "url": "https://www.examtopics.com/discussions/amazon/view/153550-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using custom models in Amazon Bedrock for a generative AI application. The company wants to use a company managed encryption key to encrypt the model artifacts that the model customization jobs create.Which AWS service meets these requirements?",
      "choices": [
        "A. AWS Key Management Service (AWS KMS)",
        "B. Amazon Inspector",
        "C. Amazon Macie",
        "D. AWS Secrets Manager"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "The company needs to use a company-managed encryption key to encrypt model artifacts. This points directly to key management.\n\nA. AWS Key Management Service (AWS KMS): This is the correct answer. AWS KMS allows you to create and manage encryption keys, including customer-managed keys (CMKs), which give you control over the key lifecycle and usage.\n\nB. Amazon Inspector: Inspector is a vulnerability management service that scans for security vulnerabilities in your AWS resources.\n\nC. Amazon Macie: Macie is a data security and privacy service that uses machine learning to discover and protect sensitive data in AWS.\n\nD. AWS Secrets Manager: Secrets Manager helps you manage secrets such as passwords, API keys, and database credentials. While it can store encrypted secrets, it's not the primary service for managing encryption keys used to protect model artifacts at rest.",
          "upvotes": 3
        },
        {
          "user": "Moon",
          "content": "The company needs to use a company-managed encryption key to encrypt model artifacts. This points directly to key management.\n\nA. AWS Key Management Service (AWS KMS): This is the correct answer. AWS KMS allows you to create and manage encryption keys, including customer-managed keys (CMKs), which give you control over the key lifecycle and usage.\n\nB. Amazon Inspector: Inspector is a vulnerability management service that scans for security vulnerabilities in your AWS resources.\n\nC. Amazon Macie: Macie is a data security and privacy service that uses machine learning to discover and protect sensitive data in AWS.\n\nD. AWS Secrets Manager: Secrets Manager helps you manage secrets such as passwords, API keys, and database credentials. While it can store encrypted secrets, it's not the primary service for managing encryption keys used to protect model artifacts at rest.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "To securely manage encryption keys for the custom models' artifacts, AWS Key Management Service (AWS KMS) is the correct service.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 105,
      "data_id": "936868",
      "url": "https://www.examtopics.com/discussions/amazon/view/153552-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use large language models (LLMs) to produce code from natural language code comments.Which LLM feature meets these requirements?",
      "choices": [
        "A. Text summarization",
        "B. Text generation",
        "C. Text completion",
        "D. Text classification"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Text generation is the appropriate feature for converting natural language into code.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "To produce code from natural language code comments, text generation is the appropriate feature of an LLM.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 106,
      "data_id": "936869",
      "url": "https://www.examtopics.com/discussions/amazon/view/153468-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is introducing a mobile app that helps users learn foreign languages. The app makes text more coherent by calling a large language model (LLM). The company collected a diverse dataset of text and supplemented the dataset with examples of more readable versions. The company wants the LLM output to resemble the provided examples.Which metric should the company use to assess whether the LLM meets these requirements?",
      "choices": [
        "A. Value of the loss function",
        "B. Semantic robustness",
        "C. Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score",
        "D. Latency of the text generation"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. ROUGE score measures how well generated text matches reference examples.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "Since the company wants the LLM output to resemble the provided examples in terms of coherence and readability, ROUGE score is the best metric for this evaluation.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "C",
          "content": "he most suitable metric to assess whether the LLM output resembles the provided examples of more readable text is:\n\nC. Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score\n\nThe ROUGE score is commonly used for evaluating the quality of text summarization and machine-generated text by comparing it to a set of reference texts. It measures how well the generated text matches the provided examples in terms of content and coherence. Specifically, ROUGE scores focus on the overlap of n-grams, word sequences, and word pairs between the generated text and the reference texts, making it ideal for this use case.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 107,
      "data_id": "936870",
      "url": "https://www.examtopics.com/discussions/amazon/view/153469-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company notices that its foundation model (FM) generates images that are unrelated to the prompts. The company wants to modify the prompt techniques to decrease unrelated images.Which solution meets these requirements?",
      "choices": [
        "A. Use zero-shot prompts.",
        "B. Use negative prompts.",
        "C. Use positive prompts.",
        "D. Use ambiguous prompts."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Using negative prompts can help guide the model away from generating unrelated images.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "By using negative prompts, the company can reduce the generation of unrelated images by specifying what should not be included in the output, leading to more accurate and relevant image generation based on the given prompt.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "B",
          "content": "B. Use negative prompts.\n\nNegative prompts help the model understand what to avoid in the generated images. By providing explicit instructions on what should not be included in the output, the model can better align its results with the intended themes and contexts of the prompts.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 108,
      "data_id": "936871",
      "url": "https://www.examtopics.com/discussions/amazon/view/153470-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to use a large language model (LLM) to generate concise, feature-specific descriptions for the company’s products.Which prompt engineering technique meets these requirements?",
      "choices": [
        "A. Create one prompt that covers all products. Edit the responses to make the responses more specific, concise, and tailored to each product.",
        "B. Create prompts for each product category that highlight the key features. Include the desired output format and length for each prompt response.",
        "C. Include a diverse range of product features in each prompt to generate creative and unique descriptions.",
        "D. Provide detailed, product-specific prompts to ensure precise and customized descriptions."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Find24",
          "selected_answer": "D",
          "content": "Option B: Creating prompts for each product category can help highlight key features, but it may still result in more generalized descriptions. This approach might not capture the unique aspects of each individual product as effectively as a detailed, product-specific prompt.\n\nOption D: By providing detailed, product-specific prompts, you ensure that the descriptions are tailored to each product's unique features. This method minimizes the need for further editing and ensures that the output is concise and highly relevant.\n\nIn summary, while Option B is useful for generating category-specific descriptions, Option D offers a higher level of precision and customization for individual products.",
          "upvotes": 2
        },
        {
          "user": "djeong95",
          "content": "Option D doesn't address the concise aspect",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Creating category-specific prompts ensures consistent and feature-focused product descriptions.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "Option B offers the best strategy for generating concise, feature-specific descriptions, as it targets the key features for each product category and provides clear instructions on the format and length of the output.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "B",
          "content": "Create prompts for each product category that highlight the key features. Include the desired output format and length for each prompt response.\n\nBy creating tailored prompts for each product category and specifying the key features along with the desired output format and length, the company can ensure that the generated descriptions are specific, concise, and relevant to each product. This approach balances the need for customization with efficiency.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 109,
      "data_id": "936872",
      "url": "https://www.examtopics.com/discussions/amazon/view/153472-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is developing an ML model to predict customer churn. The model performs well on the training dataset but does not accurately predict churn for new data.Which solution will resolve this issue?",
      "choices": [
        "A. Decrease the regularization parameter to increase model complexity.",
        "B. Increase the regularization parameter to decrease model complexity.",
        "C. Add more features to the input data.",
        "D. Train the model for more epochs."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Increasing the regularization parameter reduces model complexity and prevents overfitting.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "The most effective solution to resolve overfitting and improve the model’s performance on new data is B. Increase the regularization parameter. This helps make the model simpler, reducing the likelihood of overfitting and improving its ability to generalize.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "B",
          "content": "Increase the regularization parameter to decrease model complexity.\n\nIncreasing the regularization parameter helps prevent overfitting by penalizing more complex models, encouraging the model to generalize better to new data.\n\nWould you like more detailed information on how to implement this change or any other aspect of model tuning?",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 110,
      "data_id": "936873",
      "url": "https://www.examtopics.com/discussions/amazon/view/153473-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is implementing intelligent agents to provide conversational search experiences for its customers. The company needs a database service that will support storage and queries of embeddings from a generative AI model as vectors in the database.Which AWS service will meet these requirements?",
      "choices": [
        "A. Amazon Athena",
        "B. Amazon Aurora PostgreSQL",
        "C. Amazon Redshift",
        "D. Amazon EMR"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Amazon Aurora PostgreSQL supports vector data types and can efficiently store and query embeddings.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "Amazon Aurora PostgreSQL is the best choice for a database service to store and query embeddings from generative AI models, as it supports vector storage and similarity searches through the pgvector extension.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "B",
          "content": "Amazon Aurora PostgreSQL\n\nAmazon Aurora PostgreSQL supports vector storage and queries, making it suitable for storing embeddings from a generative AI model as vectors in the database. It integrates with extensions like pgvector to efficiently handle high-dimensional vector data.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 111,
      "data_id": "936874",
      "url": "https://www.examtopics.com/discussions/amazon/view/153477-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A financial institution is building an AI solution to make loan approval decisions by using a foundation model (FM). For security and audit purposes, the company needs the AI solution's decisions to be explainable.Which factor relates to the explainability of the AI solution's decisions?",
      "choices": [
        "A. Model complexity",
        "B. Training time",
        "C. Number of hyperparameters",
        "D. Deployment time"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Model complexity directly affects how interpretable and explainable AI decisions are.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "Model complexity is the most important factor when considering the explainability of the AI solution's decisions, as simpler models with fewer parameters and layers are typically easier to explain and interpret.",
          "upvotes": 2
        },
        {
          "user": "26b8fe1",
          "selected_answer": "A",
          "content": "Model complexity in machine learning refers to the capacity of a model to capture and represent patterns in the data. It involves the depth, breadth, and intricacy of the underlying structure of the model. Here are some key aspects",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 112,
      "data_id": "936875",
      "url": "https://www.examtopics.com/discussions/amazon/view/153478-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A pharmaceutical company wants to analyze user reviews of new medications and provide a concise overview for each medication.Which solution meets these requirements?",
      "choices": [
        "A. Create a time-series forecasting model to analyze the medication reviews by using Amazon Personalize.",
        "B. Create medication review summaries by using Amazon Bedrock large language models (LLMs).",
        "C. Create a classification model that categorizes medications into different groups by using Amazon SageMaker.",
        "D. Create medication review summaries by using Amazon Rekognition."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. LLMs are specifically designed for text analysis and summarization tasks.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "Using Amazon Bedrock’s large language models (LLMs) is the ideal solution for generating concise summaries of user reviews of new medications.",
          "upvotes": 1
        },
        {
          "user": "26b8fe1",
          "selected_answer": "B",
          "content": "Create medication review summaries by using Amazon Bedrock large language models (LLMs).\n\nAmazon Bedrock LLMs are designed for natural language processing tasks, including text summarization. They can effectively generate concise and coherent summaries from the text, making them ideal for summarizing user reviews of medications.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 113,
      "data_id": "936876",
      "url": "https://www.examtopics.com/discussions/amazon/view/153515-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to build a lead prioritization application for its employees to contact potential customers. The application must give employees the ability to view and adjust the weights assigned to different variables in the model based on domain knowledge and expertise.Which ML model type meets these requirements?",
      "choices": [
        "A. Logistic regression model",
        "B. Deep learning model built on principal components",
        "C. K-nearest neighbors (k-NN) model",
        "D. Neural network"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Logistic regression model\n\nExplanation:\nA logistic regression model is interpretable and allows direct adjustment of the weights assigned to different variables (features). This aligns with the requirement for employees to view and modify the weights based on their domain knowledge and expertise. Logistic regression provides a clear relationship between input features and output predictions, making it ideal for use cases that demand transparency and control.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Logistic regression models allow for easy interpretation and adjustment of weights.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "A logistic regression model allows for clear, adjustable weights based on domain knowledge, making it the best choice for a lead prioritization application where employees can modify model parameters easily.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "Logistic regression models are interpretable and allow the user to view and adjust the weights assigned to different variables (features). These weights determine the contribution of each feature to the final prediction, and they can be modified based on domain knowledge or expertise.\n\nThis characteristic makes logistic regression a suitable choice for the lead prioritization application, as employees can easily understand and fine-tune the model to align with their specific business requirements.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 115,
      "data_id": "936878",
      "url": "https://www.examtopics.com/discussions/amazon/view/153554-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which strategy will determine if a foundation model (FM) effectively meets business objectives?",
      "choices": [
        "A. Evaluate the model's performance on benchmark datasets.",
        "B. Analyze the model's architecture and hyperparameters.",
        "C. Assess the model's alignment with specific use cases.",
        "D. Measure the computational resources required for model deployment."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "C: Assess the model's alignment with specific use cases.\n\nExplanation:\nTo determine if a foundation model (FM) effectively meets business objectives, it is crucial to evaluate how well the model aligns with the specific use cases and objectives of the business. This involves testing the model's performance on real-world tasks and ensuring that it addresses the desired outcomes, such as accuracy, relevance, and user satisfaction, in the context of the business problem.\n\nWhy not the other options?\nA: Evaluate the model's performance on benchmark datasets:\nWhile benchmarking provides useful insights into the model's capabilities, it does not guarantee alignment with business-specific needs or objectives.",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. Assessing use case alignment determines business objective achievement.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "C. Assess the model's alignment with specific use cases.\n\nExplanation: While evaluating performance on benchmark datasets (A), analyzing the architecture and hyperparameters (B), and measuring computational resources (D) are important aspects of model evaluation, they do not directly assess whether the model fulfills the specific business goals. To determine if an FM meets business objectives, the key is to assess how well the model performs in the context of the specific use cases or real-world applications that the business is targeting. This helps ensure that the model's outputs are valuable, actionable, and aligned with the company's needs.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 116,
      "data_id": "936879",
      "url": "https://www.examtopics.com/discussions/amazon/view/153555-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company needs to train an ML model to classify images of different types of animals. The company has a large dataset of labeled images and will not label more data.Which type of learning should the company use to train the model?",
      "choices": [
        "A. Supervised learning",
        "B. Unsupervised learning",
        "C. Reinforcement learning",
        "D. Active learning"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "A: Supervised learning\n\nExplanation:\nSupervised learning is the appropriate method when a dataset of labeled examples is available, as it involves training a model using input-output pairs. In this case, the labeled images of animals (input) and their corresponding categories (output) make supervised learning the ideal approach. The model learns from these examples to classify new, unseen images into the correct categories.\n\nWhy not the other options?\nB: Unsupervised learning:\nUnsupervised learning does not use labeled data and is typically used for clustering or pattern discovery. It is not suitable for this classification task, which requires labeled data.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "A. Supervised learning\n\nExplanation: Since the company has a large dataset of labeled images, supervised learning is the appropriate choice. In supervised learning, a model is trained on a labeled dataset, where the input data (images) is paired with corresponding labels (the types of animals). This approach allows the model to learn from the labeled data and make predictions on new, unseen data.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 117,
      "data_id": "936880",
      "url": "https://www.examtopics.com/discussions/amazon/view/153516-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which phase of the ML lifecycle determines compliance and regulatory requirements?",
      "choices": [
        "A. Feature engineering",
        "B. Model training",
        "C. Data collection",
        "D. Business goal identification"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "thomasjos79",
          "selected_answer": "D",
          "content": "A clear problem definition keeps the entire ML team aligned on what success looks like. However, this step is far from straightforward. For example, setting appropriate risk thresholds for fraud detection involves balancing regulatory requirements (like GDPR, AML, and KYC) with business priorities and operational constraints.",
          "upvotes": 2
        },
        {
          "user": "fnuuu",
          "selected_answer": "C",
          "content": "c. Data collection",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "The correct answer is D. Business goal identification phase establishes all requirements including compliance and regulatory.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "C. Data collection\n\nExplanation: The data collection phase of the ML lifecycle is where compliance and regulatory requirements are primarily determined. During this phase, it's important to ensure that the data being gathered complies with legal and regulatory standards, such as data privacy laws (e.g., GDPR, HIPAA). Compliance considerations include ensuring that data is collected ethically, with proper consent, and that sensitive or personal information is handled appropriately.",
          "upvotes": 2
        },
        {
          "user": "ap6491",
          "selected_answer": "D",
          "content": "The business goal identification phase is where the organization defines the purpose of the ML project and determines the compliance, regulatory, and legal requirements. These considerations must be addressed early in the lifecycle to ensure the solution adheres to applicable laws and standards.\n\nFor example, in industries like finance or healthcare, this phase would identify data privacy regulations (e.g., GDPR, HIPAA) or fairness requirements that need to be incorporated into the ML workflow.",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 118,
      "data_id": "936881",
      "url": "https://www.examtopics.com/discussions/amazon/view/153556-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A food service company wants to develop an ML model to help decrease daily food waste and increase sales revenue. The company needs to continuously improve the model's accuracy.Which solution meets these requirements?",
      "choices": [
        "A. Use Amazon SageMaker and iterate with newer data.",
        "B. Use Amazon Personalize and iterate with historical data.",
        "C. Use Amazon CloudWatch to analyze customer orders.",
        "D. Use Amazon Rekognition to optimize the model."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Using Amazon SageMaker allows for continuous iteration and improvement of the model's accuracy with newer data.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "A. Use Amazon SageMaker and iterate with newer data.\n\nExplanation:\n\nTo meet the requirements of decreasing food waste and increasing sales revenue, the company needs a machine learning model that can continuously improve and adjust based on new data.\n\nAmazon SageMaker is a fully managed service that allows companies to build, train, and deploy machine learning models at scale. By iterating with newer data, the model can be continuously updated to reflect changing patterns in customer behavior, demand, and food consumption, leading to more accurate predictions over time.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 119,
      "data_id": "936882",
      "url": "https://www.examtopics.com/discussions/amazon/view/153557-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company has developed an ML model to predict real estate sale prices. The company wants to deploy the model to make predictions without managing servers or infrastructure.Which solution meets these requirements?",
      "choices": [
        "A. Deploy the model on an Amazon EC2 instance.",
        "B. Deploy the model on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.",
        "C. Deploy the model by using Amazon CloudFront with an Amazon S3 integration.",
        "D. Deploy the model by using an Amazon SageMaker endpoint."
      ],
      "answer": "d",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "D",
          "content": "The correct answer is D. Deploying the model using an Amazon SageMaker endpoint allows for serverless predictions.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "D",
          "content": "D. Deploy the model by using an Amazon SageMaker endpoint.\n\nExplanation:\n\nAmazon SageMaker is a fully managed service that enables you to quickly build, train, and deploy machine learning models at scale. Deploying a model using an Amazon SageMaker endpoint allows the company to make predictions without needing to manage servers or infrastructure. SageMaker automatically handles the provisioning of resources, scaling, and maintenance, making it an ideal solution for production-grade ML deployments.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 120,
      "data_id": "936883",
      "url": "https://www.examtopics.com/discussions/amazon/view/153517-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to develop an AI application to help its employees check open customer claims, identify details for a specific claim, and access documents for a claim.Which solution meets these requirements?",
      "choices": [
        "A. Use Agents for Amazon Bedrock with Amazon Fraud Detector to build the application.",
        "B. Use Agents for Amazon Bedrock with Amazon Bedrock knowledge bases to build the application.",
        "C. Use Amazon Personalize with Amazon Bedrock knowledge bases to build the application.",
        "D. Use Amazon SageMaker to build the application by training a new ML model."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "B",
          "content": "B. Use Agents for Amazon Bedrock with Amazon Bedrock knowledge bases to build the application: This is the correct answer. Agents for Bedrock can connect to and interact with various data sources, including knowledge bases. Using a Bedrock knowledge base (which could be populated with claim data and documents) allows the agent to retrieve the necessary information to fulfill user requests related to claims.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Using Agents for Amazon Bedrock with Amazon Bedrock knowledge bases allows employees to check open customer claims, identify details, and access related documents effectively.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "B. Use Agents for Amazon Bedrock with Amazon Bedrock knowledge bases to build the application.\n\nExplanation:\n\nAmazon Bedrock is a fully managed service that allows you to build and deploy generative AI applications. Agents for Amazon Bedrock provides AI-powered agents to interact with users and help them get information, making it ideal for helping employees check open customer claims, identify claim details, and access documents.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "B",
          "content": "Agents for Amazon Bedrock enable the creation of AI-driven applications that integrate with enterprise systems and use natural language processing (NLP) to answer user queries.\n\nAmazon Bedrock knowledge bases allow the agent to access structured and unstructured data, such as claim details and associated documents, enabling employees to search and retrieve specific claim-related information efficiently.\n\nThis combination supports the application’s requirement to check open claims, identify specific claim details, and access claim documents.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 121,
      "data_id": "936884",
      "url": "https://www.examtopics.com/discussions/amazon/view/153558-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A manufacturing company uses AI to inspect products and find any damages or defects.Which type of AI application is the company using?",
      "choices": [
        "A. Recommendation system",
        "B. Natural language processing (NLP)",
        "C. Computer vision",
        "D. Image processing"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "C",
          "content": "Computer vision is a type of AI application that enables machines to interpret and analyze visual data from the real world, such as images and videos. In this scenario, the company is using AI to inspect products for damages or defects, which involves analyzing visual inputs—making computer vision the appropriate answer.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "C",
          "content": "The correct answer is C. Computer vision is used for visual inspection tasks.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "C",
          "content": "C. Computer vision\n\nExplanation:\n\nComputer vision is a field of AI that enables machines to interpret and make decisions based on visual data, such as images or videos. In the context of inspecting products for damages or defects, computer vision algorithms can analyze product images to detect visual patterns, anomalies, or defects, making it the most appropriate AI application type for this use case.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 122,
      "data_id": "936885",
      "url": "https://www.examtopics.com/discussions/amazon/view/153559-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to create an ML model to predict customer satisfaction. The company needs fully automated model tuning.Which AWS service meets these requirements?",
      "choices": [
        "A. Amazon Personalize",
        "B. Amazon SageMaker",
        "C. Amazon Athena",
        "D. Amazon Comprehend"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "B",
          "content": "The correct answer is B. Amazon SageMaker provides fully automated model tuning capabilities through its hyperparameter optimization features.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "B",
          "content": "B. Amazon SageMaker\n\nExplanation:\n\nAmazon SageMaker is a fully managed service that provides tools to build, train, and deploy machine learning models. It includes SageMaker Autopilot, which automates the machine learning model development process, including model tuning. This feature helps users create and optimize models with minimal manual intervention, making it ideal for fully automated model tuning.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 123,
      "data_id": "936886",
      "url": "https://www.examtopics.com/discussions/amazon/view/153518-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which technique can a company use to lower bias and toxicity in generative AI applications during the post-processing ML lifecycle?",
      "choices": [
        "A. Human-in-the-loop",
        "B. Data augmentation",
        "C. Feature engineering",
        "D. Adversarial training"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "A",
          "content": "The question specifies reducing bias and toxicity during post-processing of generated content.\n\nA. Human-in-the-loop: This is the correct answer. Human review of generated outputs allows for filtering or modification of biased or toxic content after generation.\n\nB. Data augmentation: This occurs during training, modifying the training data itself, not the generated outputs.\n\nC. Feature engineering: Also a training phase activity, focusing on input features, not generated content.\n\nD. Adversarial training: Used during training to improve robustness, not to filter post-generation content",
          "upvotes": 2
        },
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Human-in-the-loop review provides direct oversight for reducing bias and toxicity.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "A. Human-in-the-loop\n\nExplanation:\n\nHuman-in-the-loop (HITL) is a technique used in the post-processing stage of the machine learning lifecycle to improve model performance, including reducing bias and toxicity. In HITL, human evaluators intervene to assess and refine model outputs. This feedback loop helps to identify and correct biases, toxic language, or other undesirable outputs before they are presented to end-users. It ensures that the AI system adheres to ethical guidelines and improves the quality of generated content.",
          "upvotes": 1
        },
        {
          "user": "ap6491",
          "selected_answer": "A",
          "content": "Human-in-the-loop (HITL) involves incorporating human reviewers into the model’s post-processing workflow to evaluate and refine outputs generated by the AI.\n\nThis approach helps identify and reduce bias or toxic content by leveraging human judgment to assess and correct inappropriate or inaccurate results.\n\nHITL is particularly useful in generative AI applications where outputs can be subjective and require nuanced review to align with ethical and business standards.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 124,
      "data_id": "936887",
      "url": "https://www.examtopics.com/discussions/amazon/view/153560-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A bank has fine-tuned a large language model (LLM) to expedite the loan approval process. During an external audit of the model, the company discovered that the model was approving loans at a faster pace for a specific demographic than for other demographics.How should the bank fix this issue MOST cost-effectively?",
      "choices": [
        "A. Include more diverse training data. Fine-tune the model again by using the new data.",
        "B. Use Retrieval Augmented Generation (RAG) with the fine-tuned model.",
        "C. Use AWS Trusted Advisor checks to eliminate bias.",
        "D. Pre-train a new LLM with more diverse training data."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "may2021_r",
          "selected_answer": "A",
          "content": "The correct answer is A. Fine-tuning with more diverse data is the most cost-effective bias mitigation approach.",
          "upvotes": 1
        },
        {
          "user": "aws_Tamilan",
          "selected_answer": "A",
          "content": "A. Include more diverse training data. Fine-tune the model again by using the new data.\n\nExplanation:\n\nThe issue of bias in the loan approval model likely arises from the model being trained on data that does not sufficiently represent all demographics. To address this, the bank should augment the training dataset with more diverse data to ensure that the model can learn to make fair and equitable decisions across different demographics. After incorporating the more diverse training data, the bank can fine-tune the model again to adjust its behavior and reduce any biases identified during the audit.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 126,
      "data_id": "936889",
      "url": "https://www.examtopics.com/discussions/amazon/view/153592-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company needs to log all requests made to its Amazon Bedrock API. The company must retain the logs securely for 5 years at the lowest possible cost.Which combination of AWS service and storage class meets these requirements? (Choose two.)",
      "choices": [
        "A. AWS CloudTrail",
        "B. Amazon CloudWatch",
        "C. AWS Audit Manager",
        "D. Amazon S3 Intelligent-Tiering",
        "E. Amazon S3 Standard"
      ],
      "answer": "ad",
      "comments": [
        {
          "user": "Moon",
          "selected_answer": "AD",
          "content": "A: AWS CloudTrail\nD: Amazon S3 Intelligent-Tiering\n\nExplanation:\nA: AWS CloudTrail:\nAWS CloudTrail records all API calls made to AWS services, including Amazon Bedrock, and provides detailed logs of these interactions. It is the primary service for tracking and logging API requests.\nD: Amazon S3 Intelligent-Tiering:\nAmazon S3 Intelligent-Tiering is a cost-effective storage class designed to optimize costs for data with unknown or changing access patterns. It automatically moves data between frequent and infrequent access tiers based on usage, ensuring cost efficiency while meeting long-term retention requirements.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "AD",
          "content": "To log all requests to the Amazon Bedrock API and retain them securely for 5 years at the lowest possible cost, use AWS CloudTrail for comprehensive logging and Amazon S3 Intelligent-Tiering for cost-effective, long-term storage.",
          "upvotes": 1
        },
        {
          "user": "may2021_r",
          "selected_answer": "AD",
          "content": "The correct answers are A and D. CloudTrail logs API calls, while S3 Intelligent-Tiering optimizes storage costs.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 129,
      "data_id": "939532",
      "url": "https://www.examtopics.com/discussions/amazon/view/155866-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company needs to monitor the performance of its ML systems by using a highly scalable AWS service.Which AWS service meets these requirements?",
      "choices": [
        "A. Amazon CloudWatch",
        "B. AWS CloudTrail",
        "C. AWS Trusted Advisor",
        "D. AWS Config"
      ],
      "answer": "a",
      "comments": []
    },
    {
      "category": "examtopics",
      "number": 130,
      "data_id": "939533",
      "url": "https://www.examtopics.com/discussions/amazon/view/155868-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An AI practitioner is developing a prompt for an Amazon Titan model. The model is hosted on Amazon Bedrock. The AI practitioner is using the model to solve numerical reasoning challenges. The AI practitioner adds the following phrase to the end of the prompt: “Ask the model to show its work by explaining its reasoning step by step.”Which prompt engineering technique is the AI practitioner using?",
      "choices": [
        "A. Chain-of-thought prompting",
        "B. Prompt injection",
        "C. Few-shot prompting",
        "D. Prompt templating"
      ],
      "answer": "a",
      "comments": [
        {
          "user": "chris_spencer",
          "selected_answer": "A",
          "content": "Chain-of-thought prompting\n\nChain-of-thought prompting improves the reasoning ability of large language models by prompting them to generate a series of intermediate steps that lead to the final answer of a multi-step problem.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 131,
      "data_id": "939534",
      "url": "https://www.examtopics.com/discussions/amazon/view/155869-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which AWS service makes foundation models (FMs) available to help users build and scale generative AI applications?",
      "choices": [
        "A. Amazon Q Developer",
        "B. Amazon Bedrock",
        "C. Amazon Kendra",
        "D. Amazon Comprehend"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "jerry00218",
          "selected_answer": "B",
          "content": "Amazon Bedrock is a fully managed service that provides access to a variety of high-performing foundation models from leading AI companies and Amazon itself. \nIt offers a single API for accessing different foundation models, allowing for easy experimentation and integration into applications.",
          "upvotes": 2
        },
        {
          "user": "chris_spencer",
          "selected_answer": "A",
          "content": "Amazon Q Developer\n\n!Amazon Q Developer helps you get the most from your data to easily build analytics, AI/ML, and generative AI applications faster. Create queries using natural language, get coding help for data pipelines, design ML models, and collaborate on AI projects with built-in data governance.\"\n\nhttps://aws.amazon.com/q/developer/",
          "upvotes": 1
        },
        {
          "user": "chris_spencer",
          "content": "B should be the correct answer !",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 132,
      "data_id": "939535",
      "url": "https://www.examtopics.com/discussions/amazon/view/155870-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is building a mobile app for users who have a visual impairment. The app must be able to hear what users say and provide voice responses.Which solution will meet these requirements?",
      "choices": [
        "A. Use a deep learning neural network to perform speech recognition.",
        "B. Build ML models to search for patterns in numeric data.",
        "C. Use generative AI summarization to generate human-like text.",
        "D. Build custom models for image classification and recognition."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "chris_spencer",
          "selected_answer": "A",
          "content": "A. Use a deep learning neural network to perform speech recognition.\n\nWhile C sounds feasible, it does not handle the input of the speeches",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 133,
      "data_id": "939536",
      "url": "https://www.examtopics.com/discussions/amazon/view/155871-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to enhance response quality for a large language model (LLM) for complex problem-solving tasks. The tasks require detailed reasoning and a step-by-step explanation process.Which prompt engineering technique meets these requirements?",
      "choices": [
        "A. Few-shot prompting",
        "B. Zero-shot prompting",
        "C. Directional stimulus prompting",
        "D. Chain-of-thought prompting"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "chris_spencer",
          "selected_answer": "D",
          "content": "Chain-of-thought prompting",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 134,
      "data_id": "939537",
      "url": "https://www.examtopics.com/discussions/amazon/view/155867-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to keep its foundation model (FM) relevant by using the most recent data. The company wants to implement a model training strategy that includes regular updates to the FM.Which solution meets these requirements?",
      "choices": [
        "A. Batch learning",
        "B. Continuous pre-training",
        "C. Static training",
        "D. Latent training"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "jerry00218",
          "selected_answer": "B",
          "content": "Answer: B. Continuous pre-training\n\nTo keep a foundation model (FM) updated with the most recent data on a regular basis, you need a training approach that continually integrates new information. Continuous pre-training fits this requirement because it periodically (or even continuously) retrains or fine-tunes the model with the latest data, ensuring relevance and improved performance.\n\nHere's why the other options are less suitable:\n\nA. Batch learning: Trains in large, discrete batches and may introduce significant delays between training cycles, potentially causing the model to become stale.\nC. Static training: Trains the model once and does not update it with new data, leading to outdated predictions.\nD. Latent training: Not a standard industry term or recognized strategy for regularly updating foundation models.",
          "upvotes": 2
        },
        {
          "user": "chris_spencer",
          "selected_answer": "B",
          "content": "Continuous pre-training involves regularly updating the foundation model (FM) with new data, ensuring the model stays relevant by incorporating the latest information.",
          "upvotes": 2
        },
        {
          "user": "rrgonzalez1992",
          "selected_answer": "B",
          "content": "To keep a foundation model (FM) relevant by using the most recent data and implementing a model training strategy that includes regular updates, the best solution is Continuous pre-training. This approach involves continuously updating the model with new data, ensuring that it remains current and effective",
          "upvotes": 2
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 135,
      "data_id": "939538",
      "url": "https://www.examtopics.com/discussions/amazon/view/155872-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "HOTSPOT -A company wants to develop ML applications to improve business operations and efficiency.Select the correct ML paradigm from the following list for each use case. Each ML paradigm should be selected one or more times.\n<img src=\"https://img.examtopics.com/aws-certified-ai-practitioner-aif-c01/image5.png\">",
      "choices": [],
      "answer": "",
      "comments": [
        {
          "user": "djeong95",
          "content": "Supervised Learning:\n\t•\tBinary Classification: Requires labeled data (two classes) to train the model.\n\t•\tMulti-Class Classification: Requires labeled data (more than two classes) to train the model.\n\nUnsupervised Learning:\n\t•\tK-means Clustering: Does not require labeled data; it identifies natural groupings in the data.\n\t•\tDimensionality Reduction: Typically unsupervised; it reduces the number of features based on the inherent structure of the data without using labels.",
          "upvotes": 1
        },
        {
          "user": "chris_spencer",
          "content": "Binary classification - supervised learning \nMulti-class classification -  supervised learning \n\nBoth techniques involved training models with labeled data\n\nK-means clustering - unsupervised learning\ngroups data based on similarity but not labels\n\nDimensionality reduction -  unsupervised learning\naim to reduces number of features in dataset and does not need labels",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 136,
      "data_id": "939539",
      "url": "https://www.examtopics.com/discussions/amazon/view/155873-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "Which option is a characteristic of AI governance frameworks for building trust and deploying human-centered AI technologies?",
      "choices": [
        "A. Expanding initiatives across business units to create long-term business value",
        "B. Ensuring alignment with business standards, revenue goals, and stakeholder expectations",
        "C. Overcoming challenges to drive business transformation and growth",
        "D. Developing policies and guidelines for data, transparency, responsible AI, and compliance"
      ],
      "answer": "d",
      "comments": [
        {
          "user": "OnePG",
          "selected_answer": "D",
          "content": "transparency",
          "upvotes": 1
        },
        {
          "user": "djeong95",
          "selected_answer": "D",
          "content": "D seems to be the best answer here",
          "upvotes": 1
        },
        {
          "user": "chris_spencer",
          "selected_answer": "D",
          "content": "D. Developing policies and guidelines for data, transparency, responsible AI, and compliance",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 137,
      "data_id": "939540",
      "url": "https://www.examtopics.com/discussions/amazon/view/155936-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "An ecommerce company is using a generative AI chatbot to respond to customer inquiries. The company wants to measure the financial effect of the chatbot on the company’s operations.Which metric should the company use?",
      "choices": [
        "A. Number of customer inquiries handled",
        "B. Cost of training AI models",
        "C. Cost for each customer conversation",
        "D. Average handled time (AHT)"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "jerry00218",
          "selected_answer": "C",
          "content": "Answer: C. Cost for each customer conversation\n\nTo measure the financial effect of a generative AI chatbot on an ecommerce company’s operations, you want a metric that reflects the cost impact of each interaction. “Cost for each customer conversation” captures how much the company is spending per inquiry handled by the chatbot. This lets you directly compare the chatbot’s operational expenses versus human-agent costs or other support channels.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 138,
      "data_id": "939541",
      "url": "https://www.examtopics.com/discussions/amazon/view/155916-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to find groups for its customers based on the customers’ demographics and buying patterns.Which algorithm should the company use to meet this requirement?",
      "choices": [
        "A. K-nearest neighbors (k-NN)",
        "B. K-means",
        "C. Decision tree",
        "D. Support vector machine"
      ],
      "answer": "b",
      "comments": [
        {
          "user": "chris_spencer",
          "selected_answer": "B",
          "content": "K-means is a clustering algorithm",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 139,
      "data_id": "939542",
      "url": "https://www.examtopics.com/discussions/amazon/view/155917-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company’s large language model (LLM) is experiencing hallucinations.How can the company decrease hallucinations?",
      "choices": [
        "A. Set up Agents for Amazon Bedrock to supervise the model training.",
        "B. Use data pre-processing and remove any data that causes hallucinations.",
        "C. Decrease the temperature inference parameter for the model.",
        "D. Use a foundation model (FM) that is trained to not hallucinate."
      ],
      "answer": "c",
      "comments": [
        {
          "user": "chris_spencer",
          "selected_answer": "C",
          "content": "Decreasing the temperature reduces the variety of answer and forcing the model to focus on the tuned patterns",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 140,
      "data_id": "939543",
      "url": "https://www.examtopics.com/discussions/amazon/view/155918-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company is using a large language model (LLM) on Amazon Bedrock to build a chatbot. The chatbot processes customer support requests. To resolve a request, the customer and the chatbot must interact a few times.Which solution gives the LLM the ability to use content from previous customer messages?",
      "choices": [
        "A. Turn on model invocation logging to collect messages.",
        "B. Add messages to the model prompt.",
        "C. Use Amazon Personalize to save conversation history.",
        "D. Use Provisioned Throughput for the LLM."
      ],
      "answer": "b",
      "comments": [
        {
          "user": "jerry00218",
          "selected_answer": "B",
          "content": "Answer: B. Add messages to the model prompt\n\nLarge language models (LLMs) typically rely on the context that is provided directly in the input prompt when generating a response. To give the model the ability to use content from previous customer messages, you need to include those past messages in the prompt for each new inference call. This approach ensures that the model has the necessary context to respond accurately based on prior interactions.",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 141,
      "data_id": "939544",
      "url": "https://www.examtopics.com/discussions/amazon/view/155919-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company’s employees provide product descriptions and recommendations to customers when customers call the customer service center. These recommendations are based on where the customers are located. The company wants to use foundation models (FMs) to automate this process.Which AWS service meets these requirements?",
      "choices": [
        "A. Amazon Macie",
        "B. Amazon Transcribe",
        "C. Amazon Bedrock",
        "D. Amazon Textract"
      ],
      "answer": "c",
      "comments": [
        {
          "user": "chris_spencer",
          "selected_answer": "C",
          "content": "C. Amazon Bedrock",
          "upvotes": 1
        }
      ]
    },
    {
      "category": "examtopics",
      "number": 142,
      "data_id": "939545",
      "url": "https://www.examtopics.com/discussions/amazon/view/155920-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/",
      "question": "A company wants to upload customer service email messages to Amazon S3 to develop a business analysis application. The messages sometimes contain sensitive data. The company wants to receive an alert every time sensitive information is found.Which solution fully automates the sensitive information detection process with the LEAST development effort?",
      "choices": [
        "A. Configure Amazon Macie to detect sensitive information in the documents that are uploaded to Amazon S3.",
        "B. Use Amazon SageMaker endpoints to deploy a large language model (LLM) to redact sensitive data.",
        "C. Develop multiple regex patterns to detect sensitive data. Expose the regex patterns on an Amazon SageMaker notebook.",
        "D. Ask the customers to avoid sharing sensitive information in their email messages."
      ],
      "answer": "a",
      "comments": [
        {
          "user": "djeong95",
          "selected_answer": "A",
          "content": "If using S3 and PII is a concern, probably Macie is the answer.",
          "upvotes": 1
        },
        {
          "user": "chris_spencer",
          "selected_answer": "A",
          "content": "A. Anything related to PII, always think of Macie",
          "upvotes": 1
        }
      ]
    }
  ]