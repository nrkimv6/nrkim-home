[
  {
    "id": 1,
    "title": "1. 🎓 AWS Certified AI Practitioner 과정 개요",
    "startTime": "00:00:00.000",
    "endTime": "00:04:00.000",
    "items": [
      {
        "id": 1,
        "content": "**AWS Certified AI Practitioner**( **AIFC01**) 과정은 AI 클라우드 작업 및 **AWS**제공을 이해하는 데 필요한 기본 지식을 배우는 과정이다.",
        "shortcut": 2
      },
      {
        "id": 2,
        "content": "이 인증은 **AI 엔지니어**또는 **데이터 과학자**가 되려고 하거나 AI 관련 작업을 수행해야 하는 개발자에게 유용하며, 비즈니스 사용 사례를 설계하는 데 도움을 준다.",
        "shortcut": 11
      },
      {
        "id": 3,
        "content": "과정 수료를 위해 약 10시간의 평균 공부 시간이 필요하며, 강의와 실습을 병행하여 학습할 것을 권장한다.",
        "shortcut": 23
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 2,
    "title": "2. 📋 AWS 인증 시험 정보 요약",
    "startTime": "00:04:45.000",
    "endTime": "00:08:45.000",
    "items": [
      {
        "id": 4,
        "content": "기본 모델은 기초 모델(foundation models)뿐만 아니라 모델의 사전 경험을 강조하고 있다. 하지만 도메인 4와 5는 AI의 책임 지침과 보안, 규정 준수, 거버넌스 및 **AI 솔루션**을 다루며, 여기에 대한 내용은 제한적이다.",
        "shortcut": 2
      },
      {
        "id": 5,
        "content": "**AWS**는 Pearson Vue를 통해 온라인 시험을 제공하며, 과거의 PSI는 더 이상 사용되지 않는다. 이는 **AWS**가 단일 제공자를 통해 플랫폼을 극대화하려는 전략으로 보인다.",
        "shortcut": 10
      },
      {
        "id": 6,
        "content": "시험의 통과 점수는 1,000점 만점에 700점이며, 실제로 70%정도면 실패할 수 있다는 점을 유념해야 한다.",
        "shortcut": 15
      },
      {
        "id": 7,
        "content": "총 65문제가 출제되며, 그 중 50문제가 채점되고 15문제는 비채점 문제로, 이들은 새로운 문제 도입을 평가하기 위해 사용된다.",
        "shortcut": 18
      },
      {
        "id": 8,
        "content": "시험 시간은 2.5시간이며, 문제당 약 1.5분이 주어진다. 이 시간에는 안내 읽기, 온라인 감독을 받는 시간 등이 포함된다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 3,
    "title": "3. 📚 인증의 가치와 AI 학습 경험",
    "startTime": "00:09:32.000",
    "endTime": "00:11:32.000",
    "items": [
      {
        "id": 9,
        "content": "인증은 학습을 구조화된 방식으로 제공하며 목표 설정에 기여한다. 하지만 최근에는 인증이 단지 학습 경로로 기능하는 경향이 있다.",
        "shortcut": 1
      },
      {
        "id": 10,
        "content": "**AI 엔지니어** 또는 **데이터 과학자**로 일하기 위해서는 추가적으로 250~500시간의 학습이 필요하다. 따라서 단순한 인증만으로는 불충분할 수 있다.",
        "shortcut": 5
      },
      {
        "id": 11,
        "content": "실습실(labs)을 추가하여 실전에서의 기술 격차를 해소하는 데 도움을 준다. 실습을 통해 실제 기술을 배우는 것이 중요하다.",
        "shortcut": 7
      },
      {
        "id": 12,
        "content": "인증은 마케팅 도구로 사용되며, 서비스 선택에 있어 진정한 정보를 제공받는 것이 필요하다. **AWS**커뮤니티의 일원으로서 신뢰할 수 있는 정보를 전파하고자 한다.",
        "shortcut": 18
      },
      {
        "id": 13,
        "content": "비용 관리에 대한 책임은 개인에게 있으며, 예기치 않은 지출이 발생할 수 있다. 특정 서비스의 UI가 불량하여 오해를 불러일으킬 수 있으므로 주의가 요구된다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 4,
    "title": "4. 📚 AWS AI Practitioner 인증 개요",
    "startTime": "00:12:06.000",
    "endTime": "00:14:06.000",
    "items": [
      {
        "id": 14,
        "content": "**AWS Certified AI Practitioner**시험은 현재 베타로 진행 중이며, 베타 시험은 질문이 변경될 가능성이 크므로 출시 후에 응시할 것을 추천한다.",
        "shortcut": 5
      },
      {
        "id": 15,
        "content": "인증을 받기 위해서는 **AWS** Cloud Practitioner 자격증을 먼저 취득해야 하며, 특정 기술적 작업이나 코딩 능력이 요구되지 않는다.",
        "shortcut": 13
      },
      {
        "id": 16,
        "content": "실습 경험은 중요하며, 학습 내용을 더욱 강하게 심어줄 수 있는 방식이므로 Hands-on labs를 추천한다.",
        "shortcut": 17
      },
      {
        "id": 17,
        "content": "시험 질문 유형에는 단답형, 다중 응답, 정렬, 매칭, 사례 연구 등의 새로운 질문 형식이 포함되어 있으며, 최소 통과 점수는 700점이다.",
        "shortcut": 22
      },
      {
        "id": 18,
        "content": "시험 영역으로는 AI, ML 기초, 생성 AI의 기초, 기초 모델 응용, **책임 있는 AI** 지침 및 보안 등이 포함된다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 5,
    "title": "5. 💻 AI 워크로드와 서비스 개요",
    "startTime": "00:14:53.000",
    "endTime": "00:15:53.000",
    "items": [
      {
        "id": 19,
        "content": "현재 베타 단계에 있어 확실히 어떤 내용이 나올지 uncertain한 상황이다.",
        "shortcut": 1
      },
      {
        "id": 20,
        "content": "인식된 앱 AI 워크로드에 대해 언제 사용해야 하고, 사용하지 말아야 하는지를 다룬다.",
        "shortcut": 3
      },
      {
        "id": 21,
        "content": "모든 관리형 서비스를 포괄적으로 다루며, SageMaker와 ML 파이프라인의 핵심 기능과 서비스를 소개한다.",
        "shortcut": 5
      },
      {
        "id": 22,
        "content": "모델 성과에 대한 세부 설명이 포함되며, 나중에 유용하게 사용될 수 있는 정보로 추가적인 시간을 할애하고 있다.",
        "shortcut": 7
      },
      {
        "id": 23,
        "content": "Gen AI에 대한 많은 정보가 포함되어 있으며, 여러 프로젝트 경험을 통해 유용한 내용을 담았다.",
        "shortcut": 9
      },
      {
        "id": 24,
        "content": "🚫 제품 평가Amazon Q에 대한 평가가 부정적이며, 지속적으로 개선되고 있다고 주장하지만 실제로는 성능이 좋지 않다. 제품에 대해 긍정적인 의견이 없으며, 개선이 이루어질 가능성은 있으나 현재 상태는 불만족스럽다.",
        "shortcut": 13
      },
      {
        "id": 25,
        "content": "Amazon Q에 대한 평가가 부정적이며, 지속적으로 개선되고 있다고 주장하지만 실제로는 성능이 좋지 않다.",
        "shortcut": 13
      },
      {
        "id": 26,
        "content": "제품에 대해 긍정적인 의견이 없으며, 개선이 이루어질 가능성은 있으나 현재 상태는 불만족스럽다.",
        "shortcut": 17
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 6,
    "title": "6. 🤖 인공지능의 정의와 하위 분야",
    "startTime": "00:16:20.000",
    "endTime": "00:20:20.000",
    "items": [
      {
        "id": 27,
        "content": "**인공지능**(AI)은 인간의 행동을 모방하여 작업을 수행하는 컴퓨터 시스템을 의미하며, 이는 종종 문제 해결, 의사 결정, 자연어 이해, 음성 및 이미지 인식과 같은 작업을 포함한다.",
        "shortcut": 23
      },
      {
        "id": 28,
        "content": "기계 학습(ML)은 명시적인 프로그래밍 없이 작업에서 개선되는 머신을 지칭하며, 여러 복잡한 알고리즘을 통해 주어진 작업을 수행할 수 있다.",
        "shortcut": 27
      },
      {
        "id": 29,
        "content": "심층 학습(Deep Learning)은 인간의 뇌에 영감을 받은 인공 신경망을 사용하는 머신으로, 복잡한 문제를 해결하는 데 주력한다.",
        "shortcut": 30
      },
      {
        "id": 30,
        "content": "생성적 **인공지능**(Generative AI)은 내용을 생성하는 특수한 하위 분야로, 이미지, 비디오, 텍스트, 오디오 등을 만들어내며, 대개 심층 학습을 활용한다.",
        "shortcut": 35
      },
      {
        "id": 31,
        "content": "용어 사용이 혼란스러울 수 있으나, 일반적으로 AI라는 용어가 ML이나 심층 학습을 지칭하는 경우도 많으며, 이러한 혼동을 이해하고 사용하는 것이 중요하다.",
        "shortcut": 20
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 7,
    "title": "7. 🤖 AI와 생성 AI의 차이점",
    "startTime": "00:21:05.000",
    "endTime": "00:25:05.000",
    "items": [
      {
        "id": 32,
        "content": "AI의 목표는 인간의 행동을 해석, 분석, 및 반응하는 것이다. 이는 기계에서 인간 지능을 시뮬레이션하는 것을 목적으로 한다.",
        "shortcut": 1
      },
      {
        "id": 33,
        "content": "생성 AI는 새로운 콘텐츠나 데이터를 생성하는 데 초점을 맞춘 AI의 하위 집합으로, 텍스트, 이미지, 음악 등 다양한 형태의 미디어를 생성할 수 있다.",
        "shortcut": 10
      },
      {
        "id": 34,
        "content": "AI는 기존 데이터 기반의 이해와 결정에 중점을 두지만, 생성 AI는 기존 데이터를 활용하여 신선한 출력을 만들어 낸다.",
        "shortcut": 20
      },
      {
        "id": 35,
        "content": "적용 분야에서 AI는 데이터 분석, 자동화, 의료 등 다양한 분야에 걸쳐 있으며, 반면 생성 AI는 창의적이고 혁신적이며 콘텐츠 생성과 합성 데이터 생성에 중점을 둔다.",
        "shortcut": 23
      },
      {
        "id": 36,
        "content": "생성 AI는 종종 대형 언어 모델(LLM)과 혼재되지만, 이는 AI의 한 방식에 불과하다는 점에서 주의가 필요하다.",
        "shortcut": 16
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 8,
    "title": "8. 📝 JupyterLab 및 JupyterHub 개요",
    "startTime": "00:25:46.000",
    "endTime": "00:26:46.000",
    "items": [
      {
        "id": 37,
        "content": "JupyterLab는 다음 세대의 웹 기반 사용자 인터페이스로, 기존 Jupyter Notebook과 유사한 기능을 제공하지만 더 유연하고 강력한 사용자 인터페이스를 갖추고 있다.",
        "shortcut": 2
      },
      {
        "id": 38,
        "content": "JupyterLab은 노트북, 터미널, 텍스트 편집기, 파일 탐색기, 풍부한 출력 등을 포함하며, 화면의 측면에 탭이 있는 구조로 기능을 제공한다.",
        "shortcut": 4
      },
      {
        "id": 39,
        "content": "JupyterLab은 기존 Jupyter Notebook을 대체하는 방향으로 발전하고 있지만, 특정 환경에서는 기존 노트북도 여전히 사용되고 있어 완전한 대체는 아닐 수 있다.",
        "shortcut": 5
      },
      {
        "id": 40,
        "content": "JupyterHub는 여러 사용자를 위해 JupyterLab을 실행하는 서버로, 학생의 수업, 기업의 데이터 과학 그룹, 과학 연구 그룹 등을 대상으로 설계되었다.",
        "shortcut": 7
      },
      {
        "id": 41,
        "content": "JupyterLab과 유사한 노트북 경험을 제공하는 다른 툴들이 있으며, SageMaker Studio Classic이나 VS Code와 같은 확장성이 있는 솔루션도 존재한다.",
        "shortcut": 10
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 9,
    "title": "9. 🧠 자연어 처리(NLP)의 기초",
    "startTime": "00:27:25.000",
    "endTime": "00:31:25.000",
    "items": [
      {
        "id": 42,
        "content": "자연어 처리는 **머신러닝**에서 텍스트의 맥락을 이해하는 기술이다.",
        "shortcut": 1
      },
      {
        "id": 43,
        "content": "코퍼스는 관련된 텍스트의 집합으로, 자연어 처리를 위해 작업하는 텍스트를 의미한다.",
        "shortcut": 3
      },
      {
        "id": 44,
        "content": "NLP는 컴퓨터 과학과 언어학이 교차하는 지점으로, 알고리즘을 통해 구술 및 서면 언어를 이해하게 한다.",
        "shortcut": 4
      },
      {
        "id": 45,
        "content": "NLP는 문서, 이메일, 메시지를 분석하고 해석하며, 감정 분석, 음성 합성, 자동 번역 등의 작업을 가능하게 한다.",
        "shortcut": 5
      },
      {
        "id": 46,
        "content": "언어 이해는 NLP의 더 전문화된 하위 분야로, 고전적인 NLP 방법을 더욱 깊게 이해하는 과정이다.",
        "shortcut": 6
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 10,
    "title": "10. 📊 회귀 분석, 분류 및 클러스터링 개념",
    "startTime": "00:31:32.000",
    "endTime": "00:35:32.000",
    "items": [
      {
        "id": 47,
        "content": "회귀 분석은 레이블 데이터 세트를 연속 변수와 상관시키기 위한 함수 찾기 과정으로, 예측할 변수를 시각화하고 회귀선을 그려 미래의 변수를 예측한다.",
        "shortcut": 1
      },
      {
        "id": 48,
        "content": "회귀선과의 거리에서 점이 회귀선과 가까울수록 예측이 정확하고, 멀리 떨어질수록 오차로 평가된다.",
        "shortcut": 7
      },
      {
        "id": 49,
        "content": "분류는 레이블 데이터 세트를 여러 클래스나 카테고리로 나누는 방식으로, 예를 들어 특정 날씨 예측(맑음/비)에서 데이터를 그래프 상에서 분류선으로 나눈다.",
        "shortcut": 11
      },
      {
        "id": 50,
        "content": "클러스터링은 레이블이 없는 데이터를 유사성과 차이에 따라 그룹화하는 과정으로, 예를 들어 Windows와 Mac 컴퓨터 그룹을 식별하는 것과 같다.",
        "shortcut": 18
      },
      {
        "id": 51,
        "content": "기계 학습에서는 감독 학습, 비감독 학습, 강화 학습이라는 세 가지 학습 문제 유형이 있으며, 감독 학습은 레이블이 있는 데이터를 포함하고, 비감독 학습은 레이블 없는 데이터로 작업하며, 강화 학습은 환경에서 작동하는 에이전트가 피드백을 통해 배우는 과정이다.",
        "shortcut": 27
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 11,
    "title": "11. 🧠 머신러닝의 다양한 학습 방법 이해하기",
    "startTime": "00:36:00.000",
    "endTime": "00:40:00.000",
    "items": [
      {
        "id": 52,
        "content": "강화학습은 데이터가 없을 때 모델이 시행착오를 통해 올바른 행동을 찾는 방식으로, 게임 AI와 자율주행차에서 사용된다.",
        "shortcut": 2
      },
      {
        "id": 53,
        "content": "혼합 학습 문제로는 반지도 학습, 자기지도 학습, 다중 인스턴스가 있으며, 반지도 학습은 레이블이 있는 데이터와 없는 데이터가 섞여 있는 형태이다.",
        "shortcut": 4
      },
      {
        "id": 54,
        "content": "통계적 추론의 방법으로는 유도, 연역, 전이적 추론이 있으며, 각각 주어진 증거를 기반으로 결과를 도출하는 방식이다.",
        "shortcut": 11
      },
      {
        "id": 55,
        "content": "학습 기술에는 멀티태스크, 능동 학습, 온라인 학습, 전이 학습, 앙상블이 포함되어 있으며, 앙상블 방법은 여러 모델이 동일 데이터에 적합되며 예측 결과를 결합하는 방식이다.",
        "shortcut": 15
      },
      {
        "id": 56,
        "content": "고전 **머신러닝**은 간단하고 명확한 특성이 있는 데이터를 사용하며, 일반적으로 비용 효율성이 뛰어난 특징이 있다.",
        "shortcut": 24
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 12,
    "title": "12. 🤖 감독 학습과 비감독 학습의 개념",
    "startTime": "00:40:48.000",
    "endTime": "00:44:48.000",
    "items": [
      {
        "id": 57,
        "content": "감독 학습은 라벨이 붙은 데이터를 제공하며, 이를 통해 기계가 결과를 학습하고 예측할 수 있게 한다. 여기에는 분류와 회귀가 포함된다.",
        "shortcut": 3
      },
      {
        "id": 58,
        "content": "비감독 학습은 라벨이 없는 데이터를 기반으로 패턴을 발견하는 방법으로, 기계가 스스로 라벨을 적용한다. 이 과정에서 데이터 드리븐 방식으로 운영된다.",
        "shortcut": 11
      },
      {
        "id": 59,
        "content": "비감독 학습의 예로는 군집화, 차원 축소, 그리고 연관 규칙 학습이 있다. 이러한 방법은 특정한 예측을 필요로 하지 않는다.",
        "shortcut": 13
      },
      {
        "id": 60,
        "content": "전반적으로 감독 학습은 정확도가 높지만 사전 작업이 더 필요하고, 비감독 학습은 결과 검증을 위해 인간의 개입이 필요하다.",
        "shortcut": 30
      },
      {
        "id": 61,
        "content": "마지막으로, 강화 학습은 데이터가 없는 환경에서 ML 모델이 목표에 도달하기 위해 여러 시도를 하며 데이터를 생성하는 방법으로 정의된다.",
        "shortcut": 43
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 13,
    "title": "13. 🧠 머신러닝 모델과 신경망의 이해",
    "startTime": "00:45:00.000",
    "endTime": "00:49:00.000",
    "items": [
      {
        "id": 62,
        "content": "분류는 데이터 세트를 클래스나 범주로 나누는 과정을 의미하며, 이 과정에는 로지스틱 회귀, k-최근접 이웃, 지원 벡터 머신, 결정 트리 등의 다양한 알고리즘이 사용된다.",
        "shortcut": 6
      },
      {
        "id": 63,
        "content": "회귀는 데이터 세트를 연속 변수로 상관시키는 과정으로, 여기에는 단순 선형 회귀, 다중 선형 회귀, 다항 회귀 등이 포함된다.",
        "shortcut": 12
      },
      {
        "id": 64,
        "content": "비지도 학습에서 군집화는 유사성과 차이를 기준으로 레이블이 없는 데이터를 그룹핑하는 과정이며, k-평균 및 DBSCAN과 같은 여러 알고리즘이 존재한다.",
        "shortcut": 16
      },
      {
        "id": 65,
        "content": "연관성은 변수 간의 관계를 발견하는 과정으로, 예를 들어, 빵을 구매한 고객에게 버터를 추천하는 방식으로 작용한다.",
        "shortcut": 19
      },
      {
        "id": 66,
        "content": "신경망은 뇌를 모방한 구조로, 여러 개의 층으로 구성되어 있으며, 입력층, 여러 개의 숨은 층, 출력층으로 이루어져 있다. 심층 학습은 세 개 이상의 숨은 층을 가진 경우를 의미한다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 14,
    "title": "14. 🧠 신경망의 기본 개념",
    "startTime": "00:49:12.000",
    "endTime": "00:53:12.000",
    "items": [
      {
        "id": 67,
        "content": "피드포워드 신경망(FNN)은 노드 간의 연결이 사이클이 형성되지 않아 데이터가 항상 한 방향으로 진행되며, 후방전파(backpropagation) 과정을 통해 다음 iteration의 결과를 개선하기 위해 가중치를 조정하는 방법이다.",
        "shortcut": 2
      },
      {
        "id": 68,
        "content": "손실 함수(loss function)는 예측값과 실제값(ground truth) 간의 오차를 비교하여 네트워크의 성능을 평가하는 데 사용되며, ground truth는 레이블이 붙은 정확한 데이터이다.",
        "shortcut": 11
      },
      {
        "id": 69,
        "content": "활성화 함수(activation function)는 은닉층 노드에 적용되는 알고리즘으로, 이러한 함수는 출력에 영향을 미치며 RELU와 같은 예가 있다.",
        "shortcut": 16
      },
      {
        "id": 70,
        "content": "퍼셉트론(perceptron)은 1943년에 발명된 이진 분류를 위한 감독 학습 알고리즘으로, 1957년에는 이미지 인식 기능을 가진 Mark I 퍼셉트론 기계가 개발되었다.",
        "shortcut": 31
      },
      {
        "id": 71,
        "content": "신경망의 구조는 다수의 입력과 출력 레이어로 구성되며, 입력 레이어의 노드 수는 입력 벡터의 차원에 따라 결정되고, 입력 차원이 증가하면 밀도가 높아진(dense) 구조를 가진다.",
        "shortcut": 43
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 15,
    "title": "15. 🤖 신경망의 입력 및 출력 레이어 이해",
    "startTime": "00:54:11.000",
    "endTime": "00:56:11.000",
    "items": [
      {
        "id": 72,
        "content": "입력 레이어는 연결점으로만 작용하며, 데이터 수정 없이 시작 지점 역할을 한다.",
        "shortcut": 1
      },
      {
        "id": 73,
        "content": "출력 레이어의 노드 개수는 신경망의 적용에 따라 결정된다.",
        "shortcut": 2
      },
      {
        "id": 74,
        "content": "예/아니오 분류의 경우 단일 출력 노드가 필요하며, 이는 0 또는 1을 판별하는 역할을 한다.",
        "shortcut": 3
      },
      {
        "id": 75,
        "content": "데이터는 각 노드 사이를 가중치에 의해 곱해지며, 이는 조정하고자 하는 값의 강도나 약도를 나타낸다.",
        "shortcut": 5
      },
      {
        "id": 76,
        "content": "가중치는 훈련 과정을 통해 수정되어 더 나은 결과를 산출하도록 한다.",
        "shortcut": 6
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 16,
    "title": "16. 🔑 활성화 함수의 역할과 종류",
    "startTime": "00:56:15.000",
    "endTime": "00:59:15.000",
    "items": [
      {
        "id": 77,
        "content": "활성화 함수는 노드 간의 게이트 역할을 하며, 출력이 다음 레이어로 전달될지를 결정한다.",
        "shortcut": 1
      },
      {
        "id": 78,
        "content": "활성화 함수는 노드의 활성화 여부를 결정하며, 출력 범위는 0에서 1 또는 -1에서 0으로 설정될 수 있다.",
        "shortcut": 2
      },
      {
        "id": 79,
        "content": "선형 활성화 함수는 데이터 전파 기능은 있으나, 역전파를 수행할 수 없고, 복잡한 비선형 데이터를 처리하지 못한다.",
        "shortcut": 7
      },
      {
        "id": 80,
        "content": "비선형 활성화 함수는 역전파 가능하며, 여러 레이어를 쌓을 수 있다.",
        "shortcut": 9
      },
      {
        "id": 81,
        "content": "주요 활성화 함수로는 ReLU, Leaky ReLU, Tanh, Sigmoid, Softmax 등이 있으며 각자 특징과 문제 점이 존재한다.",
        "shortcut": 17
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 17,
    "title": "17. 🔍 활성화 함수의 종류와 특징",
    "startTime": "00:59:28.000",
    "endTime": "01:00:28.000",
    "items": [
      {
        "id": 82,
        "content": "이 범위는 무한하여, 도함수는 1이다. 즉, 이 함수는 입력한 값에 따라서 결과가 나오는 특징을 가지고 있다.",
        "shortcut": 1
      },
      {
        "id": 83,
        "content": "이진 단계 활성화 함수는 0 또는 1을 반환하며, 입력값이 0 이하일 경우 0을, 0보다 클 경우 1을 반환한다.",
        "shortcut": 6
      },
      {
        "id": 84,
        "content": "이 함수는 이진 분류만 처리할 수 있도록 설계되어, 0 또는 1, 즉 켜짐 또는 꺼짐을 표현한다. 그러나 범위는 0과 1로 제한된다.",
        "shortcut": 10
      },
      {
        "id": 85,
        "content": "시그모이드 활성화 함수는 S자 형태의 로지스틱 곡선을 형성하며, 이진 또는 다중 분류 문제를 처리할 수 있다.",
        "shortcut": 15
      },
      {
        "id": 86,
        "content": "출력을 위한 활성화 함수로서, 시그모이드 함수는 예측에 있어 명확한 구분을 제공하며 활성화를 0과 1 사이로 끌어당기는 경향이 있다.",
        "shortcut": 18
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 18,
    "title": "18. ⚙️ 활성화 함수와 기울기 문제",
    "startTime": "01:01:01.000",
    "endTime": "01:04:01.000",
    "items": [
      {
        "id": 87,
        "content": "Vanishing gradient는 네트워크가 더 이상 학습하지 않거나 학습이 매우 느려지는 현상이다.",
        "shortcut": 2
      },
      {
        "id": 88,
        "content": "Sigmoid 함수는 거의 모든 뉴런이 활성화되지만, 느리고 비용이 많이 든다.",
        "shortcut": 6
      },
      {
        "id": 89,
        "content": "Tanh 함수는 sigmoid와 유사하지만, 더 넓은 범위(-1에서 1)에서 빠른 기울기를 제공하여 다중 분류 문제에 적합하다.",
        "shortcut": 16
      },
      {
        "id": 90,
        "content": "ReLU(Rectified Linear Unit)는 양수 축에서 선형이며, 음수 축은 항상 0이다. 이는 효율적이지만 ReLU dying gradient 문제로 인해 기울기가 0이 되는 부작용이 있다.",
        "shortcut": 23
      },
      {
        "id": 91,
        "content": "Leaky ReLU는 음수 축에서 부드러운 기울기를 제공하여 뉴런이 활성화되지 않는 경우에도 작은 양의 값을 유지하도록 한다.",
        "shortcut": 37
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 19,
    "title": "19. 🤖 다양한 활성화 함수 소개",
    "startTime": "01:04:36.000",
    "endTime": "01:08:36.000",
    "items": [
      {
        "id": 92,
        "content": "ReLU는 기울기가 0이 되는 문제를 줄이기 위해 개선된 형태가 있으며, 이를 통해 일부 노드가 죽지 않도록 만든다.",
        "shortcut": 2
      },
      {
        "id": 93,
        "content": "ELU는 음의 축 방향으로 기울어져 있으며, 양의 축에서는 선형 기울기를 가지고 있어 활성화의 평균을 0에 가깝게 만든다.",
        "shortcut": 6
      },
      {
        "id": 94,
        "content": "Swish 함수는 음의 축에서 기울기가 감소하며, 부드러운 곡선을 가지고 있어 ReLU의 대안으로 제안되었다.",
        "shortcut": 15
      },
      {
        "id": 95,
        "content": "Maxout 함수는 여러 입력 중 최대 값을 선택하여 반환하는 방식으로, ReLU의 일반화된 형태이며, 죽은 ReLU 문제를 피할 수 있다.",
        "shortcut": 25
      },
      {
        "id": 96,
        "content": "Softmax 함수는 각 클래스에 대한 확률을 계산하며, 다중 분류 모델의 출력층에서 주로 사용된다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 20,
    "title": "20. 🤖 머신러닝 모델과 추론 이해하기",
    "startTime": "01:09:23.000",
    "endTime": "01:13:23.000",
    "items": [
      {
        "id": 97,
        "content": "KNN(K-최근접이웃 알고리즘)은 **머신러닝**이 아니지만, **머신러닝**문제를 해결하는데 적용될 때 **머신러닝**알고리즘이 된다.",
        "shortcut": 2
      },
      {
        "id": 98,
        "content": "모델은 객체, 사람 또는 시스템의 정보를 표현한 것이며, 구체적인 형태의 모델과 행동 패턴으로 표현된 추상적인 모델이 있다.",
        "shortcut": 4
      },
      {
        "id": 99,
        "content": "**머신러닝** 모델은 데이터를 입력받아 **머신러닝**알고리즘을 수행하고 예측을 생성하는 기능이다.",
        "shortcut": 6
      },
      {
        "id": 100,
        "content": "추론(Inference)은 데이터 입력 후 **머신러닝**모델이 예측을 제공하는 과정으로, 일반적으로 모델에 배포된 데이터에 대해 이루어진다.",
        "shortcut": 12
      },
      {
        "id": 101,
        "content": "모델 파라미터는 모델의 내부 상태를 구성하는 변수로, 학습 이후 값이 출력되며, 하이퍼파라미터는 모델 외부에 있는 변수로 학습 전에 수동으로 설정된다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 21,
    "title": "21. 🧠 모델 학습과 책임 있는 AI",
    "startTime": "01:14:05.000",
    "endTime": "01:17:05.000",
    "items": [
      {
        "id": 102,
        "content": "학습률, 에폭, 배치 크기는 **머신러닝**모델 학습에서 중요한 요소이다.",
        "shortcut": 1
      },
      {
        "id": 103,
        "content": "모델은 변수와 가중치로 이루어진 파라미터를 통해 연결되는 레이어로 구성된다.",
        "shortcut": 3
      },
      {
        "id": 104,
        "content": "교육을 위해 데이터를 모델에 전달할 때, 변수는 여러 레이어를 통과하며 설정된 파라미터에 따라 결과가 생성된다.",
        "shortcut": 4
      },
      {
        "id": 105,
        "content": "**AWS**에서 정의한 **책임 있는 AI**의 개념은 공정성, 설명 가능성, 프라이버시 및 보안과 같은 요소들로 구성된다.",
        "shortcut": 8
      },
      {
        "id": 106,
        "content": "데이터 라벨링은 **머신러닝**모델이 학습할 수 있도록 데이터를 의미 있는 라벨로 식별하는 과정이며, 이는 일반적으로 사람이 수행한다.",
        "shortcut": 27
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 22,
    "title": "22. 📊 데이터 마이닝 및 지식 마이닝 개념 이해",
    "startTime": "01:17:31.000",
    "endTime": "01:20:31.000",
    "items": [
      {
        "id": 107,
        "content": "그라운드 트루스는 모델 훈련 및 평가의 객관적 기준으로, 정확성은 훈련 모델의 정확도에 크게 의존한다. 또한, 이는 성공적인 모델을 위해 매우 중요하다.",
        "shortcut": 2
      },
      {
        "id": 108,
        "content": "데이터 마이닝은 대량의 데이터에서 패턴과 지식을 추출하는 과정으로, CRISP-DM 모델을 통해 여섯 가지 단계인 비즈니스 이해, 데이터 이해, 데이터 준비, 모델링, 평가 및 배치를 포함한다.",
        "shortcut": 7
      },
      {
        "id": 109,
        "content": "데이터 마이닝 기술은 기계 학습에서 유효한 패턴과 관계를 찾는 데 사용되며, 분류, 군집화, 회귀 및 연관 규칙, 이상치 탐지 등의 방법이 포함된다.",
        "shortcut": 9
      },
      {
        "id": 110,
        "content": "지식 마이닝은 AI의 한 분야로 정보를 빠르게 학습하여 숨겨진 인사이트를 발견하고 관계와 패턴을 대규모로 찾는 데 도움을 준다.",
        "shortcut": 16
      },
      {
        "id": 111,
        "content": "RAG (Retrieval-Augmented Generation)는 지식 마이닝과 많은 겹치는 점이 있으며, 데이터를 수집 및 풍부하게 하는 과정과 관련된 서비스들이 있으며, 이러한 서비스들은 **AWS**에서도 활용될 수 있다.",
        "shortcut": 27
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 23,
    "title": "23. 📊 데이터 변환 및 모델링의 중요성",
    "startTime": "01:21:15.000",
    "endTime": "01:25:15.000",
    "items": [
      {
        "id": 112,
        "content": "데이터 wrangling은 원시 데이터를 다른 형식으로 변환하고 매핑하는 과정으로, 분석 등 다양한 하위 용도를 위해 데이터의 가치를 높이는 것을 목표로 한다.",
        "shortcut": 5
      },
      {
        "id": 113,
        "content": "데이터 wrangling의 6가지 핵심 단계는 발견, 구조화, 청소, 보강, 검증, 출판이다.",
        "shortcut": 7
      },
      {
        "id": 114,
        "content": "데이터 모델링은 데이터 요소를 조직하고 이들이 서로 어떻게 관계하는지를 표준화하는 추상 모델이다.",
        "shortcut": 16
      },
      {
        "id": 115,
        "content": "데이터 모델은 개념적, 논리적, 물리적 모델로 분류될 수 있으며, 각 모델은 서로 다른 수준에서 데이터의 표현과 저장 방식을 정의한다.",
        "shortcut": 18
      },
      {
        "id": 116,
        "content": "데이터 분석은 유용한 정보를 추출하고 연구하기 위해 데이터를 검사, 변환 및 정리하는 과정이다. 이 과정에서 데이터 ingestion, 청소 및 변환, 차원 축소, 데이터 분석 및 시각화가 포함된다.",
        "shortcut": 26
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 24,
    "title": "24. 📊 데이터 과학 및 머신러닝의 기초 이해",
    "startTime": "01:25:41.000",
    "endTime": "01:27:41.000",
    "items": [
      {
        "id": 117,
        "content": "컴퓨터 과학의 중요성은 많은 **머신러닝**모델이 알고리즘에 기반하고 있기 때문에 필수적이다.",
        "shortcut": 1
      },
      {
        "id": 118,
        "content": "전통적인 수학 및 통계학 배경은 고전 **머신러닝**에 필수적이며, 이 분야는 통계에 크게 의존한다.",
        "shortcut": 3
      },
      {
        "id": 119,
        "content": "소프트웨어 개발 기술은 주로 파이썬을 작성하게 되므로 매우 중요하다.",
        "shortcut": 4
      },
      {
        "id": 120,
        "content": "성능이 중요한 경우에는 저수준 언어를 사용해야 할 필요가 있다.",
        "shortcut": 5
      },
      {
        "id": 121,
        "content": "데이터 과학에서의 책임감 있는 데이터 과학의 정의는 회사마다 다르며, 일반적으로 세 가지 분야 중 하나에서의 강력한 기술 전문성을 요구한다.",
        "shortcut": 9
      },
      {
        "id": 122,
        "content": "📊 데이터 역할 비교데이터 마이닝은 특정 데이터 세트에 대한 지식을 취득하고 이를 학습 또는 처리 목적으로 사용하는 것이다. 데이터 처리(wrangling)는 원시 데이터에서 또 다른 형식으로 변환 및 매핑하여 데이터 분석과 **머신러닝**에 적합하도록 만드는 과정이다. 데이터 분석은 기존 정보를 사용하여 실행 가능한 데이터를 발견하고 더 나은 비즈니스 의사결정을 위한 질문에 답하는 것이다. **데이터 과학자**는 수학, 통계학, 예측 모델링, 그리고 **머신러닝**에 대해 다학제적인 기술을 보유하고 있다. 데이터 엔지니어는 데이터 생성의 인프라와 아키텍처에 초점을 맞추고 **머신러닝**모델을 대규모로 배포한다.",
        "shortcut": 12
      },
      {
        "id": 123,
        "content": "데이터 마이닝은 특정 데이터 세트에 대한 지식을 취득하고 이를 학습 또는 처리 목적으로 사용하는 것이다.",
        "shortcut": 12
      },
      {
        "id": 124,
        "content": "데이터 처리(wrangling)는 원시 데이터에서 또 다른 형식으로 변환 및 매핑하여 데이터 분석과 **머신러닝**에 적합하도록 만드는 과정이다.",
        "shortcut": 13
      },
      {
        "id": 125,
        "content": "데이터 분석은 기존 정보를 사용하여 실행 가능한 데이터를 발견하고 더 나은 비즈니스 의사결정을 위한 질문에 답하는 것이다.",
        "shortcut": 14
      },
      {
        "id": 126,
        "content": "**데이터 과학자**는 수학, 통계학, 예측 모델링, 그리고 **머신러닝**에 대해 다학제적인 기술을 보유하고 있다.",
        "shortcut": 15
      },
      {
        "id": 127,
        "content": "데이터 엔지니어는 데이터 생성의 인프라와 아키텍처에 초점을 맞추고 **머신러닝**모델을 대규모로 배포한다.",
        "shortcut": 16
      },
      {
        "id": 128,
        "content": "📊 데이터 세트 유형데이터 세트는 훈련 데이터 세트, 검증 데이터 세트, 그리고 테스트 데이터 세트로 나뉜다. 훈련 데이터 세트는 모델이 학습할 실제 데이터이다. 검증 데이터 세트는 모델이 제대로 작동하는지를 확인하고 하이퍼파라미터 조정을 위해 사용된다. 테스트 데이터 세트는 모델이 재훈련된 후 최종 모델을 공정하게 평가하는 데 사용된다.",
        "shortcut": 17
      },
      {
        "id": 129,
        "content": "데이터 세트는 훈련 데이터 세트, 검증 데이터 세트, 그리고 테스트 데이터 세트로 나뉜다.",
        "shortcut": 17
      },
      {
        "id": 130,
        "content": "훈련 데이터 세트는 모델이 학습할 실제 데이터이다.",
        "shortcut": 18
      },
      {
        "id": 131,
        "content": "검증 데이터 세트는 모델이 제대로 작동하는지를 확인하고 하이퍼파라미터 조정을 위해 사용된다.",
        "shortcut": 19
      },
      {
        "id": 132,
        "content": "테스트 데이터 세트는 모델이 재훈련된 후 최종 모델을 공정하게 평가하는 데 사용된다.",
        "shortcut": 21
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 25,
    "title": "25. 📚 언어 분석을 위한 코퍼스와 코퍼스 언어학",
    "startTime": "01:28:08.000",
    "endTime": "01:30:08.000",
    "items": [
      {
        "id": 133,
        "content": "Ground truth 데이터는 올바른 것으로 라벨링된 데이터를 의미하며, 이는 모델의 테스트 수단으로 사용된다.",
        "shortcut": 2
      },
      {
        "id": 134,
        "content": "코퍼스는 자연적으로 발생하는 텍스트의 대규모 수집으로, 구조화된 방식으로 분석을 위해 사용된다.",
        "shortcut": 4
      },
      {
        "id": 135,
        "content": "코퍼스의 예로는 영어 사전을 작성하기 위한 텍스트 집합이나 학술 텍스트 생성을 위한 강의 및 세미나의 전사본이 있다.",
        "shortcut": 6
      },
      {
        "id": 136,
        "content": "코퍼스 언어학은 통계 분석을 통해 언어의 패턴을 찾고, 이는 텍스트에서 특정 단어의 사용 빈도나 구어 표현의 사용 여부 등을 분석하는 데 사용된다.",
        "shortcut": 10
      },
      {
        "id": 137,
        "content": "이 분야는 머신 러닝을 학습할 때 접하게 될 중요한 개념으로, 언어 사용의 패턴에 대해 이해하는 데 기여한다.",
        "shortcut": 13
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 26,
    "title": "26. 📊 데이터 세트 및 AI의 정의",
    "startTime": "01:30:13.000",
    "endTime": "01:34:13.000",
    "items": [
      {
        "id": 138,
        "content": "데이터 세트는 특정 목적을 위한 특정 종류의 데이터 항목으로 정의된다.",
        "shortcut": 1
      },
      {
        "id": 139,
        "content": "정성적 데이터는 질을 측정하는 반면, 정량적 데이터는 양을 측정한다.",
        "shortcut": 6
      },
      {
        "id": 140,
        "content": "정성적 데이터의 예시로는 범주형(순서 관계가 없는 단순 레이블), 이산형(세기적이고 유한한 값), 이진형(두 가지 옵션만 존재) 등이 있다.",
        "shortcut": 8
      },
      {
        "id": 141,
        "content": "정량적 데이터는 연속형(측정할 수 있는 무한한 값)과 구간형(제로 값 포함 및 비포함)으로 나뉜다.",
        "shortcut": 14
      },
      {
        "id": 142,
        "content": "**인공지능**(AI)는 인간의 지능을 요구하는 작업을 수행하는 컴퓨터 시스템으로, 문제 해결, 의사 결정 및 자연어 이해 등을 포함한다.",
        "shortcut": 20
      },
      {
        "id": 143,
        "content": "🤖 **생성적 AI**의 개념**생성적 AI**는 새로운 콘텐츠나 데이터를 생성하는 AI의 하위 집합으로, 데이터 해석 및 분석 뿐만 아니라 새로운 데이터를 생성하는 데 중점을 둔다. **생성적 AI**는 GANs, VAEs, GPTs와 같은 고급 **머신러닝**기술을 포함한다. **생성적 AI**는 비전, 텍스트, 오디오 등 다양한 모달리티를 가진다. **생성적 AI**의 한 응용 예는 유전자 정보를 활용한 신약 발견로, 이는 생명과학 분야와 관련이 있다. 대형 언어 모델(LLM)은 **생성적 AI**의 한 예로, 인간과 유사한 텍스트를 생성하는 능력이 있으며 다중 모달에서도 작동할 수 있다.",
        "shortcut": 36
      },
      {
        "id": 144,
        "content": "**생성적 AI**는 새로운 콘텐츠나 데이터를 생성하는 AI의 하위 집합으로, 데이터 해석 및 분석 뿐만 아니라 새로운 데이터를 생성하는 데 중점을 둔다.",
        "shortcut": 36
      },
      {
        "id": 145,
        "content": "**생성적 AI**는 GANs, VAEs, GPTs와 같은 고급 **머신러닝**기술을 포함한다.",
        "shortcut": 39
      },
      {
        "id": 146,
        "content": "**생성적 AI**는 비전, 텍스트, 오디오 등 다양한 모달리티를 가진다.",
        "shortcut": 41
      },
      {
        "id": 147,
        "content": "**생성적 AI**의 한 응용 예는 유전자 정보를 활용한 신약 발견로, 이는 생명과학 분야와 관련이 있다.",
        "shortcut": 44
      },
      {
        "id": 148,
        "content": "대형 언어 모델(LLM)은 **생성적 AI**의 한 예로, 인간과 유사한 텍스트를 생성하는 능력이 있으며 다중 모달에서도 작동할 수 있다.",
        "shortcut": 46
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 27,
    "title": "27. 🤖 AI와 생성 AI의 차이점",
    "startTime": "01:34:58.000",
    "endTime": "01:36:58.000",
    "items": [
      {
        "id": 149,
        "content": "AI는 의사 결정을 이해하는 데 중점을 두는 반면, 생성 AI는 새로운 결과물의 생성에 초점을 맞춘다.",
        "shortcut": 1
      },
      {
        "id": 150,
        "content": "생성 AI는 기존 데이터로부터 새로운 데이터와 보지 못한 출력을 생성하는 기능이 있어 AI와는 다른 이점을 가진다.",
        "shortcut": 4
      },
      {
        "id": 151,
        "content": "AI는 응용 가능성이 높고, 생성 AI는 창의적이고 혁신적인 합성물 생성에 중점을 둔다.",
        "shortcut": 5
      },
      {
        "id": 152,
        "content": "기초 모델은 방대한 데이터에서 훈련된 일반-purpose 모델로, 특정 작업을 위해 미세 조정할 수 있는 사전 훈련된 모델이다.",
        "shortcut": 9
      },
      {
        "id": 153,
        "content": "대규모 언어 모델(LLM)은 변환기 아키텍처를 사용하는 기초 모델의 전문화된 하위 집합이다.",
        "shortcut": 15
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 28,
    "title": "28. 🧠 LLMs와 Transformer 아키텍처의 이해",
    "startTime": "01:37:51.000",
    "endTime": "01:41:51.000",
    "items": [
      {
        "id": 154,
        "content": "모델은 훈련 과정에서 의미론 및 언어 패턴을 학습하여 언어를 해석하고 일관성 있는 출력을 제공하는 능력을 가지게 된다.",
        "shortcut": 1
      },
      {
        "id": 155,
        "content": "LLMs는 다음 단어를 예측하는 것처럼 보이지만, 실제로 그 출력 방식을 이해하기 어려운 복잡한 구조를 가지며 연구자들은 여전히 그 이유를 알지 못한다.",
        "shortcut": 3
      },
      {
        "id": 156,
        "content": "Transformer 아키텍처는 Google의 연구자들에 의해 개발되었으며, 멀티 헤드 주의(multi-head attention)와 위치 인코딩(positional encoding) 덕분에 자연어 처리에서 효과적이다.",
        "shortcut": 6
      },
      {
        "id": 157,
        "content": "Transformer는 인코더와 디코더 두 부분으로 구성되며, 인코더는 입력 텍스트를 읽고 이해하고, 디코더는 인코더가 학습한 내용을 기반으로 새로운 텍스트를 생성하는 역할을 한다.",
        "shortcut": 13
      },
      {
        "id": 158,
        "content": "입력 데이터는 토큰화(tokenization) 과정을 거쳐 작은 부분으로 나뉘며, 각 토큰은 모델의 어휘 내에서 고유한 ID를 부여받아야 한다.",
        "shortcut": 36
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 29,
    "title": "29. 🧠 LLM의 토큰화와 벡터 공간 모델",
    "startTime": "01:42:38.000",
    "endTime": "01:46:38.000",
    "items": [
      {
        "id": 159,
        "content": "LLM을 사용할 때, 입력 텍스트는 모델의 내부 어휘에 맞춰 시퀀스의 토큰으로 변환되어야 한다.",
        "shortcut": 3
      },
      {
        "id": 160,
        "content": "LLM이 훈련될 때 모든 지식을 기반으로 한 고유한 토큰의 내부 어휘가 생성되며, 이 모델의 토큰 수는 30,000에서 100,000개에 이를 수 있다.",
        "shortcut": 5
      },
      {
        "id": 161,
        "content": "메모리와 계산은 시퀀스 길이에 따라 증가하며, 토큰 수가 늘어날수록 메모리 사용량이 증가하고 연산이 더 많이 필요하다.",
        "shortcut": 13
      },
      {
        "id": 162,
        "content": "AI 서비스에서 모델 사용 시, 입력과 출력의 길이에 제한이 있으며, 큰 입력을 처리하면 생성할 수 있는 단어 수가 줄어들 수 있다.",
        "shortcut": 18
      },
      {
        "id": 163,
        "content": "문서나 데이터를 고차원 공간에서 벡터로 표현하는 벡터 공간 모델은 문서 간의 거리가 관계를 나타낸다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 30,
    "title": "30. 🧠 임베딩과 포지셔널 인코딩의 이해",
    "startTime": "01:47:37.000",
    "endTime": "01:50:37.000",
    "items": [
      {
        "id": 164,
        "content": "임베딩은 **머신러닝**모델이 데이터 간의 관계를 찾기 위해 사용하는 벡터 데이터이다.",
        "shortcut": 1
      },
      {
        "id": 165,
        "content": "특정 **머신러닝**모델들은 임베딩 생성 전용 모델로, Cohere와 같은 회사는 Command-R 임베딩을 통해 입력을 벡터 저장소에 배치할 임베딩 출력을 제공한다.",
        "shortcut": 3
      },
      {
        "id": 166,
        "content": "다양한 임베딩 알고리즘은 단어의 철자 유사성, 단어의 길이, 또는 특정 산업에 대한 문맥과 같은 관계를 캡처하고 이를 벡터 공간에 프로젝션하여 표현한다.",
        "shortcut": 6
      },
      {
        "id": 167,
        "content": "포지셔널 인코딩은 자연어 처리에서 단어의 순서를 유지하기 위해 필요하며, 변환기 모델은 이를 통해 데이터를 순차적으로 처리하지 않더라도 이해의 순서를 유지할 수 있다.",
        "shortcut": 12
      },
      {
        "id": 168,
        "content": "변환기의 선행 기술인 RNN은 순차적으로 작동하기 때문에 단어의 순서를 기억할 수 있지만, 이는 대량의 단어를 스케일링하는 데 어려움을 주었다.",
        "shortcut": 14
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 31,
    "title": "31. 🧠 자기 주의 및 다중 헤드 주의 메커니즘",
    "startTime": "01:51:08.000",
    "endTime": "01:52:08.000",
    "items": [
      {
        "id": 169,
        "content": "자기 주의는 동일한 입력 시퀀스 내에서 각 요소가 다른 모든 요소에 주의를 기울이는 방식으로 주의 가중치를 계산한다.",
        "shortcut": 2
      },
      {
        "id": 170,
        "content": "교차 주의는 두 개의 다른 시퀀스 간의 주의 가중치를 계산하여 한 시퀀스가 다른 시퀀스에 주의를 기울이도록 한다. 이는 번역과 같은 작업에서 필수적이다.",
        "shortcut": 4
      },
      {
        "id": 171,
        "content": "다중 헤드 주의는 여러 개의 자기 주의 또는 교차 주의 헤드를 병렬로 결합하여 다양한 입력의 측면에 집중할 수 있도록 한다.",
        "shortcut": 6
      },
      {
        "id": 172,
        "content": "다중 헤드 주의에서 Q, K, V는 각각 쿼리, 키, 값을 나타내며, 이는 검색 엔진의 작동 방식과 비슷하다.",
        "shortcut": 8
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 32,
    "title": "32. 🤖 Transformer 모델 및 Fine-Tuning 핵심 개념",
    "startTime": "01:52:43.000",
    "endTime": "01:56:43.000",
    "items": [
      {
        "id": 173,
        "content": "Self-attention은 자기 자신을 피드백하며 작동하므로, 같은 시퀀스를 반복적으로 처리하는 개념이다.",
        "shortcut": 1
      },
      {
        "id": 174,
        "content": "Multi-headed cross-attention은 V(값), K(키), Q(쿼리)를 포함하여 서로 다른 두 소스로부터 시퀀스를 입력받고 처리한다.",
        "shortcut": 2
      },
      {
        "id": 175,
        "content": "Fine-tuning은 모델 개선을 위해 중요한 과정이며, Hidden layer와 그 구성 요소를 이해해야 한다.",
        "shortcut": 12
      },
      {
        "id": 176,
        "content": "파라미터는 노드 간의 연결 가중치를 나타내며, 연결에 따라 하나 또는 여러 개의 파라미터를 가질 수 있다.",
        "shortcut": 26
      },
      {
        "id": 177,
        "content": "GPT-3는 96개의 layer와 1750억 개의 파라미터를 가진 대형 모델로, BERT는 12에서 24 layers를 가지며, T5는 12 encoder와 12 decoder layers를 포함하고 있다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 33,
    "title": "33. 🔧 파인튜닝(Fine-Tuning)의 정의와 과정",
    "startTime": "01:57:04.000",
    "endTime": "01:58:04.000",
    "items": [
      {
        "id": 178,
        "content": "파인튜닝은 사전 훈련된 모델의 가중치나 매개변수를 작은 데이터 세트에 대해 재훈련하는 과정이다.",
        "shortcut": 3
      },
      {
        "id": 179,
        "content": "감독된 파인튜닝(SFT)은 이미 레이블이 붙은 데이터 세트를 제공하여 모델이 데이터를 이해하도록 돕는 방식이다.",
        "shortcut": 7
      },
      {
        "id": 180,
        "content": "감독 학습은 모델이 데이터가 무엇인지 명시적으로 알려주는 반면, 기본 모델 학습은 비감독적일 수 있으므로 데이터의 의미를 명시하지 않는다.",
        "shortcut": 8
      },
      {
        "id": 181,
        "content": "기본 모델 또는 재정의한 모델(FM)은 파인튜닝이 이루어지며, 이 과정에서 사전 훈련된 모델이라고도 불린다.",
        "shortcut": 10
      },
      {
        "id": 182,
        "content": "기본 모델과 사전 훈련된 모델은 시점에 따라 서로 다른 의미를 가질 수 있지만, 궁극적으로 같은 범주에 속한다.",
        "shortcut": 13
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 34,
    "title": "34. ⚙️ 파인튜닝 유형 및 접근 방법",
    "startTime": "01:58:48.000",
    "endTime": "02:02:48.000",
    "items": [
      {
        "id": 183,
        "content": "모델을 파인튜닝할 때는 기본 모델을 미세 조정하고, 소규모 데이터 세트를 사용하여 이 모델의 상태를 업데이트한다.",
        "shortcut": 1
      },
      {
        "id": 184,
        "content": "Instruction fine-tuning은 특정 데이터를 통해 원하는 입력과 출력의 예를 제공하여 모델을 조정하는 방식이다.",
        "shortcut": 10
      },
      {
        "id": 185,
        "content": "도메인 특정 파인튜닝은 특정 지식 기반을 활용해 모델을 업데이트하거나 특정 도메인에 집중하도록 만드는 방식이다. 예를 들어, **클라우드 컴퓨팅**을 배우기 위해 최신 데이터를 모델에 입력할 수 있다.",
        "shortcut": 13
      },
      {
        "id": 186,
        "content": "전체 파인튜닝는 모델의 모든 가중치를 업데이트하며, 비용이 많이 드는 전통적인 방법이다.",
        "shortcut": 13
      },
      {
        "id": 187,
        "content": "파라미터 효율적인 파인튜닝(PEFT)은 학습 중 소수의 파라미터를 업데이트하고 나머지는 동결하며, 이 방법에 포함된 LoRa는 모든 파라미터를 업데이트할 필요가 없을 때 비용을 절감할 수 있다.",
        "shortcut": 18
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 35,
    "title": "35. 🚀 아마존 베드락(Amazon Bedrock) 모델 카탈로그 소개",
    "startTime": "02:03:30.000",
    "endTime": "02:07:30.000",
    "items": [
      {
        "id": 188,
        "content": "아마존 베드락은 모델 카탈로그를 통해 사용자가 사용할 모델을 선택하여 추론이나 예측을 수행할 수 있도록 한다.",
        "shortcut": 2
      },
      {
        "id": 189,
        "content": "사용자는 커스터마이징한 모델을 만들 수 있으며, 이를 위해 파인튜닝 및 사전 학습 옵션이 제공된다.",
        "shortcut": 4
      },
      {
        "id": 190,
        "content": "모델에 대한 프롬프트 관리 기능이 포함되어 있어, 여러 변수를 테스트할 수 있는 프롬프트 템플릿을 저장할 수 있다.",
        "shortcut": 6
      },
      {
        "id": 191,
        "content": "모델 카탈로그에는 다양한 LLM(대형 언어 모델) 및 생성 **AI 모델**이 포함되어 있으며, **AWS**의 여러 제공자 모델을 선택할 수 있다.",
        "shortcut": 23
      },
      {
        "id": 192,
        "content": "모델 접근 요청은 제공자마다 상이하지만, **AWS**에서는 대부분 즉각적인 접근이 가능하여 빠르게 운영을 시작할 수 있다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 36,
    "title": "36. ⚙️ AWS 모델 배포 및 비용 구조",
    "startTime": "02:08:06.000",
    "endTime": "02:12:06.000",
    "items": [
      {
        "id": 193,
        "content": "온디맨드 모델은 입력 및 출력 토큰에 따라 요금을 청구하는 방식으로, 이는 Amazon Bedrock에서 주로 사용된다. 다른 제공업체와는 달리, Bedrock은 토큰량이 아닌 토큰의 입출력을 기준으로 비용을 계산한다.",
        "shortcut": 7
      },
      {
        "id": 194,
        "content": "예를 들어, Cohere Command R Plus와 같은 온디맨드 모델은 1000개의 입력 토큰당 소수의 비용이 발생하며, 출력 토큰은 다를 수 있다.",
        "shortcut": 10
      },
      {
        "id": 195,
        "content": "**AWS**에서는 Amazon CloudWatch를 통해 토큰 사용 정보를 추적할 수 있으며, Lab에서 이 정보를 시연할 수 있는 핸즈온 실습도 있다.",
        "shortcut": 13
      },
      {
        "id": 196,
        "content": "프로비전드 스루풋 모델은 모델 단위에 따른 요금 체계로, 서버리스 컨테이너와 비슷하게 실제 서버를 추상화하여 제공된다.",
        "shortcut": 16
      },
      {
        "id": 197,
        "content": "Amazon Bedrock Playground는 코드 작성 없이 배포된 모델 API와 상호작용할 수 있도록 하며, 사용 시 비용 추적 기능을 제공한다. 그러나 개발 목적으로 빠르게 평가하기 위해 설계되었으며, 일상적이거나 생산적인 사용에는 적합하지 않다.",
        "shortcut": 38
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 37,
    "title": "37. 💬 채팅 완성 및 텍스트 완성의 개요",
    "startTime": "02:12:13.000",
    "endTime": "02:14:13.000",
    "items": [
      {
        "id": 198,
        "content": "채팅 완성(chat completion)은 언어 모델(LMs)와 상호작용할 수 있는 기능으로, 이는 매우 직관적이다.",
        "shortcut": 1
      },
      {
        "id": 199,
        "content": "텍스트 완성(text completion)은 다음 문장을 예측할 수 있는 LMs과의 상호작용을 허용하며, 과거에는 텍스트 완성만 존재했었다.",
        "shortcut": 3
      },
      {
        "id": 200,
        "content": "여러 Playground들은 특정 모델만 사용할 수 있는 제한이 있으며, Azure AI Studio와 Bedrock에서는 다른 방식으로 채팅 완성 모델을 활용할 수 있다.",
        "shortcut": 9
      },
      {
        "id": 201,
        "content": "텍스트 완성은 분류나 카테고리화에 유용하며, 이를 통해 미세 조정(fine-tuning)을 하는 데 활용될 수 있다.",
        "shortcut": 13
      },
      {
        "id": 202,
        "content": "Amazon Bedrock은 여러 모델을 사용할 수 있는 모델 서비스로, 서버리스 방식으로 활용할 수 있는 기능을 제공한다.",
        "shortcut": 24
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 38,
    "title": "38. 🚀 AWS AI 모델 활성화 및 비용 이해",
    "startTime": "02:14:57.000",
    "endTime": "02:16:57.000",
    "items": [
      {
        "id": 203,
        "content": "**AWS**에서 **AI 모델**을 활성화하려면 모델을 선택하고 체크박스를 선택해야 하며, 모든 모델을 활성화하는 것이 효율적이다.",
        "shortcut": 1
      },
      {
        "id": 204,
        "content": "모델 사용 시 각 모델마다 비용이 다르므로, 특히 온디맨드 모델과 프로비저닝된 처리량 모델의 차이를 이해해야 한다.",
        "shortcut": 13
      },
      {
        "id": 205,
        "content": "Titan Text G1 Premier 모델은 무료 사용이 가능할 수 있으며, **AWS**크레딧을 사용할 수 있다.",
        "shortcut": 20
      },
      {
        "id": 206,
        "content": "입력 토큰과 출력 토큰의 정보를 통해 비용을 추적할 수 있으며, 이러한 메트릭은 관리에 중요하다.",
        "shortcut": 27
      },
      {
        "id": 207,
        "content": "모델의 난이도 조정 옵션인 온도와 top P는 모델이 생성하는 무작위성의 수준을 바꿔주기 때문에 주의해야 한다.",
        "shortcut": 31
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 39,
    "title": "39. 🤖 AI 텍스트 생성 평가",
    "startTime": "02:17:45.000",
    "endTime": "02:18:45.000",
    "items": [
      {
        "id": 208,
        "content": "텍스트 생성의 확률적 결과는 설정값에 따라 달라지며, 0.505는 기본 설정으로 적합하다고 평가된다.",
        "shortcut": 1
      },
      {
        "id": 209,
        "content": "입력이 `one-to-one` 형식일 경우, 의미 없는 결과가 생성될 가능성이 있다.",
        "shortcut": 3
      },
      {
        "id": 210,
        "content": "채팅과 텍스트의 두 가지 플레이그라운드가 있으며, 총 대화 과정과 단일 문장 완성을 지원한다.",
        "shortcut": 10
      },
      {
        "id": 211,
        "content": "텍스트 모드에서 제공되는 결과는 다양하지만, 기본적으로 주제를 벗어난 일반적인 텍스트 생성 결과가 나온다.",
        "shortcut": 16
      },
      {
        "id": 212,
        "content": "단일 턴 시스템에서는 기대한 답변이 아닌, 무작위의 텍스트 생성이 발생할 수 있다.",
        "shortcut": 18
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 40,
    "title": "40. 🛠️ Amazon Bedrock 사용 및 비용 관리",
    "startTime": "02:19:32.000",
    "endTime": "02:23:32.000",
    "items": [
      {
        "id": 213,
        "content": "Amazon Bedrock을 활용할 때 더 창의적인 결과를 얻기 위해서는 온도와 상위 확률(top P) 값을 조정해야 한다.",
        "shortcut": 9
      },
      {
        "id": 214,
        "content": "더 낮은 모델은 보다 기본적인 선택을 하며, 예를 들어 피자와 스파게티 같은 일반적인 음식을 선택하는 경향이 있다.",
        "shortcut": 18
      },
      {
        "id": 215,
        "content": "사용자는 비용을 관리하기 위해 JupyterLab 노트북을 중지해야 하며, 이를 통해 불필요한 비용 발생을 막을 수 있다.",
        "shortcut": 24
      },
      {
        "id": 216,
        "content": "Amazon SageMaker를 통해 코드 실행이 가능하며, SageMaker Studio에 대한 설정이 간단하다는 점이 강조된다.",
        "shortcut": 42
      },
      {
        "id": 217,
        "content": "실습을 위해 Bedrock 작업공간을 사용할 때, 직접적인 비용을 절감하기 위해 노트북을 주기적으로 삭제하는 것이 좋다.",
        "shortcut": 28
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 41,
    "title": "41. ☁️ AWS AI Practitioner와 SageMaker 활용",
    "startTime": "02:24:02.000",
    "endTime": "02:28:02.000",
    "items": [
      {
        "id": 218,
        "content": "**AWS**AI Practitioner 인증을 위해 실험실을 꼭 수행할 필요는 없지만, 기본적인 동작을 알고 있어야 한다.",
        "shortcut": 3
      },
      {
        "id": 219,
        "content": "초기 2개월 간 T3 medium 인스턴스에 대해 무료 250시간 제공되며, 이후 사용 시 시간당 약 5센트의 요금이 발생한다.",
        "shortcut": 4
      },
      {
        "id": 220,
        "content": "SageMaker 및 JupyterLab을 사용하여 텍스트 생성 작업을 진행하며, 표준 **Python**커널을 선택한다.",
        "shortcut": 24
      },
      {
        "id": 221,
        "content": "제로샷 프롬프트는 추가 예시 없이 작업을 제시하는 기법으로, 원하는 결과와 포맷이 항상 일치하지 않을 수 있다는 점이 지적된다.",
        "shortcut": 37
      },
      {
        "id": 222,
        "content": "Anthropic Claude 2.1 모델은 XML 태그를 사용하여 원하는 출력을 이해하는 데 효과적임을 보여준다.",
        "shortcut": 57
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 42,
    "title": "42. 📝 XML 태그와 프롬프트 엔지니어링",
    "startTime": "02:28:52.000",
    "endTime": "02:32:52.000",
    "items": [
      {
        "id": 223,
        "content": "Anthropic를 사용할 경우, 프롬프트에 XML 태그를 사용하는 것이 성능 향상에 도움이 될 수 있다. 각각의 LLM 모델에 따라 다르게 적용되므로 주의가 필요하다.",
        "shortcut": 16
      },
      {
        "id": 224,
        "content": "OpenAI의 LLM은 XML 태그와 같은 구문 구조를 고려하지 않기 때문에, 사용자가 모델의 특성을 이해하고 적용해야 한다.",
        "shortcut": 17
      },
      {
        "id": 225,
        "content": "**AWS** SDK for **Python**(Boto3)을 사용하여 Amazon Bedrock과 프로그램적으로 상호작용할 수 있으며, 이는 Jupyter Notebook 환경에서 원활하게 실행될 수 있다.",
        "shortcut": 32
      },
      {
        "id": 226,
        "content": "Boto3는 일반적으로 사용자 로컬 머신에서 설치가 필요하나, 특정 환경에서는 미리 설치되어 있을 수 있다.",
        "shortcut": 35
      },
      {
        "id": 227,
        "content": "**AWS**의 문서화는 업데이트가 잘 이루어지지 않기 때문에, 필요한 정보를 찾기 위해 사용자 스스로 검색하는 것이 중요하다.",
        "shortcut": 52
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 43,
    "title": "43. 🖥️ 텍스트 생성 및 모델 설정 과정",
    "startTime": "02:33:42.000",
    "endTime": "02:37:42.000",
    "items": [
      {
        "id": 228,
        "content": "모델 설정에 있어 프롬프트 데이터와 관련된 다양한 설정값(temperature, top P, top k 등)을 조정하는 과정이 필요하다.",
        "shortcut": 2
      },
      {
        "id": 229,
        "content": "top k의 의미는 명확하지 않으며, 일반적으로 자주 수정하는 설정은 아니다.",
        "shortcut": 12
      },
      {
        "id": 230,
        "content": "텍스트 생성에 필요한 최대 길이 설정은 특별히 수정하지 않고 기본값을 유지한다.",
        "shortcut": 13
      },
      {
        "id": 231,
        "content": "Amazon Bedrock의 모델 ID를 확인해야 하며, 이를 위해 관련 문서를 참조하여 적절한 모델을 선택한다.",
        "shortcut": 23
      },
      {
        "id": 232,
        "content": "JSON으로 구성된 응답을 읽고 처리하는 과정이 있으며, 이를 통해 생성된 텍스트를 출력한다. 이는 에러 핸들링을 위한 botocore 모듈의 수입과 관련이 있다.",
        "shortcut": 52
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 44,
    "title": "44. 🛠️ 코드 설정과 오류 해결 과정",
    "startTime": "02:38:41.000",
    "endTime": "02:41:41.000",
    "items": [
      {
        "id": 233,
        "content": "사용자는 \"key prompt not found\" 오류가 발생했으며, 이는 최대 샘플 토큰과 관련된 설정이 누락되었음을 나타낸다.",
        "shortcut": 3
      },
      {
        "id": 234,
        "content": "최대 토큰의 샘플 수를 200으로 설정해 보았지만, 여전히 문제가 해결되지 않았다.",
        "shortcut": 9
      },
      {
        "id": 235,
        "content": "오류를 수정하기 위해 Boto 3를 사용한 코드에서 prompt의 설정을 검토하고, 클린한 구현을 선호하는 모습을 보였다.",
        "shortcut": 18
      },
      {
        "id": 236,
        "content": "여러 설정이 서로 다르며 온도 값을 1.0으로 조정할 수 있다고 언급되었다.",
        "shortcut": 33
      },
      {
        "id": 237,
        "content": "마지막으로, 모델을 호출할 때 프롬프트가 \"Okay\"로 끝나야 한다는 점이 강조되었다.",
        "shortcut": 43
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 45,
    "title": "45. 🤖 AWS 코드 디버깅 과정",
    "startTime": "02:42:32.000",
    "endTime": "02:46:32.000",
    "items": [
      {
        "id": 238,
        "content": "코드 작성을 위해 \"assistant:\"와 같은 형식으로 텍스트를 입력해야 하며, 모델의 대화는 반드시 새로운 줄로 끝나야 한다는 점이 언급된다.",
        "shortcut": 11
      },
      {
        "id": 239,
        "content": "**AWS**의 코드는 항상 신뢰할 수 있는 것은 아니며, 이로 인해 불필요한 오류가 발생할 수 있다고 강조된다.",
        "shortcut": 22
      },
      {
        "id": 240,
        "content": "응답을 단순화하기 위해 코드에서 불필요한 요소를 제거하고, 그 결과로 \"None type object is not subscriptable\" 오류가 발생하는 상황을 설명한다.",
        "shortcut": 19
      },
      {
        "id": 241,
        "content": "스트리밍 텍스트의 응답 본문을 출력하기 위해 필요한 함수 사용을 시도하며, 이를 통해 코드를 성공적으로 수정하는 과정을 보여준다.",
        "shortcut": 42
      },
      {
        "id": 242,
        "content": "디버깅 과정에서의 시행착오를 겪으면서도 \"RSP\"와 같은 변수를 활용하는 방법을 반복적으로 시험하고 있다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 46,
    "title": "46. 📊 프롬프트 엔지니어링 예시",
    "startTime": "02:47:24.000",
    "endTime": "02:51:24.000",
    "items": [
      {
        "id": 243,
        "content": "완성된 출력을 얻기 위해 코드를 수정하며 시도하는 과정이 존재한다. 이 과정은 때때로 작동하지 않는 경우도 있어 불안정함을 느낀다.",
        "shortcut": 3
      },
      {
        "id": 244,
        "content": "프롬프트 엔지니어링의 일부로 쇼트와 퓨샷 예시를 사용하는 방안에 대해 설명한다. 특히, 퓨샷은 이전의 예시를 제공하여 다음 항목을 예측하게 하는 개념이다.",
        "shortcut": 29
      },
      {
        "id": 245,
        "content": "타이탄 익스프레스 모델을 사용하여 출력 결과가 \"Positive\"가 나오는 것을 확인하며 해당 모델의 동작을 검증한다.",
        "shortcut": 32
      },
      {
        "id": 246,
        "content": "여러 환경에서 설정을 재현할 수 있도록 필요한 설치 작업과 코드 구성 방법을 안내한다. 하지만 Boto Core는 현재 사용하지 않기 때문에 필요하지 않다.",
        "shortcut": 51
      },
      {
        "id": 247,
        "content": "각 모델은 서로 다르게 작동할 수 있으며, 동일한 형식의 프롬프트가 필요하지 않다는 점을 강조한다.",
        "shortcut": 59
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 47,
    "title": "47. 🚀 문자열 처리 및 결과 출력 과정",
    "startTime": "02:51:41.000",
    "endTime": "02:54:41.000",
    "items": [
      {
        "id": 248,
        "content": "입력에서 특정 요소를 제거하면 자동으로 문자열로 변환된다.",
        "shortcut": 1
      },
      {
        "id": 249,
        "content": "응답을 단순화하기 위해 직접 프롬프트 데이터를 제공할 수 있다.",
        "shortcut": 2
      },
      {
        "id": 250,
        "content": "JSON 형식의 본문(body)을 제공해야 함을 확인하였고, 이는 오류를 알려준다.",
        "shortcut": 13
      },
      {
        "id": 251,
        "content": "각각의 모델에서 형식 불일치가 발생하고 있어, 이를 일관되게 조정해야 한다.",
        "shortcut": 24
      },
      {
        "id": 252,
        "content": "체인 오브 생각을 통해 복잡한 추론을 단계적으로 나누어 처리한다는 개념이 강조되며, 예시를 제공하는 것이 중요하다.",
        "shortcut": 42
      }
    ],
    "sourceIndex": 1
  },
  {
    "id": 48,
    "title": "1. 🤖 체인 오브 씽크(Chain of Thought) 활용하기",
    "startTime": "00:00:00.000",
    "endTime": "00:04:00.000",
    "items": [
      {
        "id": 253,
        "content": "체인 오브 씽크는 문제를 해결하기 전에 단계적으로 생각하도록 유도하여 더 나은 결과를 이끌어낸다.",
        "shortcut": 36
      },
      {
        "id": 254,
        "content": "작은 **모델**을 사용할 경우 정보량이 적어지므로 더 큰 **모델**을 사용하는 것이 유리하다.",
        "shortcut": 17
      },
      {
        "id": 255,
        "content": "Anthropic CLA **모델**과 같은 다양한 **모델**을 시험해 보며 적합한 **모델**을 찾아내는 과정이 중요하다.",
        "shortcut": 11
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 49,
    "title": "2. 🤖 대화형 AI 모델과 API 사용",
    "startTime": "00:04:03.000",
    "endTime": "00:07:03.000",
    "items": [
      {
        "id": 256,
        "content": "일부 대형 언어 **모델**은 특정 기능에서 더 나은 성능을 보이며, 특히 **Claude** **모델**이 그러하다.",
        "shortcut": 1
      },
      {
        "id": 257,
        "content": "대화형 **모델**을 사용할 때 **API**지원 문제가 발생할 수 있으며, 이 경우 messages **API**를 사용해야 한다.",
        "shortcut": 4
      },
      {
        "id": 258,
        "content": "**모델**간의 기능 차이가 있으며, Haiku와 같은 특정 **모델**에 대해 지원 여부가 불확실한 상황이다.",
        "shortcut": 9
      },
      {
        "id": 259,
        "content": "입력하는 데이터의 형식이 문제의 원인일 수 있으며, 이는 사용 중인 **모델**의 버전 차이에서 비롯될 수 있다.",
        "shortcut": 18
      },
      {
        "id": 260,
        "content": "Anthropic **모델**관련 정보가 다른 형식으로 제공되며, 이는 기존 데이터와 다르게 더 구조화된 형태이다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 50,
    "title": "3. 💻 Amazon Bedrock 작업 흐름 및 프롬프트 엔지니어링",
    "startTime": "00:07:08.000",
    "endTime": "00:12:08.000",
    "items": [
      {
        "id": 261,
        "content": "주어진 입력에 대한 대화 정의를 통해 메시지 히스토리를 추가하여 부가적인 정보를 유지할 수 있다.",
        "shortcut": 1
      },
      {
        "id": 262,
        "content": "**프롬프트 엔지니어링**에서 주요 기술로는 **Chain of Thought**, few-shot, zero-shot 등이 있으며, 이들은 효과적인 **모델**응답을 이끌어내는 데 사용된다.",
        "shortcut": 24
      },
      {
        "id": 263,
        "content": "GitHub에서 다양한 예제를 추가하기 위해 새로운 폴더를 생성하고 이를 통한 코드 관리를 진행할 수 있다.",
        "shortcut": 35
      },
      {
        "id": 264,
        "content": "**텍스트 생성**관련 작업이 진행되며, 이는 **Amazon Bedrock**의 LangChain 통합 작업을 지원한다.",
        "shortcut": 49
      },
      {
        "id": 265,
        "content": "각 작업 과정의 결과를 확인하고, 다음 단계로 나아가는 방향을 잡을 수 있다.",
        "shortcut": 45
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 51,
    "title": "4. 🛠️ LangChain과 LlamaIndex 사용 준비 과정",
    "startTime": "00:12:10.000",
    "endTime": "00:17:10.000",
    "items": [
      {
        "id": 266,
        "content": "LangChain과 LlamaIndex는 다양한 LLM **모델**에 대한 어댑터 역할을 한다.",
        "shortcut": 20
      },
      {
        "id": 267,
        "content": "Amazon Bedrock은 많은 **모델**에 접근할 수 있도록 하지만, LangChain과 LlamaIndex 생태계는 더 강력하다.",
        "shortcut": 21
      },
      {
        "id": 268,
        "content": "LangChain을 사용하기 위해 pip를 이용하여 설치할 계획이다.",
        "shortcut": 31
      },
      {
        "id": 269,
        "content": "LangChain과 Bedrock 통합을 위한 특화된 라이브러리가 제공되어 있어 이를 활용할 것이다.",
        "shortcut": 46
      },
      {
        "id": 270,
        "content": "설치 시 종속성 충돌이 발생하는 경우가 있을 수 있어, 이를 주의해야 한다.",
        "shortcut": 54
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 52,
    "title": "5. 🛠️ Amazon Bedrock 및 LangChain 사용 예시",
    "startTime": "00:17:20.000",
    "endTime": "02:59:20.000",
    "items": [
      {
        "id": 271,
        "content": "**Amazon Bedrock**과 LangChain은 다양한 작업을 함께 사용할 수 있는 툴로, 여러 에이전트를 조합하여 데이터에 접근하고, 처리하는 등 복합 작업을 수행한다.",
        "shortcut": 1
      },
      {
        "id": 272,
        "content": "LangChain의 예시로, 여러 데이터를 중앙에서 관리하고 이를 바탕으로 질의응답을 수행하는 기능을 가진 에이전트 구축이 포함된다.",
        "shortcut": 3
      },
      {
        "id": 273,
        "content": "**Amazon Bedrock**에서는 RAG(retrieval-augmented generation) 방식의 워크플로우를 설정하여 다양한 데이터 소스에서 정보를 검색하고, 이를 바탕으로 답변을 생성하는 과정에서 벡터 스토어를 활용한다.",
        "shortcut": 485
      },
      {
        "id": 274,
        "content": "이런 시스템에서 데이터 소스로는 Amazon S3, WebCrawler, Salesforce 등이 활용될 수 있으며, 이를 통해 지속적으로 데이터베이스를 업데이트할 수 있다.",
        "shortcut": 493
      },
      {
        "id": 275,
        "content": "Chunking 방법론을 통해 대량의 문서 데이터를 다양한 형식으로 쪼개어 저장할 수 있는 기능이 제공되고, 이를 통한 Parsing도 가능하다.",
        "shortcut": 497
      },
      {
        "id": 276,
        "content": "각 단계에서 나타나는 주요 기능은 다음과 같다:",
        "shortcut": ""
      },
      {
        "id": 277,
        "content": "**JSON**데이터를 통해 간단한 CSV 생성 및 SQL 쿼리생성 작업을 수행하며, 이를 저장하고 실행하는 과정에서의 에러 처리도 포함된다.",
        "shortcut": 18
      },
      {
        "id": 278,
        "content": "데이터를 위한 지식베이스 구조를 설계, 구축하며 이를 통해 다양한 외부 데이터 조회 기능이 구현된다.",
        "shortcut": 485
      },
      {
        "id": 279,
        "content": "여러 **API**와의 통신 및 결합을 통해 복합적인 흐름을 관리할 수 있는 기능이 강화되어, 간편하게 다양한 기능을 수행할 수 있게 된다.",
        "shortcut": 1418
      },
      {
        "id": 280,
        "content": "이러한 설정을 통해 **Amazon Bedrock**환경에서의 복합적이고 효율적인 데이터 관리 및 처리 작업이 가능해짐을 보여준다.",
        "shortcut": ""
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 53,
    "title": "5.1. ️ 문제 해결 및 코드 실행 과정",
    "startTime": "00:17:20.000",
    "endTime": "00:20:20.000",
    "items": [
      {
        "id": 281,
        "content": "커널을 재시작할 경우, 설치된 패키지가 그대로 남아 있을 수 있으니 주의해야 한다.",
        "shortcut": 3
      },
      {
        "id": 282,
        "content": "Jupyter Lab 노트북은 특정 패키지가 누락되면 여전히 문제가 발생할 수 있음을 강조하고 있다.",
        "shortcut": 7
      },
      {
        "id": 283,
        "content": "LangChain을 사용해 Bedrock과의 통합을 시도했으나, 필요한 패키지인 Boto 3의 설치 여부가 문제를 일으킬 수 있다.",
        "shortcut": 20
      },
      {
        "id": 284,
        "content": "커널을 재시작하고 모든 출력을 지운 뒤 다시 시도해볼 예정이다.",
        "shortcut": 27
      },
      {
        "id": 285,
        "content": "LangChain을 사용한 간단한 예시가 성공적으로 실행되었음을 보여준다.",
        "shortcut": 37
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 54,
    "title": "5.2. ️ LangChain과 Llama Index 개요",
    "startTime": "00:21:19.000",
    "endTime": "00:23:19.000",
    "items": [
      {
        "id": 286,
        "content": "LangChain은 여러 에이전트를 조율하고 데이터베이스 및 데이터 저장소와 연결하는 시스템으로, 다양한 작업을 수행할 수 있게 한다.",
        "shortcut": 40
      },
      {
        "id": 287,
        "content": "**Amazon Bedrock**는 광고 생태계 내에서 비슷한 기능을 가진 prompt flows와 agents를 제공한다.",
        "shortcut": 41
      },
      {
        "id": 288,
        "content": "Microsoft의 **Azure AI Studio** 또한 유사한 prompt flow를 제공하지만, 이는 오픈 소스와 경쟁 관계에 있다.",
        "shortcut": 42
      },
      {
        "id": 289,
        "content": "오픈 소스 솔루션인 LangChain이나 **Llama Index**가 실용성을 위해 더 우수한 선택이 될 수 있다.",
        "shortcut": 44
      },
      {
        "id": 290,
        "content": "**Llama Index**를 사용할 때 Bedrock과의 통합에서 어려움이 발생할 수 있으며, 이는 Bedrock의 데이터 반환 방식과 관련이 있다.",
        "shortcut": 48
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 55,
    "title": "5.3. ️ 코드 생성 및 요약화",
    "startTime": "00:23:40.000",
    "endTime": "00:25:40.000",
    "items": [
      {
        "id": 291,
        "content": "다양한 종류의 텍스트를 처리할 수 있으며, 예를 들어 Star Trek을 넣어볼 수 있다.",
        "shortcut": 61
      },
      {
        "id": 292,
        "content": "제너레이션의 일종으로, 제로샷(Zero-shot) 생성을 통해 **코드 생성**을 활용할 수 있다.",
        "shortcut": 72
      },
      {
        "id": 293,
        "content": "**코드 생성**과 함께 **요약**화에 대한 방법도 중요한 부분으로, 시험에 나올 가능성이 있다.",
        "shortcut": 74
      },
      {
        "id": 294,
        "content": "아마존 베드락 **API**를 사용하여 **코드 생성**을 진행하며, 더 쉽게 작업을 수행할 수 있다.",
        "shortcut": 77
      },
      {
        "id": 295,
        "content": "몇 가지 사용 사례로는 **코드 생성**이 포함되며, 더 복잡한 작업을 처리할 수 있다.",
        "shortcut": 81
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 56,
    "title": "5.4. ️ 코드 생성 및 CSV 데이터 분석 과정",
    "startTime": "00:25:48.000",
    "endTime": "00:29:48.000",
    "items": [
      {
        "id": 296,
        "content": "**코드 생성**을 위한 준비 단계로 Boto Three를 이용하여 CSV 데이터를 설정하고 파일을 생성한다.",
        "shortcut": 86
      },
      {
        "id": 297,
        "content": "**CSV 파일**에는 판매 데이터가 포함되어 있으며, 이를 분석하기 위해 Python 프로그램을 생성하라는 지침이 포함되어 있다.",
        "shortcut": 102
      },
      {
        "id": 298,
        "content": "IPython display를 사용하여 마크다운 형식으로 데이터를 시각적으로 표현할 수 있도록 준비한다.",
        "shortcut": 106
      },
      {
        "id": 299,
        "content": "코드 작성을 보다 쉽게 하도록 줄 간격을 조정하고, 문제 발생 시 빠르게 디버깅할 수 있도록 구조를 정리한다.",
        "shortcut": 110
      },
      {
        "id": 300,
        "content": "마지막으로 출력된 코드를 실행하여 분석 작동 여부를 확인하고 결과를 검증한다.",
        "shortcut": 122
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 57,
    "title": "5.5. ️ SQL 생성 과정 설명",
    "startTime": "00:29:52.000",
    "endTime": "00:32:52.000",
    "items": [
      {
        "id": 301,
        "content": "**SQL 생성**에 대한 예제가 간단하고 이해하기 쉽게 구성되어 있다.",
        "shortcut": 127
      },
      {
        "id": 302,
        "content": "특정 형식의 프롬프트를 사용하여 SQL 쿼리를 생성하는 방법이 설명된다.",
        "shortcut": 133
      },
      {
        "id": 303,
        "content": "새로운 데이터베이스를 로드해야 하며, 이를 통해 SQL 쿼리 생성이 가능해진다.",
        "shortcut": 140
      },
      {
        "id": 304,
        "content": "현재 사용되는 시스템은 Titan이며, 데이터베이스를 사용할 수 있어야 쿼리 테스트가 가능하다.",
        "shortcut": 141
      },
      {
        "id": 305,
        "content": "SQLite를 사용하여 실제 데이터베이스에 대해 쿼리를 실행해 볼 수 있지만, 오늘은 이를 시도하지 않을 예정이다.",
        "shortcut": 160
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 58,
    "title": "5.6. ️ 텍스트 요약 및 코드 생성",
    "startTime": "00:33:11.000",
    "endTime": "00:47:11.000",
    "items": [
      {
        "id": 306,
        "content": "**코드 생성**이 완료된 후, 텍스트 **요약**을 위해 새로운 노트북을 만들고 \"summarization\"으로 명명한다.",
        "shortcut": 161
      },
      {
        "id": 307,
        "content": "**요약**프로세스는 **Claude**Sonnets를 사용하여 텍스트를 **요약**하는 방식으로 진행된다.",
        "shortcut": 163
      },
      {
        "id": 308,
        "content": "**텍스트 생성**과정에서, 입력 텍스트는 **JSON** 포맷으로 제공되어야 하며, 출력은 읽기 쉽게 정리된다.",
        "shortcut": 173
      },
      {
        "id": 309,
        "content": "**요약**작업은 상대적으로 단순하지만, **Claude**의 Sonet **요약**은 XML 태그를 사용하는 특성이 있다.",
        "shortcut": 203
      },
      {
        "id": 310,
        "content": "Q&A 예제에서는 경고를 무시하고 데이터를 입력하는 방식이 필요한데, 이는 일관성을 유지하기 어렵다는 문제를 언급한다.",
        "shortcut": 209
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 59,
    "title": "5.7. ️ LangChain과 코드 수정 과정",
    "startTime": "00:47:17.000",
    "endTime": "01:06:17.000",
    "items": [
      {
        "id": 311,
        "content": "LangChain을 사용하여 데이터를 처리하는 방법을 소개하고 있으며, 해당 기술은 자동으로 작업을 수행하는 기술이다.",
        "shortcut": 310
      },
      {
        "id": 312,
        "content": "이메일을 분석하기 위해 코드를 살펴보며, Beautiful Soup을 사용하여 HTML format으로부터 정보를 추출하는 방법을 언급하고 있다.",
        "shortcut": 315
      },
      {
        "id": 313,
        "content": "코드에서 아직 사용되지 않은 파라미터나 다른 형식의 코드들이 나타나는데, 이는 이전 코드와의 불일치 때문일 가능성이 있다.",
        "shortcut": 326
      },
      {
        "id": 314,
        "content": "여러번의 오류 수정 과정을 거치면서, 데이터에 대한 올바른 입력 형식과 필요한 파라미터를 설정하려고 노력하고 있다.",
        "shortcut": 329
      },
      {
        "id": 315,
        "content": "최종적으로 **텍스트 생성**을 완료하고, 모든 작업을 마치기 위해 파일을 다운로드하려는 단계에 도달하였다.",
        "shortcut": 471
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 60,
    "title": "5.8. 아마존 베드록 지식 기반 및 RAG 워크플로우",
    "startTime": "01:06:32.000",
    "endTime": "01:10:32.000",
    "items": [
      {
        "id": 316,
        "content": "아마존 베드록 지식 기반은 RAG(리트리벌-증강 생성) 워크플로우를 벡터 저장소와 연결하는 기능이다.",
        "shortcut": 485
      },
      {
        "id": 317,
        "content": "RAG는 데이터 소스로부터 정보를 가져와 컨텍스트 윈도우에 넣어 응답을 더 지능적으로 생성하는 방식이다.",
        "shortcut": 487
      },
      {
        "id": 318,
        "content": "데이터 소스에는 아마존 S3, 웹 크롤러, 콜렌스, 세일즈포스, 그리고 SharePoint가 포함되며, 향후 더 많은 데이터 소스가 추가될 수 있다.",
        "shortcut": 493
      },
      {
        "id": 319,
        "content": "데이터의 청크(chunking)에는 기본 청크, 고정 청크, 계층적 청크, 의미 청크가 있으며, 데이터 저장을 위한 분할 방법을 결정할 수 있다.",
        "shortcut": 497
      },
      {
        "id": 320,
        "content": "데이터를 벡터 저장소에 넣기 위해서는 임베딩(embedding)이 필요하며, 다양한 임베딩 옵션(Titan, Cohere 등)이 있다.",
        "shortcut": 508
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 61,
    "title": "5.9. Amazon Bedrock을 활용한 RAG 구현 과정",
    "startTime": "01:10:52.000",
    "endTime": "02:28:52.000",
    "items": [
      {
        "id": 321,
        "content": "**Amazon Bedrock**의 프로젝트 지식 기반을 사용하여 RAG(복원 생성)는 설정하기 쉽지 않으며, 많은 작업을 요구한다는 점이 지적된다.",
        "shortcut": 527
      },
      {
        "id": 322,
        "content": "지식 기반 생성 시, Amazon S3 버킷을 만들고 파일을 업로드하여 데이터 소스를 설정하는 과정이 포함된다.",
        "shortcut": 533
      },
      {
        "id": 323,
        "content": "다양한 벡터 데이터베이스 옵션이 존재하며, OpenSearch가 사용된다고 언급된다.",
        "shortcut": 565
      },
      {
        "id": 324,
        "content": "RAG에서는 외부 데이터 소스에서 정보를 가져와 주입하여 응답을 생성하는 방식이 여러 전략으로 이루어질 수 있음을 설명한다.",
        "shortcut": 702
      },
      {
        "id": 325,
        "content": "DynamoDB를 사용한 예약 생성 예시를 통해, Lambda 함수를 통한 행동 그룹 정의와 지침 설정의 중요성이 강조된다.",
        "shortcut": 947
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 62,
    "title": "5.10. 에이전트와 세션 관리",
    "startTime": "02:29:45.000",
    "endTime": "02:58:45.000",
    "items": [
      {
        "id": 326,
        "content": "에이전트와 세션 ID를 사용하여 대화 시스템을 설정할 수 있으며, 에이전트 ID는 쉽게 얻을 수 있다.",
        "shortcut": 1318
      },
      {
        "id": 327,
        "content": "세션을 계속 사용하여 정보를 스트리밍할 수 있으며, 이 경우 동일한 세션 ID를 공급해야 한다.",
        "shortcut": 1335
      },
      {
        "id": 328,
        "content": "'Invoke agent is not defined' 오류는 실행 역할이 없는 경우 발생하며, 이를 해결하기 위해서는 적절한 권한 추가가 필요하다.",
        "shortcut": 1359
      },
      {
        "id": 329,
        "content": "Prom Flow는 복잡한 Gen 워크플로우를 조정할 수 있는 기능을 제공하며, 다양한 노드를 사용하여 로직 라우팅을 할 수 있다.",
        "shortcut": 1431
      },
      {
        "id": 330,
        "content": "실시간으로 여러 버전을 비교하고 사용할 수 있는 점이 강조되며, 이를 통해 입력 형식 및 응답 형식을 조정할 수 있다.",
        "shortcut": 1558
      }
    ],
    "sourceIndex": 2
  },
  {
    "id": 63,
    "title": "1. 💻 클라우드 리소스 정리 및 프롬프트 관리",
    "startTime": "00:00:04.000",
    "endTime": "00:03:04.000",
    "items": [
      {
        "id": 331,
        "content": "클라우드에서 여러 리소스를 정리하는 단계로, 지식 베이스, DynamoDB 테이블, **S3 버킷**, 에이전트, OpenSearch 등을 삭제하였다.",
        "shortcut": 2
      },
      {
        "id": 332,
        "content": "주피터 스튜디오에서 실행 중인 작업도 중지할 수 있지만, 주어진 예시에서 파인 튜닝 작업 때문에 이를 유지할 계획이다.",
        "shortcut": 19
      },
      {
        "id": 333,
        "content": "**Amazon Bedrock**의 **프롬프트 관리**기능을 활용하여 재사용 가능한 프롬프트 템플릿을 만들고 다양한 변형을 테스트하여 프롬프트 엔지니어링을 세밀하게 분석하는 것이 유용하다.",
        "shortcut": 28
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 64,
    "title": "2. ⚙️ 커스텀 모델 및 Fine-Tuning 개요",
    "startTime": "00:04:00.000",
    "endTime": "00:07:00.000",
    "items": [
      {
        "id": 334,
        "content": "Prompt Flow로 LLM을 사용할 때, 프롬프트 템플릿을 만들고 변수를 삽입하는 것이 필요하다.",
        "shortcut": 1
      },
      {
        "id": 335,
        "content": "**Amazon Bedrock**에서는 **기본 모델**을 선택하고 교육을 통해 커스텀 모델을 생성할 수 있으며, 이 과정에서 unlabeled data를 사용해 일반적인 지식을 향상시키는 continued pre-training과 labeled data로 특정 작업 수행을 위해 개선하는 fine-tuning이 있다.",
        "shortcut": 5
      },
      {
        "id": 336,
        "content": "**JSONL 파일** 형식이 주로 사용되며, 모델의 사용 목적에 따라 형식이 달라질 수 있다.",
        "shortcut": 11
      },
      {
        "id": 337,
        "content": "커스텀 **모델 훈련**시, 훈련 시간과 저장 비용이 발생하며, 특히 provisioned throughput으로 전환해야 하므로 비용이 추가된다.",
        "shortcut": 16
      },
      {
        "id": 338,
        "content": "모델 임포트 기능을 통해 특정 모델의 가중치를 가져와 커스텀 모델을 만든 후, Hugging Transformer Library에서 생성된 파일을 제공해야 한다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 65,
    "title": "3. 🧩 모델 커스터마이징 및 파인튜닝",
    "startTime": "00:08:00.000",
    "endTime": "00:12:00.000",
    "items": [
      {
        "id": 339,
        "content": "커스터마이징 모델의 두 가지 옵션은 파인튜닝 작업 생성과 지속적인 사전 학습 작업 생성이다.",
        "shortcut": 1
      },
      {
        "id": 340,
        "content": "사용자는 소스 모델을 선택하여 입력 데이터, 검증 데이터, 하이퍼파라미터를 제공하고 모델을 프로비저닝할 수 있다.",
        "shortcut": 2
      },
      {
        "id": 341,
        "content": "SageMaker와 상호작용하는 방식이 명확하지 않지만, **모델 커스터마이징**에 관련된 지침이 존재한다.",
        "shortcut": 4
      },
      {
        "id": 342,
        "content": "**데이터 세트**로는 CNN의 뉴스 기사들이 사용되며, Hugging Face를 통해 **데이터 세트**를 가져온다.",
        "shortcut": 22
      },
      {
        "id": 343,
        "content": "파인 튜닝을 위한 일반적인 프롬프트 구조는 작업을 정의하는 시스템 프롬프트와 추가 맥락을 제공하는 입력으로 구성된다.",
        "shortcut": 24
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 66,
    "title": "4. 📊 모델 평가 및 성능 확인",
    "startTime": "00:12:44.000",
    "endTime": "00:13:44.000",
    "items": [
      {
        "id": 344,
        "content": "하이퍼파라미터 검증과 훈련 응답 체크가 필요하며, 커스텀 모델의 성능을 평가하기 위해 모델을 호출해야 한다.",
        "shortcut": 1
      },
      {
        "id": 345,
        "content": "BERT 점수를 사용하여 모델을 평가하는 방식이 적용되며, 이는 흥미로운 방법이다.",
        "shortcut": 5
      },
      {
        "id": 346,
        "content": "파인 튜닝된 모델은 **기본 모델**대비 결과가 개선된다는 점을 강조하며, 훈련 손실과 검증 손실의 비교가 중요하다.",
        "shortcut": 6
      },
      {
        "id": 347,
        "content": "모델 성능을 평가하기 위해 FM eval을 사용하여 요약 정확도를 측정하는 여러 지표인 Meteor, Rouge, BERT 점수 등이 고려된다.",
        "shortcut": 11
      },
      {
        "id": 348,
        "content": "Foundation Model Evaluation Library는 대규모 언어 모델을 평가하여 특정 용도에 적합한 모델을 선택하는 데 도움을 준다.",
        "shortcut": 14
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 67,
    "title": "5. 📊 모델 평가 및 파인튜닝 과정",
    "startTime": "00:14:31.000",
    "endTime": "00:17:31.000",
    "items": [
      {
        "id": 349,
        "content": "슬라이드를 작성하면서 Bedrock의 평가와 유사한 점을 발견했으며, 이는 **모델 평가**에 사용되는 라이브러리일 가능성이 높다.",
        "shortcut": 3
      },
      {
        "id": 350,
        "content": "코드에서는 **미세 조정**된 모델 성능을 Meteor, Rouge, B 점수와 같은 요약 정확도 메트릭으로 평가한다고 언급되고, 자동으로 이러한 평가가 실행되는 것처럼 보인다.",
        "shortcut": 6
      },
      {
        "id": 351,
        "content": "모델을 활용하기 위해선 20-30분 정도 소요되는 프로비저닝이 필요하다고 하며, 이는 상당히 긴 시간으로 간주된다.",
        "shortcut": 15
      },
      {
        "id": 352,
        "content": "계속된 프리트레이닝은 일반 콘텐츠를 모델에 삽입하는 방식으로, 상대적으로 간단하다고 언급된다.",
        "shortcut": 18
      },
      {
        "id": 353,
        "content": "파인튜닝을 위해서는 라벨링된 데이터가 필요하며, 데이터가 준비되면 직접 업로드하고 훈련할 수 있다고 설명된다.",
        "shortcut": 19
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 68,
    "title": "6. 🤖 모델 학습 및 분류 평가",
    "startTime": "00:18:05.000",
    "endTime": "00:21:05.000",
    "items": [
      {
        "id": 354,
        "content": "사용자들은 데이터셋을 활용하여 커스텀 모델을 학습하고자 하며, Azure AI와 Babbage 모델을 사용해 분류 작업을 진행한다.",
        "shortcut": 2
      },
      {
        "id": 355,
        "content": "사용자가 가벼운 모델을 선택하고 이를 활용해 학습하려는 이유는 더 복잡한 환경인 SageMaker를 피하고 싶기 때문이다.",
        "shortcut": 14
      },
      {
        "id": 356,
        "content": "\"Light\" 모델은 지능이 낮아 특정 분류 작업에 적합하다고 평가되며, 효과적으로 학습할 수 있는 최적의 선택으로 보인다.",
        "shortcut": 19
      },
      {
        "id": 357,
        "content": "동물을 분류하는 테스트를 진행하며, 다양한 동물에 대해 올바른 결과를 출력할 수 있는지 확인하고, 일부 결과는 예상과 다르게 나타나기도 한다.",
        "shortcut": 24
      },
      {
        "id": 358,
        "content": "**모델 평가**시 매개변수 조정을 통해 결과 향상을 꾀하고 있으며, 추가적인 결과가 필요하다고 언급된다.",
        "shortcut": 39
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 69,
    "title": "7. 🐾 훈련 데이터셋 생성 과정",
    "startTime": "00:21:55.000",
    "endTime": "00:25:55.000",
    "items": [
      {
        "id": 359,
        "content": "단일 단어로 동물을 분류하려고 시도했지만, 출력이 단일 단어가 아닌 문제가 발생하였다.",
        "shortcut": 1
      },
      {
        "id": 360,
        "content": "Claude Sonic을 사용하여 ML 모델의 훈련 데이터셋을 생성하려고 하였으며, 중복 없는 100개의 동물 예시를 요구하였다.",
        "shortcut": 9
      },
      {
        "id": 361,
        "content": "훈련 데이터셋은 JSON 파일 형식으로 구성되며, 단일 턴 메시지를 준비하는 과정이 포함된다.",
        "shortcut": 15
      },
      {
        "id": 362,
        "content": "현재 진행 중인 데이터 형식은 회화형이 아닌 단일 턴 메시지 형식으로 보인다.",
        "shortcut": 22
      },
      {
        "id": 363,
        "content": "요청한 동물 목록에 따라 **JSONL 파일**형식으로 100개의 동물을 출력할 수 있을지를 확인하고 있다.",
        "shortcut": 26
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 70,
    "title": "8. 🗂️ 데이터 세트 구성 및 검증",
    "startTime": "00:26:23.000",
    "endTime": "00:30:23.000",
    "items": [
      {
        "id": 364,
        "content": "현재 **데이터 세트**에 중복이 없는지 확인하는 과정을 진행 중이며, 적절한 형태로 보인다.",
        "shortcut": 1
      },
      {
        "id": 365,
        "content": "**데이터 세트**를 **JSONL 파일**형식으로 새 폴더에 저장할 계획이며, 현재 91줄이 들어 있다.",
        "shortcut": 5
      },
      {
        "id": 366,
        "content": "모델 학습을 위해 두 개의 **데이터 세트**가 필요하며, 하나는 훈련용, 다른 하나는 검증용 **데이터 세트**이다.",
        "shortcut": 8
      },
      {
        "id": 367,
        "content": "**S3 버킷**을 생성하여 훈련 **데이터 세트**, 검증 **데이터 세트**, 그리고 검증 출력을 위한 정리된 공간을 마련할 예정이다.",
        "shortcut": 14
      },
      {
        "id": 368,
        "content": "최종 **데이터 세트**는 훈련용과 검증용으로 이름을 지정하며, 동일한 형식과 내용을 유지해야 할 것 같다.",
        "shortcut": 28
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 71,
    "title": "9. 🛠️ 모델 훈련 데이터와 검증 데이터 설정",
    "startTime": "00:30:52.000",
    "endTime": "00:34:52.000",
    "items": [
      {
        "id": 369,
        "content": "검증 데이터셋에 대한 설명이 없으며, 동일한 데이터셋 형식을 가정하는 것이 불확실하다.",
        "shortcut": 1
      },
      {
        "id": 370,
        "content": "훈련 **데이터 세트**와 검증 **데이터 세트**의 텍스트-투-텍스트 형식을 확인하기 위해 ChatGPT를 활용했다.",
        "shortcut": 4
      },
      {
        "id": 371,
        "content": "**모델 훈련**을 위해 Stage Maker와 Ground Truth를 사용하여 훈련 데이터를 생성하고 라벨링할 수 있다.",
        "shortcut": 9
      },
      {
        "id": 372,
        "content": "훈련 데이터와 검증 데이터를 목표 영역에 업로드하는 과정을 진행하였다.",
        "shortcut": 12
      },
      {
        "id": 373,
        "content": "Bedrock **모델 커스터마이징**작업에는 사용자의 권한이 필요하며, 새로운 권한을 생성할 수 있다.",
        "shortcut": 35
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 72,
    "title": "10. 💡 모델 세부 조정과 비용 분석",
    "startTime": "00:35:36.000",
    "endTime": "00:38:36.000",
    "items": [
      {
        "id": 374,
        "content": "세부 조정 서비스를 시작하기 위해서는 사용할 모델을 위한 구매 제공 처리량을 구매해야 한다고 한다.",
        "shortcut": 3
      },
      {
        "id": 375,
        "content": "세부 조정 비용을 조사하는 과정에서, 1,000 토큰을 훈련하는 비용이 저렴하다는 것을 알게 되었다고 언급한다.",
        "shortcut": 9
      },
      {
        "id": 376,
        "content": "훈련 진행 상황을 확인하는 과정에서, 훈련이 진행되고 있는지 확인이 어려운 점과 비용에 대한 우려를 표현하고 있다.",
        "shortcut": 22
      },
      {
        "id": 377,
        "content": "**모델 훈련** 중에 예기치 않은 비용 발생을 피하기 위해, 필요시 언제든지 훈련 작업을 중단할 수 있다고 강조한다.",
        "shortcut": 23
      },
      {
        "id": 378,
        "content": "명확한 가격 예시가 부족하다는 점을 지적하며, 여러 플랫폼에서 모델을 성공적으로 훈련한 경험을 공유한다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 73,
    "title": "11. 🖼️ Amazon Bedrock을 이용한 이미지 생성 탐색",
    "startTime": "00:38:41.000",
    "endTime": "00:41:41.000",
    "items": [
      {
        "id": 379,
        "content": "영상에서 Andrew Brown은 **Amazon Bedrock**을 이용한 이미지 생성을 탐색하고 있다.",
        "shortcut": 1
      },
      {
        "id": 380,
        "content": "사용 경험에 따르면, **Amazon Bedrock**은 사용하기 어렵고 결과가 잘 나오지 않는 경우가 많다고 언급한다.",
        "shortcut": 3
      },
      {
        "id": 381,
        "content": "사용자는 다양한 샘플링 옵션인 fast, blue, green, neon, slow 중에서 선택할 수 있다.",
        "shortcut": 8
      },
      {
        "id": 382,
        "content": "이미지를 생성하기 위해 256x256 이상의 이미지 크기가 필요하며, 이를 충족하지 않으면 오류가 발생한다고 설명한다.",
        "shortcut": 19
      },
      {
        "id": 383,
        "content": "실제로 촬영한 사진을 사용하여 파이레츠 배경에서의 생성 시도를 하지만, 생성된 이미지의 결과가 만족스럽지 않았다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 74,
    "title": "12. 🖼️ 이미지 생성 모델 및 설정 조정",
    "startTime": "00:42:04.000",
    "endTime": "00:45:04.000",
    "items": [
      {
        "id": 384,
        "content": "이미지와 안정적 확산(Stable Diffusion)은 네 가지 주요 모델인 클립 텍스트 인코더, VAE, 오토인코더, UNet에 의해 생성된다.",
        "shortcut": 1
      },
      {
        "id": 385,
        "content": "이미지 설명을 변경하여 사진에서 싫어하는 것을 직접 명시하는 부정적인 프롬프트를 사용하고 있으며, 이를 통해 조정 및 수정이 가능하다.",
        "shortcut": 3
      },
      {
        "id": 386,
        "content": "특정 영역을 대상으로 태양을 추가하는 조정을 시도하며, 결과가 완벽하지는 않지만 기능이 작동함을 보여준다.",
        "shortcut": 6
      },
      {
        "id": 387,
        "content": "CLIP glance 기술은 CLIP 신경망을 활용하여 생성된 이미지를 포함된 프롬프트와 더 잘 일치시키도록 안내한다.",
        "shortcut": 10
      },
      {
        "id": 388,
        "content": "안정적 확산을 위한 다양한 설정(예: 샘플러)을 조정할 수 있는 방법을 탐색하고 있으며, 텍스트 인코딩을 위한 클립 레이어 조정과 스타일 관련 요소도 고려되고 있다.",
        "shortcut": 18
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 75,
    "title": "13. 🚦 Amazon Bedrock의 가드레일 기능",
    "startTime": "00:45:53.000",
    "endTime": "00:49:53.000",
    "items": [
      {
        "id": 389,
        "content": "가드레일은 LLM( **대형 언어 모델**)을 위한 입력과 출력을 필터링하는 기능이다.",
        "shortcut": 18
      },
      {
        "id": 390,
        "content": "콘텐츠 필터는 유해 범주 필터를 기반으로 하여 0에서 5까지의 스코어를 제공한다.",
        "shortcut": 20
      },
      {
        "id": 391,
        "content": "프롬프트 공격 필터는 사용자가 LLM 모델의 논리를 파괴하거나 의도를 왜곡하려는 시도를 방지하는 기능이다.",
        "shortcut": 21
      },
      {
        "id": 392,
        "content": "그라운딩 필터는 참고 소스의 정보가 사실적인지 검증할 수 있는 점수 임계값을 제공한다.",
        "shortcut": 22
      },
      {
        "id": 393,
        "content": "LLM에 블록할 주제를 정의할 수 있는 거부 주제 필터는 최대 30개의 주제를 설정할 수 있으며, 모욕적 표현을 필터링할 수 있는 기능도 제공한다.",
        "shortcut": 24
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 76,
    "title": "14. 🛡️ 아마존 베드록 가드레일 설정 및 필터링",
    "startTime": "00:50:50.000",
    "endTime": "00:54:50.000",
    "items": [
      {
        "id": 394,
        "content": "아마존 베드록의 가드레일을 설정하기 위해 필터를 구성할 수 있는데, 문서에 따르면 콘텐츠 필터는 75센트의 비용을 부과하고, 추가적으로 특정 주제와 민감한 정보를 차단하는 것은 무료로 제공된다.",
        "shortcut": 5
      },
      {
        "id": 395,
        "content": "필터링 예시로, '아주르(Azure)'에 대한 언급을 차단하고, 오직 Adabas와 Cloud 관련 서비스에 대해서만 이야기할 수 있도록 설정할 수 있다.",
        "shortcut": 19
      },
      {
        "id": 396,
        "content": "문자 필터링 기능도 제공되며, 예를 들어 금지된 단어로 '바나나(banana)'를 추가할 수 있다. 그러나 사용자 인터페이스가 불편하여 설정 과정이 어려운 점이 있다.",
        "shortcut": 26
      },
      {
        "id": 397,
        "content": "개인 정보 보호 기능을 통해 다양한 정보 유형을 마스크(mask)하거나 차단(block)할 수 있으며, 정규 표현식을 사용하여 특정 패턴의 데이터도 필터링할 수 있다.",
        "shortcut": 32
      },
      {
        "id": 398,
        "content": "설정 후 특정 질문을 통해 가드레일이 작동하는지 테스트해보면, 예를 들어 '아주르와 바나나'를 언급하는 경우 차단 메시지를 반환하게 된다.",
        "shortcut": 51
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 77,
    "title": "15. 🛠️ Amazon Bedrock의 모델 호출 로그",
    "startTime": "00:55:48.000",
    "endTime": "00:57:48.000",
    "items": [
      {
        "id": 399,
        "content": "모델 호출 로깅을 통해 **Amazon Bedrock**에서 CloudWatch 로그로 데이터 전송이 가능하며, 이는 입력/출력 토큰 사용량 및 호출된 모델 정보를 확인하는 데 유용하다.",
        "shortcut": 3
      },
      {
        "id": 400,
        "content": "로그에서 작업 구분이 불가능하여, 여러 프로젝트에서 사용하는 모델을 구별하기 어려운 문제가 있다.",
        "shortcut": 5
      },
      {
        "id": 401,
        "content": "이를 해결하기 위한 방법으로는, 작업별로 별도의 계정을 만들거나, 다른 지역에서 모델을 실행하는 것이 제안된다.",
        "shortcut": 8
      },
      {
        "id": 402,
        "content": "**Amazon Bedrock**의 설정에서 모델 호출 로깅을 활성화할 수 있으며, 로그 그룹에서 구체적인 호출 정보를 확인할 수 있다.",
        "shortcut": 11
      },
      {
        "id": 403,
        "content": "보안 측면에서 민감한 정보가 CloudWatch 로그에 저장될 수 있으므로, 이를 S3에 저장하고 암호화하는 것이 바람직하다.",
        "shortcut": 21
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 78,
    "title": "16. 📊 아마존 베드락의 모델 평가 기능에 대한 고찰",
    "startTime": "00:58:32.000",
    "endTime": "01:02:32.000",
    "items": [
      {
        "id": 404,
        "content": "아마존 베드락은 **모델 평가** 기능을 통해 사용자가 모델을 평가할 수 있도록 한다, 그리고 이 기능은 자동, 팀 직접 운영, 관리형 작업 팀의 세 가지 모드를 제공한다.",
        "shortcut": 13
      },
      {
        "id": 405,
        "content": "자동 모드를 선택할 경우, 최소 네 가지의 메트릭을 제공하는데, 이에는 정확도, 독성 및 강건성이 포함된다, 이는 Dat의 오픈 소스 **모델 평가**라이브러리를 기반으로 한다.",
        "shortcut": 15
      },
      {
        "id": 406,
        "content": "제공되는 데이터셋이 매우 크기 때문에, 사용자 맞춤의 데이터셋을 준비하지 않으면 비용이 금방 올라갈 가능성이 있다.",
        "shortcut": 17
      },
      {
        "id": 407,
        "content": "아마존 베드락의 **모델 평가**기능은 제대로 개발되지 않은 서비스라고 느끼며, 오픈 소스 라이브러리 사용을 추천한다.",
        "shortcut": 19
      },
      {
        "id": 408,
        "content": "사용자가 이 기능을 사용하기 전에 실습 영상을 참고하길 바라며, 실제로 사용하기보다는 참고하는 것이 더 바람직하다고 주장한다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 79,
    "title": "17. 🤖 자동 평가 프로세스 이해하기",
    "startTime": "01:02:46.000",
    "endTime": "01:06:46.000",
    "items": [
      {
        "id": 409,
        "content": "강화 학습은 인간 피드백을 통한 학습으로, 이는 학습 자체에 관한 것이고, 자동 평가는 별개의 과정이다.",
        "shortcut": 1
      },
      {
        "id": 410,
        "content": "모델을 사용하여 텍스트 분류 같은 자동 평가를 실행할 수 있으며, 내장된 데이터셋을 통해 정확도를 측정한다.",
        "shortcut": 4
      },
      {
        "id": 411,
        "content": "**Amazon Bedrock** **모델 평가**를 위해 요구되는 코어 설정이 이해되지 않으며, 설정을 수정할 필요가 있다.",
        "shortcut": 20
      },
      {
        "id": 412,
        "content": "모델 생성 시 올바른 권한을 명시해야 하며, 이를 위해 필요한 콘솔 권한이 포함된 정책을 설정할 수 있다.",
        "shortcut": 25
      },
      {
        "id": 413,
        "content": "UI의 불편함이 문제를 일으키고 있으며, 역할(policies)과 관련해 여러 설정이 복잡하게 얽혀 있어 오류가 발생할 가능성이 크다.",
        "shortcut": 39
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 80,
    "title": "18. 💻 Amazon Bedrock에 대한 IAM 역할 및 정책 설정",
    "startTime": "01:07:29.000",
    "endTime": "01:11:29.000",
    "items": [
      {
        "id": 414,
        "content": "텍스트 분류를 선택하고 **S3 버킷**에 접근하기 위해 필요한 설정을 진행하는 중이다.",
        "shortcut": 1
      },
      {
        "id": 415,
        "content": "**S3 버킷**의 존재하는 역할이나 새로운 역할 생성을 위해 UI의 불편함을 호소하며, 기존 역할을 다시 선택할 것을 고려하고 있다.",
        "shortcut": 6
      },
      {
        "id": 416,
        "content": "**Amazon Bedrock**을 활용하기 위해 IAM 역할과 정책을 생성하는 필요성을 언급하고, 관련된 권한을 설정하는 것에 대해 고민하고 있다.",
        "shortcut": 24
      },
      {
        "id": 417,
        "content": "Bedrock의 신뢰 정책 및 주체(Principal)에 대한 정보가 부족하다고 느끼며, ChatGPT에게 도움을 요청할 의도도 보인다.",
        "shortcut": 22
      },
      {
        "id": 418,
        "content": "최종적으로, 불편한 UI로 인해 선택에 어려움을 겪는 가운데 기존의 역할을 사용하고 있음을 알리고 있다.",
        "shortcut": 37
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 81,
    "title": "19. 🛠️ AWS S3 버킷 및 Bedrock 설정 과정",
    "startTime": "01:12:21.000",
    "endTime": "01:15:21.000",
    "items": [
      {
        "id": 419,
        "content": "AWS **S3 버킷**에 접근하기 위해 필요한 설정들을 진행 중이다.",
        "shortcut": 2
      },
      {
        "id": 420,
        "content": "Bedrock이 호출할 권한이 없다는 오류가 발생했으며, 이는 Bedrock의 IM 정책을 검토해야 함을 나타낸다.",
        "shortcut": 6
      },
      {
        "id": 421,
        "content": "Amazon Titan으로 변경할 수 있으나, 원래 원하는 설정과는 다르다는 점이 언급된다.",
        "shortcut": 7
      },
      {
        "id": 422,
        "content": "최소한의 정보로 모델에 접근하는 방법을 찾아야 하며, 새로운 역할에 대한 권한 추가가 필요하다.",
        "shortcut": 13
      },
      {
        "id": 423,
        "content": "잘못된 행동을 피하기 위한 조정이 필요하며, 적절한 작업을 명시해야 하는 상황이다.",
        "shortcut": 20
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 82,
    "title": "20. 🛠️ 모델 실행 및 데이터 처리에서의 문제점",
    "startTime": "01:16:04.000",
    "endTime": "01:20:04.000",
    "items": [
      {
        "id": 424,
        "content": "실행 모델이 올바르게 설정되지 않으면, 유효하지 않은 모델 또는 액션이 발생할 수 있다.",
        "shortcut": 2
      },
      {
        "id": 425,
        "content": "**Amazon Bedrock**API를 사용하여 작업을 설정하는 과정에서 모델 관련 정의가 혼란스러울 수 있다.",
        "shortcut": 13
      },
      {
        "id": 426,
        "content": "접근 권한이 제대로 설정되지 않았다면, 모델 실행 오류가 발생할 수 있으며 이는 여러 번 확인해야 할 필요가 있다.",
        "shortcut": 28
      },
      {
        "id": 427,
        "content": "데이터셋의 대량인 고객 리뷰와 평가(23,000개)는 과도한 비용을 초래할 수 있어 주의가 필요하다.",
        "shortcut": 38
      },
      {
        "id": 428,
        "content": "데이터셋의 크기나 소비 비용에 대한 명확한 정보 부족은 사용자에게 혼란을 줄 수 있다.",
        "shortcut": 41
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 83,
    "title": "21. 🛠️ 평가 방법과 데이터 세트 활용",
    "startTime": "01:21:00.000",
    "endTime": "01:22:00.000",
    "items": [
      {
        "id": 429,
        "content": "작은 **데이터 세트**를 생성하여 테스트할 수 있지만, 유의미한 결과를 얻기 어려우므로 이를 실행하지 말 것을 권장한다.",
        "shortcut": 1
      },
      {
        "id": 430,
        "content": "현재 사용할 수 있는 데이터가 부족하여 훈련 데이터의 양을 추정하기 어려운 상황이다.",
        "shortcut": 3
      },
      {
        "id": 431,
        "content": "서비스를 이용할 경우 자신의 **데이터 세트**를 사용하는 것이 정확한 평가에 도움이 된다.",
        "shortcut": 5
      },
      {
        "id": 432,
        "content": "사용자에게 인기 있는 제3자 벡터 스토어가 있으며, 이들은 **Amazon Bedrock**지식 기반에 통합될 수 있다.",
        "shortcut": 9
      },
      {
        "id": 433,
        "content": "Pinecone은 여러 임베딩에서 선택할 수 있는 사용하기 쉬운 벡터 스토어로, 많은 클라우드 서비스와의 통합이 가능하다.",
        "shortcut": 12
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 84,
    "title": "22. 🗂️ MongoDB Atlas 및 Pinecone 활용 방안",
    "startTime": "01:22:30.000",
    "endTime": "01:26:30.000",
    "items": [
      {
        "id": 434,
        "content": "MongoDB Atlas는 벡터 검색을 위해 UHN, ENN, HSNW와 같은 여러 검색 방법을 사용할 수 있다.",
        "shortcut": 1
      },
      {
        "id": 435,
        "content": "데이터가 MongoDB의 문서 데이터베이스에 있는 경우, MongoDB Atlas를 사용하면 낮은 추론 시간으로 데이터를 쉽게 가져올 수 있다.",
        "shortcut": 5
      },
      {
        "id": 436,
        "content": "Redis Enterprise는 Redis 인메모리 데이터베이스를 벡터 검색 데이터베이스로 변환하여, 빠른 검색이 가능하게 한다.",
        "shortcut": 9
      },
      {
        "id": 437,
        "content": "Pinecone는 사용이 간편하고 클라우드 네이티브 솔루션으로, 초기 비용을 절감하면서도 벡터 저장소로 활용할 수 있다.",
        "shortcut": 11
      },
      {
        "id": 438,
        "content": "Pinecone은 다양한 프레임워크와 통합되며, AWS에서 관리되는 방식으로 사용할 수 있다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 85,
    "title": "23. 🗂️ Pinecone 및 Momento 통합 과정",
    "startTime": "01:27:23.000",
    "endTime": "01:30:23.000",
    "items": [
      {
        "id": 439,
        "content": "데이터는 이곳에 저장되지 않지만, Pinecone과의 통합을 위해 새로운 노트북을 생성하면서 시작한다.",
        "shortcut": 1
      },
      {
        "id": 440,
        "content": "Pinecone 설치 후, 클라이언트 API를 초기화하기 위해 필요한 키를 설정해야 하며, 이를 후에 지워야 한다.",
        "shortcut": 9
      },
      {
        "id": 441,
        "content": "첫 번째 인덱스를 생성하는 과정에서 차원과 모델 지표로 cosine을 설정하고, AWS의 위치 US East 1에서 실행될 지 확인한다.",
        "shortcut": 12
      },
      {
        "id": 442,
        "content": "SER 스펙 정보를 확인하기 위해 문서를 검토하며, Azure나 GCP 같은 다른 제공업체로 교체 가능성을 탐색한다.",
        "shortcut": 18
      },
      {
        "id": 443,
        "content": "Momento는 캐싱 서비스로, 이를 통해 원하는 위치에 인덱스를 생성할 수 있으며, 사용자는 여전히 서비스 제공자가 관리하는 환경에서 작업하게 된다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 86,
    "title": "24. 🚀 모델과 데이터셋 로딩 과정",
    "startTime": "01:31:11.000",
    "endTime": "01:35:11.000",
    "items": [
      {
        "id": 444,
        "content": "데이터셋이 Colab에서 로딩되고 있으며, API 키와 서비스 사양을 사용하고 있다.",
        "shortcut": 1
      },
      {
        "id": 445,
        "content": "사용 중인 모델은 문장을 변환하는 모델로, 문장을 843차원 공간에 매핑한다.",
        "shortcut": 8
      },
      {
        "id": 446,
        "content": "문장 변환 모델은 최신 텍스트 및 이미지 임베딩 모델에 접근하기 위한 파이썬 모듈로, 문장 임베딩을 계산하는 데 활용된다.",
        "shortcut": 11
      },
      {
        "id": 447,
        "content": "업서트 작업을 위해 인덱스를 생성하고 있으며, 코사인 벡터 차원 검색을 사용함으로써 데이터를 검색할 준비가 되었음을 나타낸다.",
        "shortcut": 32
      },
      {
        "id": 448,
        "content": "데이터 삽입 시 벡터 데이터를 삽입하고 있으며, Pinecone에서 일관성이 보장되지만 업데이트된 삽입 데이터가 지연될 수 있음을 안내하고 있다.",
        "shortcut": 51
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 87,
    "title": "25. 🤖 유사성 검색 및 AI 어시스턴트 구축",
    "startTime": "01:35:45.000",
    "endTime": "01:37:45.000",
    "items": [
      {
        "id": 449,
        "content": "유사성 검색을 실행하여 각 네임스페이스에서 가장 유사한 세 개의 벡터를 쿼리할 수 있다.",
        "shortcut": 1
      },
      {
        "id": 450,
        "content": "가장 유사한 벡터로는 true 값과 다양한 값을 사용하여 매칭 결과를 얻는다.",
        "shortcut": 3
      },
      {
        "id": 451,
        "content": "임베딩을 활용하여 데이터를 전송하는 방식으로 사용될 것으로 추정된다.",
        "shortcut": 7
      },
      {
        "id": 452,
        "content": "Pinecone의 UI를 통해 질문-답변 기능이 포함된 AI 제품을 개발할 수 있다.",
        "shortcut": 10
      },
      {
        "id": 453,
        "content": "이 서비스는 문서를 업로드하고 질문을 던지며 응답을 받을 수 있는 RAG(Retrieval-Augmented Generation) 기능을 제공한다.",
        "shortcut": 12
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 88,
    "title": "26. 💾 Amazon Aurora와 RDS 개요",
    "startTime": "01:38:04.000",
    "endTime": "01:42:04.000",
    "items": [
      {
        "id": 454,
        "content": "Amazon Aurora와 RDS는 Postgres를 지원하는 관계형 데이터베이스이다.",
        "shortcut": 9
      },
      {
        "id": 455,
        "content": "Amazon Aurora는 Postgres와의 호환성을 가지고 있어, AIF가 비슷한 구조로 설계된 것으로 추정된다.",
        "shortcut": 10
      },
      {
        "id": 456,
        "content": "PostgreSQL에서 벡터 스토어를 사용하기 위해서는 PG Vector라는 확장이 필요하다.",
        "shortcut": 12
      },
      {
        "id": 457,
        "content": "PG Vector를 활용하면 3차원 벡터로 데이터를 입력하고 검색할 수 있으며, 이는 기존의 임베딩과의 거리를 반환하는 방식이다.",
        "shortcut": 14
      },
      {
        "id": 458,
        "content": "그러나 PG Vector는 다른 벡터 스토어로 설계된 데이터베이스에 비해 성능이 떨어지거나 확장성이 좋지 않을 수 있다.",
        "shortcut": 18
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 89,
    "title": "27. 🗄️ 데이터베이스 설정 및 관리",
    "startTime": "01:43:00.000",
    "endTime": "01:45:00.000",
    "items": [
      {
        "id": 459,
        "content": "사용자가 자동 스케일링 기능을 끄고 기본 BPC와 공용 액세스를 설정하고자 한다.",
        "shortcut": 2
      },
      {
        "id": 460,
        "content": "데이터베이스 이름을 Vector DB로 설정하고, 관련 정보를 기억하기 위해 노트에 적어두기로 한다.",
        "shortcut": 12
      },
      {
        "id": 461,
        "content": "백업 기능은 필요하지 않으며, 설정 비용을 절감하기 위해 삭제 보호를 원하지 않는다.",
        "shortcut": 20
      },
      {
        "id": 462,
        "content": "데이터베이스 실행 후, 파라미터 그룹에서 확장을 관리하는 방법을 알아보려 하며, 쿼리 편집기는 현재 원하는 방식으로 작동하지 않는다고 언급한다.",
        "shortcut": 27
      },
      {
        "id": 463,
        "content": "공용 액세스를 통해 다양한 도구를 사용할 수 있으며, TablePlus를 활용하고자 한다.",
        "shortcut": 37
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 90,
    "title": "28. 📊 Postgres 연결 및 확장 기능 설정",
    "startTime": "01:45:41.000",
    "endTime": "01:49:41.000",
    "items": [
      {
        "id": 464,
        "content": "새로운 Postgres 연결을 생성하며, 무료 및 유료 버전이 존재하는 점을 언급한다. 그 중 DBeaver도 사용할 수 있는 도구이다.",
        "shortcut": 2
      },
      {
        "id": 465,
        "content": "데이터베이스 이름은 Vector DB로 설정하며, 사용자 이름은 Postgres이고 비밀번호는 'testing'으로 설정한다.",
        "shortcut": 9
      },
      {
        "id": 466,
        "content": "데이터베이스의 호스트 위치를 확인하고, 포트는 일반적으로 5432이며 확인할 필요가 있다고 명시한다.",
        "shortcut": 11
      },
      {
        "id": 467,
        "content": "ChatGPT와 함께 작업하면서 설치 가능한 확장 기능 목록을 쿼리할 수 있음을 발견하고, 이를 통해 설치할 수 있는 확장 기능 목록을 확인한다.",
        "shortcut": 24
      },
      {
        "id": 468,
        "content": "확장 기능을 활성화하기 위해 create extension 명령어를 사용한다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 91,
    "title": "29. 📝 벡터 데이터 처리 및 검색 방법",
    "startTime": "01:50:24.000",
    "endTime": "01:53:24.000",
    "items": [
      {
        "id": 469,
        "content": "PG Vector를 활용해 데이터의 벡터 형태를 사용할 수 있는 방법이 소개된다.",
        "shortcut": 1
      },
      {
        "id": 470,
        "content": "테이블을 생성하여 필드 이름을 embedding으로 설정하고, 3차원의 벡터를 포함하는 아이템 테이블을 생성한다.",
        "shortcut": 15
      },
      {
        "id": 471,
        "content": "데이터 삽입 후, 모든 아이템을 검색할 수 있는 방법이 설명되며, 여기서 최근접 이웃 검색 기술이 적용된다.",
        "shortcut": 21
      },
      {
        "id": 472,
        "content": "현재는 임베딩을 사용하지 않고도 가장 가까운 이웃을 조회할 수 있으며, 검색 결과에서 거리 정보를 제공한다.",
        "shortcut": 24
      },
      {
        "id": 473,
        "content": "전체적인 설치 과정과 간단한 쿼리가 어떻게 구성되는지를 보여줌으로써, 사용자들이 벡터 데이터를 쉽게 처리할 수 있도록 돕는다.",
        "shortcut": 26
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 92,
    "title": "30. 🗄️ 다이나모DB와 문서DB의 차이점",
    "startTime": "01:53:44.000",
    "endTime": "01:54:44.000",
    "items": [
      {
        "id": 474,
        "content": "다이나모DB와 문서DB는 두 가지 유사한 데이터베이스로, 생성 AI를 위한 특정 용도로 사용될 수 있다.",
        "shortcut": 16
      },
      {
        "id": 475,
        "content": "다이나모DB는 키-값 저장소로, 기술적으로 문서 데이터베이스로 분류되지만 기능이 간단하고 직관적이어서 키-값으로 간주된다.",
        "shortcut": 19
      },
      {
        "id": 476,
        "content": "다이나모DB는 확장성이 뛰어나지만 벡터 검색 기능이 없어 해당 방식으로 쿼리할 수 없다.",
        "shortcut": 20
      },
      {
        "id": 477,
        "content": "그럼에도 불구하고, 다이나모DB는 RAG(불확실성 반영 생성기) 내에서 사용할 수 있으며, 다이나모DB 쿼리를 생성할 수 있도록 코딩할 수 있다.",
        "shortcut": 21
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 93,
    "title": "31. 🗄️ 다양한 데이터베이스와 그 활용",
    "startTime": "01:55:17.000",
    "endTime": "01:57:17.000",
    "items": [
      {
        "id": 478,
        "content": "RAG는 데이터베이스와 함께 사용할 수 있으며, 이를 지원하는 코드나 프레임워크가 필요하다.",
        "shortcut": 1
      },
      {
        "id": 479,
        "content": "DynamoDB는 채팅 기록을 저장하는 데 유용하며, 세션 관리 케이스로 적합하다.",
        "shortcut": 2
      },
      {
        "id": 480,
        "content": "DocumentDB는 MongoDB와 호환되는 데이터베이스로, 벡터 검색을 지원한다.",
        "shortcut": 3
      },
      {
        "id": 481,
        "content": "DocumentDB는 Postgres의 수정된 버전으로, AWS는 그것이 Postgres라고 하지만, 구조에 대한 세부 사항은 알려져 있지 않다.",
        "shortcut": 5
      },
      {
        "id": 482,
        "content": "Amazon Neptune은 여러 그래프 언어를 활용할 수 있는 그래프 데이터베이스이다.",
        "shortcut": 9
      },
      {
        "id": 483,
        "content": "Amazon OpenSearch는 Apache Lucene 검색 라이브러리를 기반으로 하며, 데이터를 수집하고 인덱싱 및 검색하는 데 사용된다.",
        "shortcut": 16
      },
      {
        "id": 484,
        "content": "OpenSearch는 일반 텍스트 검색뿐만 아니라 벡터 스토어로도 사용 가능하며, 다양한 유형의 검색을 수행할 수 있다.",
        "shortcut": 17
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 94,
    "title": "32. 🛠️ Amazon Party Rock의 기능과 한계",
    "startTime": "01:58:06.000",
    "endTime": "02:02:06.000",
    "items": [
      {
        "id": 485,
        "content": "Amazon Party Rock은 사용자가 쉽게 하위 웹 앱을 구축할 수 있도록 돕는 무코드 개발 환경이다.",
        "shortcut": 1
      },
      {
        "id": 486,
        "content": "이 플랫폼은 여러 개의 대화형 에이전트(widgets)를 제공하며, 각 에이전트는 자신의 작업을 수행하고 다른 에이전트의 출력에 의존할 수 있다.",
        "shortcut": 4
      },
      {
        "id": 487,
        "content": "Party Rock에는 다양한 기능이 있지만, 특히 프로토타이핑과 LLM 사용의 창의적인 탐색에 유용하다.",
        "shortcut": 8
      },
      {
        "id": 488,
        "content": "사용자는 Google, Apple, Amazon 계정으로 로그인할 수 있지만, Builder ID로는 로그인할 수 없는 제한이 있다.",
        "shortcut": 6
      },
      {
        "id": 489,
        "content": "앱 생성 후에는 다른 사용자와의 링크 공유가 가능하며, 문서 업로드 기능도 지원하나 아직 실사용이 미비하다.",
        "shortcut": 5
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 95,
    "title": "33. 🎮 게임 주제 및 구성 요소",
    "startTime": "02:03:00.000",
    "endTime": "02:07:00.000",
    "items": [
      {
        "id": 490,
        "content": "게임의 주제는 모던 스릴러와 모험이다.",
        "shortcut": 1
      },
      {
        "id": 491,
        "content": "Zork와 유사한 게임으로, 사용자 입력이 필요한 게임 지침이 있다.",
        "shortcut": 3
      },
      {
        "id": 492,
        "content": "입력된 지시사항은 일본어로 해야 하며, 모든 본문 텍스트는 영어로 제공된다.",
        "shortcut": 5
      },
      {
        "id": 493,
        "content": "사용자는 일본어를 배울 수 있도록 일부 핵심 명사는 일본어로 제공된다.",
        "shortcut": 5
      },
      {
        "id": 494,
        "content": "게임의 시작은 일본어로 \"start\"라고 입력해야 하며, 이는 \"hajime\"로 추정된다.",
        "shortcut": 14
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 96,
    "title": "34. 🎮 UI 인터페이스와 일본어 동작 목록",
    "startTime": "02:07:22.000",
    "endTime": "02:11:22.000",
    "items": [
      {
        "id": 495,
        "content": "UI 인터페이스는 사용자가 모험 게임에서 수행할 수 있는 행동의 목록을 제시한다.",
        "shortcut": 1
      },
      {
        "id": 496,
        "content": "일본어 단어를 기반으로 사용자가 취할 수 있는 가능성을 나열하는 것이 목적이다.",
        "shortcut": 2
      },
      {
        "id": 497,
        "content": "게임 내에서 특정 명령을 잘 수행하기 위해서는 매우 세부적인 지시가 필요하다.",
        "shortcut": 5
      },
      {
        "id": 498,
        "content": "대화의 흐름을 바탕으로 각 상황에 맞는 동작을 제시하고자 하며, 이는 게임 내 문맥을 고려하여 진행된다.",
        "shortcut": 8
      },
      {
        "id": 499,
        "content": "다양한 일본어 표현이 출력되고 있으며, 특정 행동이나 아이템에 대한 명확한 지시가 부족하다는 점이 언급된다.",
        "shortcut": 17
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 97,
    "title": "35. 🖥️ 머신 러닝 워크플로우 개요",
    "startTime": "02:12:09.000",
    "endTime": "02:16:09.000",
    "items": [
      {
        "id": 500,
        "content": "머신 러닝 워크플로우는 여러 단계와 단계를 포함한 ML 솔루션을 구축하는 과정이다.",
        "shortcut": 21
      },
      {
        "id": 501,
        "content": "데이터 수집 단계에서, 데이터는 공개 데이터셋이나 리포지토리에서 가져오며, 이 데이터는 하나의 장소에 위치한다.",
        "shortcut": 24
      },
      {
        "id": 502,
        "content": "데이터 정제 과정에서는 동일 열의 일부 항목이 '미국'으로 표기되고 다른 항목이 'US'로 표기되는 사례처럼 데이터의 일관성을 위해 정규화가 필요하다.",
        "shortcut": 26
      },
      {
        "id": 503,
        "content": "데이터 준비 단계에서는 두 개의 속성을 결합하여 새로운 속성을 생성할 수 있으며, 이는 모델에 최적화된 데이터 포인트가 적게 들어가는 결과를 가져온다.",
        "shortcut": 29
      },
      {
        "id": 504,
        "content": "**모델 훈련** 단계에서 알고리즘이 필요하며, SageMaker에는 기본 제공되는 알고리즘이 여러 개 있으며 Hugging Face에서도 다양한 알고리즘을 활용할 수 있다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 98,
    "title": "36. 🛠️ 머신러닝 파이프라인과 데이터 준비",
    "startTime": "02:16:31.000",
    "endTime": "02:20:31.000",
    "items": [
      {
        "id": 505,
        "content": "SageMaker는 AI 솔루션을 구축하기 위한 통합 머신러닝 플랫폼으로, 데이터 준비, 특징 엔지니어링, 훈련, **미세 조정**등을 포함하는 다양한 단계가 있다.",
        "shortcut": 1
      },
      {
        "id": 506,
        "content": "데이터 준비 단계에서는 데이터 라벨링, **데이터 세트**, 실험, 최적화 등을 포함하여 데이터 수집이 중요하다.",
        "shortcut": 17
      },
      {
        "id": 507,
        "content": "S3는 머신러닝 모델용 데이터를 수집하기 위한 훌륭한 장소이며, AWS Glue Data Catalog는 메타데이터 저장에 유용하다.",
        "shortcut": 23
      },
      {
        "id": 508,
        "content": "Exploratory Data Analysis(EDA)는 **데이터 세트**를 분석하여 머신러닝 용도에 적합한 형태로 만드는 과정이다.",
        "shortcut": 27
      },
      {
        "id": 509,
        "content": "데이터 전처리를 위한 서비스로는 SageMaker의 Data Wrangler와 AWS Glue DataBrew가 있으며, Data Wrangler는 머신러닝 파이프라인에 더 적합하다.",
        "shortcut": 35
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 99,
    "title": "37. 📊 AWS Data Wrangler와 SageMaker Data Wrangler",
    "startTime": "02:21:26.000",
    "endTime": "02:23:26.000",
    "items": [
      {
        "id": 510,
        "content": "AWS Data Wrangler는 AWS가 제공하는 오픈 소스 라이브러리로, Pandas 라이브러리를 AWS와 연결하여 데이터를 처리할 수 있게 해준다.",
        "shortcut": 2
      },
      {
        "id": 511,
        "content": "이 라이브러리는 ETL 작업을 수행할 수 있는 추상화된 기능을 제공하며, 데이터 레이크, 데이터 웨어하우스, 데이터베이스에서의 데이터 로드 및 언로드를 지원한다.",
        "shortcut": 2
      },
      {
        "id": 512,
        "content": "SageMaker Data Wrangler는 데이터 준비 및 특징 엔지니어링 프로세스를 단순화하는 기능으로, 300개 이상의 내장 데이터 변환을 제공하여 코드 작성 없이 쉽게 데이터를 변환하고 결합할 수 있게 한다.",
        "shortcut": 6
      },
      {
        "id": 513,
        "content": "데이터 과학자 조사에 따르면, ML 모델을 위한 데이터 준비는 데이터 과학자의 시간의 66%를 차지한다고 하여, 데이터 준비 작업이 많은 비중을 차지한다.",
        "shortcut": 8
      },
      {
        "id": 514,
        "content": "SageMaker Data Wrangler는 SageMaker Canvas에서 제공되며, 이전 버전의 SageMaker Studio Classic보다 사용자 경험이 떨어진다고 주장된다.",
        "shortcut": 11
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 100,
    "title": "38. ⚠️ SageMaker 사용 시 주의사항",
    "startTime": "02:23:42.000",
    "endTime": "02:27:42.000",
    "items": [
      {
        "id": 515,
        "content": "SageMaker Canvas를 사용할 때는 모든 기능이 꺼져 있는지 확인해야 하며, 그렇지 않으면 예기치 않은 비용이 발생할 수 있다.",
        "shortcut": 7
      },
      {
        "id": 516,
        "content": "SageMaker Canvas는 작동 중일 때 시간당 $19의 비용이 청구되며, 이로 인해 예상치 못한 지출이 발생할 수 있다.",
        "shortcut": 9
      },
      {
        "id": 517,
        "content": "작업 공간 인스턴스가 활성화된 상태에서는 탭을 닫는 것만으로는 사용 중인 인스턴스가 종료되지 않아 추가 비용이 발생할 수 있다.",
        "shortcut": 12
      },
      {
        "id": 518,
        "content": "AWS의 사용자 인터페이스는 가독성이 떨어져 사용자가 비용 청구 상황을 이해하기 어려운 점이 있어 개선이 필요하다.",
        "shortcut": 31
      },
      {
        "id": 519,
        "content": "예산 설정을 하더라도, SageMaker의 가격 구조가 복잡해 예상치 못한 비용이 발생할 수 있음을 유념해야 한다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 101,
    "title": "39. 🔍 SageMaker Canvas 사용 시 비용 문제 및 주의 사항",
    "startTime": "02:27:44.000",
    "endTime": "02:29:44.000",
    "items": [
      {
        "id": 520,
        "content": "SageMaker Canvas의 사용 중 예상치 못한 비용 발생이 있었으며, 이는 사용자 경험 디자인의 결함 때문이다.",
        "shortcut": 2
      },
      {
        "id": 521,
        "content": "SageMaker Canvas는 인터페이스를 실행하기만 해도 비용이 발생하므로 주의가 필요하다.",
        "shortcut": 12
      },
      {
        "id": 522,
        "content": "해당 서비스는 로그아웃 버튼을 클릭해야 비용 발생을 멈출 수 있으며, 탭을 닫으면 계속 비용이 발생한다.",
        "shortcut": 17
      },
      {
        "id": 523,
        "content": "비용 경고 알림이 제대로 전달되지 않을 수 있어, 예상치 못한 지출을 초래할 수 있다.",
        "shortcut": 19
      },
      {
        "id": 524,
        "content": "직관적이지 못한 비주얼 디자인 문제로 인해 사용자들이 비용 발생을 인식하기 어려운 상황이 발생할 수 있다.",
        "shortcut": 21
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 102,
    "title": "40. 🧠 AutoML과 SageMaker Canvas의 기능",
    "startTime": "02:30:21.000",
    "endTime": "02:31:21.000",
    "items": [
      {
        "id": 525,
        "content": "SageMaker Canvas는 데이터셋을 쉽게 가져올 수 있도록 하여, 사용자로 하여금 저장소에 대한 걱정 없이 다양한 데이터셋을 활용할 수 있게 해준다.",
        "shortcut": 3
      },
      {
        "id": 526,
        "content": "AutoML은 기계 학습 파이프라인의 자동화를 의미하며, 복잡성을 줄이고 머신러닝 모델 설정을 도와준다.",
        "shortcut": 6
      },
      {
        "id": 527,
        "content": "AutoML의 과정은 데이터 수집, 탐색, 준비, 기능 공학, 모델 선택, **모델 훈련**, 하이퍼파라미터 조정 및 예측 등을 포함하며 , 이러한 단계들은 일반적으로 자체 파이프라인을 구축할 때 수행해야 하는 작업들이다.",
        "shortcut": 7
      },
      {
        "id": 528,
        "content": "AutoML의 목적은 중간적인 작업들을 처리하는 것으로, 사용자는 데이터를 업로드하고 ML 유형을 선택하기만 하면 준비가 완료된다.",
        "shortcut": 10
      },
      {
        "id": 529,
        "content": "이러한 과정을 통해 사용자는 데이터 과학자처럼 보일 수 있지만, 제공되는 모델 유형에 대해서는 중간 과정이 그리 어렵지 않다는 점이 강조된다.",
        "shortcut": 11
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 103,
    "title": "41. ⚠️ SageMaker Canvas 사용에 대한 경고",
    "startTime": "02:31:41.000",
    "endTime": "02:34:41.000",
    "items": [
      {
        "id": 530,
        "content": "SageMaker Canvas는 사용하기에 비효율적인 서비스로, 비용이 발생할 수 있다는 점을 유의해야 한다.",
        "shortcut": 2
      },
      {
        "id": 531,
        "content": "AutoML에서 이름이 변경된 SageMaker Autopilot는 다양한 ML 문제를 해결할 수 있지만, 중요한 언어가 숨겨져 있어 이해하기 어렵다고 느껴진다.",
        "shortcut": 5
      },
      {
        "id": 532,
        "content": "주어진 CSV 데이터만 지원하며, 텍스트 기반 문제의 경우 사용이 제한적이라는 점을 인지해야 한다.",
        "shortcut": 21
      },
      {
        "id": 533,
        "content": "SageMaker Canvas는 사용자가 모델을 선택하고 실행할 수 있는 UI를 제공하지만, 실제로는 유용하지 않다고 평가된다.",
        "shortcut": 23
      },
      {
        "id": 534,
        "content": "사용 중 비용이 급증할 수 있으므로, 실행 여부를 확인하기 어려운 점에 대해 주의해야 하며 , 사용을 자제할 것을 권장한다.",
        "shortcut": 31
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 104,
    "title": "42. 🖥️ SageMaker Canvas와 데이터 탐색 및 모델링",
    "startTime": "02:35:40.000",
    "endTime": "02:39:40.000",
    "items": [
      {
        "id": 535,
        "content": "SageMaker Canvas는 무료 계층이 있지만, 이를 초과하면 비용이 발생하며, workspace instance를 운영하는 데 $11.90의 비용이 든다 (단가 정보).",
        "shortcut": 5
      },
      {
        "id": 536,
        "content": "데이터를 탐색하기 위해 Data Wrangler를 사용하며, 특정 데이터를 임포트하여 분석을 시작한다 (데이터 임포트 과정).",
        "shortcut": 10
      },
      {
        "id": 537,
        "content": "탐색한 데이터셋은 위도, 경도, 주택, 방 수 등의 기본 정보를 포함하고 있으며, 샘플 데이터 임포트를 통해 분석을 진행할 예정이다 (데이터 특성).",
        "shortcut": 18
      },
      {
        "id": 538,
        "content": "사용자 인터페이스에서 변환 작업을 추가할 수 있으며, 다양한 변환 옵션이 있지만 이해하기 어렵다는 점이 언급된다 (변환 작업 추가).",
        "shortcut": 26
      },
      {
        "id": 539,
        "content": "모델 생성 옵션이 존재하지만, 모델이 무엇인지 명확하지 않으며, MLOps로 데이터 모델을 실행할 수 있는 가능성을 언급한다 (모델링 가능성).",
        "shortcut": 42
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 105,
    "title": "43. 🛠️ 모델 배포와 예측 분석 과정",
    "startTime": "02:40:11.000",
    "endTime": "02:44:11.000",
    "items": [
      {
        "id": 540,
        "content": "모델을 배포하면, 배포 목록에서 확인할 수 있으며, 다양한 모델 옵션이 제시된다.",
        "shortcut": 1
      },
      {
        "id": 541,
        "content": "새로운 모델 생성 시, 예측 분석, 이미지 분석, 텍스트 분석, 모델의 세부 조정 등 다양한 옵션 중에서 선택 가능하다.",
        "shortcut": 4
      },
      {
        "id": 542,
        "content": "**데이터 세트**를 선택한 후, 예측할 열을 선택하고, 숫자 예측 모델 유형으로 설정하여 모델을 구성한다.",
        "shortcut": 11
      },
      {
        "id": 543,
        "content": "빠른 빌드 또는 표준 빌드 옵션을 통해 2-15분 내에 모델을 구축할 수 있으며, 빠른 빌드를 선택하면 모델 공유가 불가능하다.",
        "shortcut": 17
      },
      {
        "id": 544,
        "content": "모델 생성 후, 수치 값을 변경하여 단일 예측을 진행할 수 있으며, 그에 따라 새로운 예측 결과를 얻을 수 있다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 106,
    "title": "44. 📊 SageMaker Feature Store의 기능과 데이터 수집 방법",
    "startTime": "02:44:49.000",
    "endTime": "02:48:49.000",
    "items": [
      {
        "id": 545,
        "content": "SageMaker Feature Store는 데이터 과학자와 머신러닝 엔지니어가 기능을 쉽게 생성, 공유 및 관리할 수 있도록 돕는다. 이를 통해 반복적인 데이터 처리와 큐레이션 작업을 줄여 ML 알고리즘 훈련을 위한 원시 데이터를 기능으로 변환할 수 있다.",
        "shortcut": 9
      },
      {
        "id": 546,
        "content": "이 스토어는 기능과 관련 메타데이터를 위한 중앙 집중식 저장소로, 기능을 쉽게 검색하고 재사용할 수 있게 해준다.",
        "shortcut": 10
      },
      {
        "id": 547,
        "content": "데이터는 온라인이나 오프라인으로 저장할 수 있으며, 오프라인은 실시간으로 사용되지 않는 상태를 의미한다.",
        "shortcut": 11
      },
      {
        "id": 548,
        "content": "데이터 수집 방법으로는 스트리밍과 배치 방식이 있으며, 스트리밍 방식은 인제스팅 API를 통해 이루어진다.",
        "shortcut": 20
      },
      {
        "id": 549,
        "content": "SageMaker Feature Store는 데이터 품질을 유지하기 위해 데이터 유효성 검사를 진행하며, 입력 데이터가 정의된 데이터 유형에 부합하는지 확인한다.",
        "shortcut": 23
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 107,
    "title": "45. ☁️ SageMaker Python SDK와 데이터 처리",
    "startTime": "02:49:12.000",
    "endTime": "02:53:12.000",
    "items": [
      {
        "id": 550,
        "content": "Data Wrangler는 SageMaker Studio에서 기능 저장소를 사용할 수 있게 해준다. 그리고 Athena와 연동하여 쿼리를 실행해 데이터셋을 구축할 수도 있다.",
        "shortcut": 1
      },
      {
        "id": 551,
        "content": "SageMaker는 HTTPS 요청을 수락하는 지역별 서비스 엔드포인트를 가지고 있으며, 모델을 훈련하고 배포하는 데 사용된다.",
        "shortcut": 11
      },
      {
        "id": 552,
        "content": "SageMaker Python SDK는 Boto 3와 달리 SageMaker 및 특정 머신러닝 도구와의 통합을 제공하며, 다양한 ML 프레임워크를 지원한다.",
        "shortcut": 19
      },
      {
        "id": 553,
        "content": "SageMaker Estimators는 훈련을 기반으로 최적의 ML 모델을 선택하는 공식으로, 모델과 예측기를 포함하여 실시간 추론을 제공한다.",
        "shortcut": 27
      },
      {
        "id": 554,
        "content": "**모델 훈련**을 위해 training script를 준비하고, 해당 스크립트에서 추정기를 만들고 fit 메서드를 호출해야 하며, 각 모델의 상이한 매개변수를 제공해야 한다.",
        "shortcut": 31
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 108,
    "title": "46. 🛠️ SageMaker Python의 모델 학습 및 로컬 모드 설정",
    "startTime": "02:53:43.000",
    "endTime": "02:57:43.000",
    "items": [
      {
        "id": 555,
        "content": "**모델 훈련**을 위해 SageMaker Python을 사용하려면 훈련 스크립트를 준비해야 한다.",
        "shortcut": 2
      },
      {
        "id": 556,
        "content": "로컬 모드에서는 TensorFlow, MXNet, Chainer, PyTorch, scikit-learn과 같은 여러 프레임워크 이미지를 지원하며, 사용자 지정 이미지도 사용할 수 있다.",
        "shortcut": 8
      },
      {
        "id": 557,
        "content": "로컬 모드의 설정 방법은 전역적으로 또는 지역적으로 구성할 수 있으며, 로컬 코드를 사용할 경우 의존성 매개변수를 사용할 수 없다.",
        "shortcut": 12
      },
      {
        "id": 558,
        "content": "SageMaker 세션은 훈련 작업, 엔드포인트 및 입력 데이터와 같은 Amazon SageMaker의 리소스를 조작하기 위한 편리한 방법을 제공한다.",
        "shortcut": 21
      },
      {
        "id": 559,
        "content": "입력 매니페스트 파일은 **S3 버킷**에 배치해야 하며, CORS가 활성화되어 있지 않거나 데이터 형식이 잘못된 경우 문제가 발생할 수 있다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 109,
    "title": "47. 📁 JSONL 파일 및 CORS 구성 요구사항",
    "startTime": "02:57:45.000",
    "endTime": "02:59:45.000",
    "items": [
      {
        "id": 560,
        "content": "**JSONL 파일**은 S3에 저장된 입력 데이터를 사용해야 하며, SageMaker가 데이터를 읽을 수 있도록 권한을 부여해야 한다.",
        "shortcut": 2
      },
      {
        "id": 561,
        "content": "매니페스트 파일은 라벨링 작업과 동일한 지역에 위치해야 하며, UTF-8 인코딩 형식을 사용해야 한다.",
        "shortcut": 4
      },
      {
        "id": 562,
        "content": "JSON 객체는 크기가 100,000자를 초과할 수 없고, 객체 내의 단일 속성은 20,000자를 초과할 수 없다.",
        "shortcut": 7
      },
      {
        "id": 563,
        "content": "지원되는 입력 매니페스트 파일 형식은 이미지, 텍스트, 비디오 및 객체 추적을 위한 비디오 프레임 시퀀스를 포함한다.",
        "shortcut": 9
      },
      {
        "id": 564,
        "content": "CORS는 웹 페이지에서 제한된 자원을 다른 도메인에서 요청할 수 있도록 하는 메커니즘으로, 입력 데이터의 방향 수정 및 CORS 구성 설정이 필요하다.",
        "shortcut": 11
      }
    ],
    "sourceIndex": 3
  },
  {
    "id": 110,
    "title": "1. 🎨 라벨링 및 모델 조정",
    "startTime": "00:00:00.000",
    "endTime": "00:03:00.000",
    "items": [
      {
        "id": 565,
        "content": "**SageMaker Ground Truth**는 다양한 데이터 유형(이미지, 텍스트, 비디오, 포인트 클라우드)에 대한 라벨링 작업을 지원하며, 사용자 친화적인 인터페이스를 제공한다.",
        "shortcut": 3
      },
      {
        "id": 566,
        "content": "사용자 지정 라벨링을 위해 HTML 같은 **템플릿**을 제공하고, 여러 미리 만들어진 구성 요소를 통해 커스터마이즈할 수 있다.",
        "shortcut": 17
      },
      {
        "id": 567,
        "content": "라벨링 작업은 Amazon 팀, Amazon Mechanical Turk, 또는 개인 팀을 통해 수행할 수 있으며, 24/7 이용 가능한 인력이 존재한다.",
        "shortcut": 23
      },
      {
        "id": 568,
        "content": "SageMaker 자동 모델 조정은 지정한 하이퍼파라미터 범위를 기반으로 최적의 모델을 찾는 과정이며, 데이터셋과 알고리즘의 이해가 중요하다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 111,
    "title": "2. 🔍 하이퍼파라미터 튜닝과 예측 배치",
    "startTime": "00:03:36.000",
    "endTime": "00:05:36.000",
    "items": [
      {
        "id": 569,
        "content": "**하이퍼파라미터 튜닝**은 딥러닝 모델의 최적 버전을 찾기 위해 많은 조합을 수동으로 탐색할 수 없기 때문에 유용하다.",
        "shortcut": 2
      },
      {
        "id": 570,
        "content": "예를 들어, XGBoost 알고리즘을 사용하여 이진 분류 문제를 해결하고자 할 때, AUC 지표를 극대화하기 위해 ETA, Alpha, Min child weight 및 Max depth와 같은 조정 가능한 매개변수를 최적화해야 한다.",
        "shortcut": 3
      },
      {
        "id": 571,
        "content": "SageMaker의 자동 모델 튜닝 기능을 통해 매개변수 값의 범위를 지정하면, 모델 학습 작업을 수행하여 가장 높은 AUC를 찾는다.",
        "shortcut": 6
      },
      {
        "id": 572,
        "content": "**하이퍼파라미터 튜닝**에는 두 가지 최적화 방법이 있으며, 랜덤 탐색과 베이지안 탐색이 사용되며, 그리드 탐색은 비효율적이므로 사용되지 않는다.",
        "shortcut": 10
      },
      {
        "id": 573,
        "content": "예측을 위해 **ML 모델**을 배포하는 방법에는 **실시간 예측**(API 엔드포인트)과 배치 예측이 있으며, 각각 SageMaker 호스팅 서비스와 배치 변환을 사용하여 처리된다.",
        "shortcut": 21
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 112,
    "title": "3. 🔍 추론 파이프라인 이해하기",
    "startTime": "00:06:22.000",
    "endTime": "00:08:22.000",
    "items": [
      {
        "id": 574,
        "content": "Amazon SageMaker의 모델은 두 개에서 다섯 개의 컨테이너로 구성되어 있으며, 이들은 데이터를 처리하고 **추론**요청을 처리한다.",
        "shortcut": 5
      },
      {
        "id": 575,
        "content": "**추론** 파이프라인은 사전 훈련된 SageMaker 내장 알고리즘과 사용자 정의 알고리즘을 Docker 컨테이너에 패키징하여 정의하고 배포할 수 있게 해준다.",
        "shortcut": 6
      },
      {
        "id": 576,
        "content": "데이터 과학 작업을 결합하여 **사전 처리**, 예측 및 사후 처리를 수행할 수 있으며, 학습에 사용했던 컨테이너를 재사용할 수 있다.",
        "shortcut": 7
      },
      {
        "id": 577,
        "content": "**추론**파이프라인을 배포하면, 모든 컨테이너가 ECS에서 실행되며, 따라서 낮은 지연 시간으로 **추론**결과를 받을 수 있다.",
        "shortcut": 10
      },
      {
        "id": 578,
        "content": "**추론** 파이프라인은 불변성이 있으며, 새로운 엔드포인트를 배포해야만 업데이트할 수 있다.",
        "shortcut": 12
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 113,
    "title": "4. 🛠️ 모델 배포 및 모니터링",
    "startTime": "00:09:05.000",
    "endTime": "00:13:05.000",
    "items": [
      {
        "id": 579,
        "content": "단일 모델에는 **사전 처리**및 **후처리**를 포함한 **추론**스크립트가 있으며, TensorFlow serving 모델을 사용하여 기능 핸들러를 설정한다.",
        "shortcut": 1
      },
      {
        "id": 580,
        "content": "SageMaker 파이프라인을 통해 사전 및 **후처리**단계를 만들 수 있고, SageMaker processing은 파이프라인과 함께 작동하도록 설계되어 있다.",
        "shortcut": 9
      },
      {
        "id": 581,
        "content": "**모델 배포**를 위해 ML EC2 인스턴스를 활용하며, 적절한 인스턴스를 지정하고 배포 기능을 호출하면 예측기를 반환받는다.",
        "shortcut": 11
      },
      {
        "id": 582,
        "content": "멀티모달 엔드포인트를 활용하면 여러 모델을 공유 컨테이너에 호스팅하여 **비용 절감**과 자원 효율성을 지원하고 A/B 테스트가 가능하다.",
        "shortcut": 20
      },
      {
        "id": 583,
        "content": "모델漂流은 시간 경과에 따른 모델 예측 정확도의 저하를 의미하며, SageMaker Model Monitor가 이를 측정하고 지속적으로 모니터링한다.",
        "shortcut": 33
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 114,
    "title": "5. 📦 SageMaker 모델 레지스트리와 처리",
    "startTime": "00:13:25.000",
    "endTime": "00:14:25.000",
    "items": [
      {
        "id": 584,
        "content": "**SageMaker 모델 레지스트리**는 **ML 모델**을 관리에 용이하게 하고, 버전 관리, 메타데이터 연관 등의 기능을 제공한다.",
        "shortcut": 1
      },
      {
        "id": 585,
        "content": "모델의 승인 상태를 관리하고, 모델을 배포하며, CI/CD를 통해 **모델 배포**를 **자동화**할 수 있다.",
        "shortcut": 4
      },
      {
        "id": 586,
        "content": "모델 그룹은 여러 모델 버전을 포함하는 논리적 그룹을 형성하며, 각 모델 버전은 특정 모델 아티팩트와 관련된다.",
        "shortcut": 5
      },
      {
        "id": 587,
        "content": "SageMaker 처리 기능을 통해 프리프로세싱, 포스트 프로세싱, 모델 평가를 위한 작업을 쉽게 수행할 수 있다.",
        "shortcut": 10
      },
      {
        "id": 588,
        "content": "SageMaker 처리 기능은 scikit-learn과 Apache Spark를 포함하여 다양한 ML 처리 작업에 사용할 수 있다.",
        "shortcut": 15
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 115,
    "title": "6. 🛠️ SageMaker Pipelines 및 편향 감지",
    "startTime": "00:15:17.000",
    "endTime": "00:19:17.000",
    "items": [
      {
        "id": 589,
        "content": "SageMaker Pipelines는 머신러닝 파이프라인 구축을 위한 도구로, SageMaker와 직접 통합되어 있다. 이러한 통합 덕분에 파이프라인은 SageMaker 내에서 완전히 관리되며, 다른 ADUs 서비스와 상호작용할 필요가 없다.",
        "shortcut": 5
      },
      {
        "id": 590,
        "content": "이 도구는 SageMaker Studio와 통합되어 있어 사용자가 파이프라인을 추적하고 실행할 수 있으며, 데이터의 출처와 사용 내역을 분석할 수 있는 데이터 계보 추적 기능을 제공한다.",
        "shortcut": 8
      },
      {
        "id": 591,
        "content": "SageMaker Pipelines는 단계 재사용(step reuse) 기능을 통해 이전 단계의 실행 결과를 재사용할 수 있어 불필요한 계산을 줄일 수 있다.",
        "shortcut": 10
      },
      {
        "id": 592,
        "content": "SageMaker Clarify는 데이터 준비, 모델 훈련 후 및 배포된 모델에서의 편향을 감지하고, 공정성을 정량화하기 위한 편향 메트릭스를 제공한다. 이러한 데이터는 머신러닝 모델의 특정 속성을 따 올바른 AI를 위한 설명 가능성과 관련된다.",
        "shortcut": 18
      },
      {
        "id": 593,
        "content": "다양한 용어로 구성된 SageMaker Clarify의 편향 및 공정성 관련 개념을 이해하는 것이 중요하며, 샘플(sample), 데이터 세트(data set), 편향 리포트(bias report) 등의 요소가 정의된다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 116,
    "title": "7. ⚙️ 머신러닝 모델의 설명과 편향 분석",
    "startTime": "00:20:01.000",
    "endTime": "00:22:01.000",
    "items": [
      {
        "id": 594,
        "content": "Facet는 편향이 측정되는 특성과 관련된 속성을 포함하는 열 또는 특성이다.",
        "shortcut": 1
      },
      {
        "id": 595,
        "content": "SHAP 알고리즘은 기계 학습 모델의 출력을 설명하기 위한 게임 이론적 접근이다.",
        "shortcut": 8
      },
      {
        "id": 596,
        "content": "SageMaker Clarify는 입력 특성이 최종 결정에 기여하는 바를 설명하기 위해 SHAP을 사용한다.",
        "shortcut": 10
      },
      {
        "id": 597,
        "content": "SageMaker 모델 카드는 머신러닝 모델을 관리하고 통제하기 위한 문서화 프레임워크로, 모델 세부정보와 **성능 평가**등을 기록한다.",
        "shortcut": 19
      },
      {
        "id": 598,
        "content": "SageMaker에서 훈련된 모델은 자동으로 모델 카드를 채울 수 있으며, 다양한 상태를 생성할 수 있는 버전 관리가 가능하다.",
        "shortcut": 20
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 117,
    "title": "8. 💻 Whisper Small 모델의 실행 요구 사항 및 성능 비교",
    "startTime": "00:22:30.000",
    "endTime": "00:25:30.000",
    "items": [
      {
        "id": 599,
        "content": "Jumpstart는 Hugging Face 플랫폼에서 모델을 빠르게 작업할 수 있는 방법을 제공한다.",
        "shortcut": 2
      },
      {
        "id": 600,
        "content": "Whisper Small 모델을 실행하기 위해 필요한 시스템 요구 사항을 확인하기 위해 ChatGPT에 질문하려고 한다.",
        "shortcut": 11
      },
      {
        "id": 601,
        "content": "Whisper Small 모델은 ML G4N X Large를 추천받았으나, 이는 \"작다\"고 보기 어려운 사양이다.",
        "shortcut": 18
      },
      {
        "id": 602,
        "content": "Whisper Small을 사용하기 위한 Nvidia T4 GPU 및 16GB 메모리의 비용은 시간당 거의 1달러로 나타났다.",
        "shortcut": 22
      },
      {
        "id": 603,
        "content": "개인적으로 Mac M1에서 Whisper Small을 실행하는 것이 가능하며, GTX 3060 GPU와의 성능 차이를 궁금해하고 있다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 118,
    "title": "9. 🔍 GPU 활용 및 인스턴스 선택 과정",
    "startTime": "00:26:19.000",
    "endTime": "00:30:19.000",
    "items": [
      {
        "id": 604,
        "content": "그래픽 카드가 Tesla T4보다 성능이 더 좋은 것으로 보이지만, 이 관련 정보에 대한 이해도가 부족한 상황이다.",
        "shortcut": 3
      },
      {
        "id": 605,
        "content": "GPU 활용 여부를 확인하기 위해서는 일반적으로 플래그를 제공해야 하지만, 현재 어떤 정보도 제공되지 않고 있다.",
        "shortcut": 4
      },
      {
        "id": 606,
        "content": "인스턴스 시작 후 크기를 선택할 수 없다는 점에 혼란을 느끼고 있으며, 예전과 다르게 작동함을 언급하고 있다.",
        "shortcut": 14
      },
      {
        "id": 607,
        "content": "AWS의 인스턴스 선택 과정에서 GPU 최적화 인스턴스를 찾고 있으나, 원하는 인스턴스를 찾는 데 어려움을 겪고 있다.",
        "shortcut": 22
      },
      {
        "id": 608,
        "content": "인스턴스 목록을 검토하면서 여러 가지 옵션을 확인하고 있으나, 특정 G5 X large 인스턴스와 관련하여 불일치 문제도 겪고 있다.",
        "shortcut": 27
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 119,
    "title": "10. 🖥️ 모델 배포 및 환경 설정 과정",
    "startTime": "00:30:49.000",
    "endTime": "00:34:49.000",
    "items": [
      {
        "id": 609,
        "content": "CPU를 활용하는 것이 GPU 선택에 어려움을 겪는 상황에서 더 나은 선택일 수 있다.",
        "shortcut": 1
      },
      {
        "id": 610,
        "content": "모델의 크기를 확인하기 위해 파일을 찾고 있으며, 모델이 그리 크지 않은 것으로 추정된다.",
        "shortcut": 6
      },
      {
        "id": 611,
        "content": "공간을 사용한 후 설정이 유지되는지 확인하기 위해 여러 번 실험하고 있다.",
        "shortcut": 11
      },
      {
        "id": 612,
        "content": "Whisper 모델을 선택하고 배포 과정에서 예상과 다른 동작을 경험하고 있어 궁금증을 가지고 있다.",
        "shortcut": 21
      },
      {
        "id": 613,
        "content": "Jupyter Labs 환경에서 노트북을 찾는 과정에서 혼란을 겪고 있으며, 이전 인터페이스와의 차이를 느끼고 있다.",
        "shortcut": 40
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 120,
    "title": "11. 🚀 모델 배포와 데이터셋 다운로드 과정",
    "startTime": "00:34:52.000",
    "endTime": "00:38:52.000",
    "items": [
      {
        "id": 614,
        "content": "사용자는 모델을 와일드카드 식별자를 사용하여 다운로드하려고 하며, 데이터셋의 크기와 위치에 대한 불확실성이 있다.",
        "shortcut": 4
      },
      {
        "id": 615,
        "content": "Hugging Face에서 데이터셋을 다운로드하고 있으며, 이 데이터는 특정 Hugging Face 디렉토리에 저장될 가능성이 있다.",
        "shortcut": 5
      },
      {
        "id": 616,
        "content": "Jumpstart 모델을 배포하는 과정은 SageMaker를 통해 가능하며, 다른 배포 방식도 유사할 것이라고 추정된다.",
        "shortcut": 13
      },
      {
        "id": 617,
        "content": "샘플 오디오 파일은 성공적으로 전사되었고, 이를 통해 머신러닝의 흥미로운 시대에 대해 언급되었다.",
        "shortcut": 22
      },
      {
        "id": 618,
        "content": "배포 후에는 API를 사용한 **추론**과 테스트가 가능하나, 구체적인 사용 방법은 명확하지 않다.",
        "shortcut": 33
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 121,
    "title": "12. 🚀 SageMaker Studio Labs 활용하기",
    "startTime": "00:39:25.000",
    "endTime": "00:43:25.000",
    "items": [
      {
        "id": 619,
        "content": "SageMaker Studio Labs는 AWS에서 제공하는 좋은 서비스로, 사용자가 GPU와 CPU를 사용하여 작업을 시작할 수 있는 환경을 제공한다.",
        "shortcut": 6
      },
      {
        "id": 620,
        "content": "사용자는 Builder ID로 로그인하여 계정을 생성해야 하며, 이 과정은 간단하지만 즉시 이루어지지는 않는다.",
        "shortcut": 9
      },
      {
        "id": 621,
        "content": "SageMaker Studio Labs는 잘 구성된 노트북을 제공하여 사용자가 쉽게 작업을 시작할 수 있도록 도와준다.",
        "shortcut": 24
      },
      {
        "id": 622,
        "content": "두 가지 옵션인 CPU와 GPU 중 선택할 수 있으며, 프로젝트에 따라 적절한 옵션을 선택해야 한다.",
        "shortcut": 18
      },
      {
        "id": 623,
        "content": "Transformers와 같은 라이브러리를 사용할 수 있으며, Hugging Face에서 모델을 다운로드하고 사용할 수 있는 접근 방식을 제공한다.",
        "shortcut": 33
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 122,
    "title": "13. ⚙️ 다양한 모델 성능 평가 지표",
    "startTime": "00:43:57.000",
    "endTime": "00:47:57.000",
    "items": [
      {
        "id": 624,
        "content": "모델 **성능 평가** 지표는 다양한 머신러닝 모델을 평가하는 데 사용되며, 평가 방식은 수행하는 작업에 따라 다르다.",
        "shortcut": 35
      },
      {
        "id": 625,
        "content": "분류(classification) 문제의 경우 정확도(accuracy), 정밀도(precision), 재현율(recall), F1 점수(F1 score), ROC 곡선이 주요 지표로 사용된다.",
        "shortcut": 35
      },
      {
        "id": 626,
        "content": "회귀(regression) 문제에서는 MSSE와 RMSE가 사용되며, 순위(rank) 문제의 경우 통계 관련 지표가 활용된다.",
        "shortcut": 36
      },
      {
        "id": 627,
        "content": "통계적 지표로는 상관관계가 있으며, 컴퓨터 비전 관련 분야에서도 별도의 지표가 사용된다.",
        "shortcut": 38
      },
      {
        "id": 628,
        "content": "자연어 처리(NLP) 분야에서는 Perplexity, BLEU, METEOR, ROUGE 등의 기준이 적용된다.",
        "shortcut": 40
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 123,
    "title": "14. 📊 평가 지표의 분류와 혼동 행렬",
    "startTime": "00:48:27.000",
    "endTime": "00:52:27.000",
    "items": [
      {
        "id": 629,
        "content": "평가 지표는 내부 평가와 외부 평가의 두 가지 범주로 나눌 수 있으며, 내부 평가는 **ML 모델**의 내부 구조를 평가하는 데 사용되고, 외부 평가는 최종 예측을 평가하는 데 사용된다.",
        "shortcut": 1
      },
      {
        "id": 630,
        "content": "분류 지표와 자연어처리(NLP) 지표, 특히 BLEU 점수는 모델 검증에 필수적인 요소이다.",
        "shortcut": 4
      },
      {
        "id": 631,
        "content": "혼동 행렬은 모델의 예측 결과와 실제 레이블 간의 비교를 시각화하는 표이며, 이를 통해 오류를 분석하고 올바른 예측을 확인할 수 있다.",
        "shortcut": 9
      },
      {
        "id": 632,
        "content": "혼동 행렬에서 true positive, true negative, false positive, false negative와 같은 용어는 데이터를 얼마나 올바르게 예측했는지를 보여준다.",
        "shortcut": 17
      },
      {
        "id": 633,
        "content": "정확도(accuracy)와 정밀도(precision)는 평가 지표에서 자주 언급되며, 둘 다 실제값에 대한 근접성을 의미하지만, 각각 다르게 해석된다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 124,
    "title": "15. 📊 정확성과 평가 지표에 대한 설명",
    "startTime": "00:53:17.000",
    "endTime": "00:57:17.000",
    "items": [
      {
        "id": 634,
        "content": "정확성은 정확하지만 정밀하지 않다는 개념이 있으며, 이는 목표 지점에 가까운 값을 찾는 데 중점을 둔다.",
        "shortcut": 1
      },
      {
        "id": 635,
        "content": "F1 스코어는 거짓 음성과 거짓 양성이 더 중요한 경우에 사용되며, 정밀도와 재현율의 조화 평균을 통해 계산된다.",
        "shortcut": 13
      },
      {
        "id": 636,
        "content": "ROC 곡선은 최소한의 거짓 양성과 최대의 진짜 양성을 산출하며, 이를 위한 임계값을 결정하는 데 유용하다.",
        "shortcut": 19
      },
      {
        "id": 637,
        "content": "AUC는 곡선 아래 면적을 나타내며, 모델이 무작위 양성 사례를 무작위 음성 사례보다 얼마나 잘 평가하는지를 나타낸다.",
        "shortcut": 22
      },
      {
        "id": 638,
        "content": "MRR와 MAP은 각각 첫 번째 관련 항목의 위치와 모든 관련 항목의 정확도를 측정하는 데 사용되며, 이러한 측정값은 추천 시스템 같은 ML에서 중요한 역할을 한다.",
        "shortcut": 31
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 125,
    "title": "16. 📊 다양한 기계 학습 메트릭 소개",
    "startTime": "00:58:01.000",
    "endTime": "01:01:01.000",
    "items": [
      {
        "id": 639,
        "content": "PSNR(피크 신호 대 잡음 비율)은 신호의 최대 가능한 전력과 왜곡된 잡음의 전력 간의 비율을 측정한다. 이 메트릭은 디지털 이미지 또는 비디오의 품질 평가에 사용된다.",
        "shortcut": 4
      },
      {
        "id": 640,
        "content": "구조 유사성 지수(SSIM)는 두 이미지 간의 유사성을 측정하며, 이미지를 비교하는 데 중요한 역할을 한다.",
        "shortcut": 7
      },
      {
        "id": 641,
        "content": "교차 비율(Intersection over Union)은 두 개의 경계 상자 또는 마스크 간의 겹침을 측정한다.",
        "shortcut": 8
      },
      {
        "id": 642,
        "content": "Perplexity(혼란도)는 말뭉치에 나타나는 문장의 확률을 평가하는 메트릭이다. 이는 주로 자연어 처리에서 사용된다.",
        "shortcut": 12
      },
      {
        "id": 643,
        "content": "BLEU(바이링구얼 평가 기준)는 기계 번역의 품질을 평가하며, 참조 번역과의 유사성을 0에서 1 사이의 점수로 측정한다. 하지만 이 메트릭은 개별 문장 평가에는 적합하지 않다.",
        "shortcut": 18
      },
      {
        "id": 644,
        "content": "Meteor는 기계 번역에서 품질을 평가할 때 의미와 문법적 정확성을 캡처하는 데 더 효과적이며, 동의어와 변형어를 참조 단어와 매치할 수 있다.",
        "shortcut": 22
      },
      {
        "id": 645,
        "content": "Rouge는 요약본 평가에 적합한 메트릭으로, 주로 문서 요약 시스템에서 사용된다.",
        "shortcut": 27
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 126,
    "title": "17. 📝 NLTK와 BLEU 점수 활용 준비 과정",
    "startTime": "01:02:00.000",
    "endTime": "01:05:00.000",
    "items": [
      {
        "id": 646,
        "content": "이 실습에서는 NLTK를 사용하여 BLEU 점수를 계산하기 위한 간단한 예제를 진행한다.",
        "shortcut": 1
      },
      {
        "id": 647,
        "content": "NLTK는 인간 언어 데이터와 함께 작업하는 파이썬 프로그램을 구축하기 위한 주요 플랫폼이며, 50개의 말뭉치 및 어휘 자원에 대해 사용하기 쉬운 인터페이스를 제공한다.",
        "shortcut": 19
      },
      {
        "id": 648,
        "content": "실습에서는 BLEU 점수를 검사하기 위해 \"the cat is on the mat\"과 \"there is a cat on the mat\"이라는 문장을 비교할 예정이며, 두 문장을 토큰화하려 한다.",
        "shortcut": 22
      },
      {
        "id": 649,
        "content": "토큰화 과정 중 \"the resource punkt not found\"라는 오류가 발생하여 NLTK 다운로드가 필요하다는 오류 메시지를 받았다.",
        "shortcut": 24
      },
      {
        "id": 650,
        "content": "이는 NLTK 환경이 사전에 구축되어 있지 않음을 나타내며, 필요한 자원을 다운로드하여 문제를 해결할 예정이다.",
        "shortcut": 27
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 127,
    "title": "18. 📊 BLEU 점수와 n-그램 조정",
    "startTime": "01:05:01.000",
    "endTime": "01:07:01.000",
    "items": [
      {
        "id": 651,
        "content": "\"the cat sat on the mat\"와 \"the cat is on the mat\"의 후보 번역을 비교하여 BLEU 점수를 계산한 결과, 초기 점수는 0.2939이다.",
        "shortcut": 1
      },
      {
        "id": 652,
        "content": "완벽하게 일치하는 경우 점수는 1이 되며, 오버랩이 적을 경우 점수는 0.2로 추정된다.",
        "shortcut": 4
      },
      {
        "id": 653,
        "content": "점수를 조정하여 \"the cat is on the mat\"로 변경했을 때, 점수는 완벽한 값으로 나타났다.",
        "shortcut": 9
      },
      {
        "id": 654,
        "content": "BLEU 점수는 n-그램의 가중치를 조정하여 계산할 수 있으며, 기본값은 4-그램이다.",
        "shortcut": 13
      },
      {
        "id": 655,
        "content": "다른 평가 방식으로 METEOR와 ROUGE를 사용해 보자는 제안이 있었다.",
        "shortcut": 17
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 128,
    "title": "19. 📊 GAN 및 회귀 메트릭스 개요",
    "startTime": "01:07:54.000",
    "endTime": "01:10:54.000",
    "items": [
      {
        "id": 656,
        "content": "인셉션 스코어는 GAN의 생성 결과물의 현실성을 평가하는 메트릭으로, 실제 이미지와 비교는 하지 않는다.",
        "shortcut": 2
      },
      {
        "id": 657,
        "content": "프리딕트 인셉션 거리(FID)는 GAN의 생성 이미지와 실제 이미지 간의 유사성을 측정하는 또 다른 메트릭이다.",
        "shortcut": 7
      },
      {
        "id": 658,
        "content": "회귀 분석에서 평균 제곱 오차(MSE)는 회귀선과 데이터 포인트 간의 거리를 제곱하여 측정하며, 큰 오차에 더 높은 패널티를 부여한다.",
        "shortcut": 13
      },
      {
        "id": 659,
        "content": "평균 절대 오차(MAE)는 절대값의 평균을 구하여 큰 오차에 대한 패널티가 덜하고, 더 많은 긍정적인 값을 고려한다.",
        "shortcut": 18
      },
      {
        "id": 660,
        "content": "제곱 평균 오차(RMSE)는 평균 제곱 오차의 제곱근으로 모델이 종속 변수에 얼마나 잘 맞는지를 평가하며, 큰 오차에 패널티를 부여하지만 상대적으로 덜 편향적이다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 129,
    "title": "20. 🛠️ 아마존 Q 및 코드 제안 기능",
    "startTime": "01:11:48.000",
    "endTime": "01:15:48.000",
    "items": [
      {
        "id": 661,
        "content": "Amazon Q는 다수의 대형 언어 모델을 사용하는 AI 챗봇으로, 질문을 하면 ChatGPT와 같은 방식으로 응답한다. 그러나 모델의 구성에 따라 성능 차이가 크다.",
        "shortcut": 10
      },
      {
        "id": 662,
        "content": "두 가지 주요 버전이 있으며, Amazon Q Business는 회사 데이터와 시스템을 연결하고, Amazon Q Developer는 개발과 관련된 기능을 제공한다.",
        "shortcut": 17
      },
      {
        "id": 663,
        "content": "Amazon Q는 고객 지원 대체 솔루션으로도 사용되지만, 그 품질은 서비스에 따라 달라질 수 있다.",
        "shortcut": 22
      },
      {
        "id": 664,
        "content": "Amazon Code Whisperer는 코드 작성을 도와주는 실시간 코드 제안 도구로, 다양한 IDE와 통합하여 사용할 수 있다.",
        "shortcut": 26
      },
      {
        "id": 665,
        "content": "Code Whisperer는 개인 및 전문 버전으로 나뉘며, 전문용은 조직 관리 기능 및 보안 취약점 스캔 기능을 포함하지만, 현재 서비스의 품질은 만족스럽지 못하다고 여겨진다.",
        "shortcut": 28
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 130,
    "title": "21. 🛠️ Visual Studio Code에서 Code Whisperer 활용 방법",
    "startTime": "01:16:09.000",
    "endTime": "01:20:09.000",
    "items": [
      {
        "id": 666,
        "content": "Code Whisperer는 Visual Studio Code에서 사용될 것이며, 이를 통해 다양한 기능을 시연하고자 한다.",
        "shortcut": 1
      },
      {
        "id": 667,
        "content": "Open VSX Marketplace에서 사용할 수 있는지에 따라 설치 여부가 결정되며, 필요 시 CodeSpaces를 이용할 수 있다.",
        "shortcut": 4
      },
      {
        "id": 668,
        "content": "Code Whisperer와 함께 Q Plus를 조합하여 사용할 수 있으며, 두 도구의 차이점은 대화 기능과 코드 완성 기능으로 추정된다.",
        "shortcut": 13
      },
      {
        "id": 669,
        "content": "사용자가 질문을 입력하면 Code Whisperer가 해당 문제에 대한 도움을 제공하며, 예시로 Ruby를 사용한 터미널 게임 생성 요청이 있었다.",
        "shortcut": 21
      },
      {
        "id": 670,
        "content": "Bundler 파일을 생성하고 필요한 gems를 설치하는 과정이 있으나, Code Whisperer가 사용자에게 이전보다 더 직관적으로 도움을 주는 것으로 보인다.",
        "shortcut": 37
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 131,
    "title": "22. 🖥️ 코드 실행 및 문제 해결 과정",
    "startTime": "01:20:48.000",
    "endTime": "01:24:48.000",
    "items": [
      {
        "id": 671,
        "content": "코드 실행을 위해 \"bundle exec main.rb\" 또는 \"ruby main.rb\"를 입력했으나, \"set color pair undefined\"라는 오류가 발생했다.",
        "shortcut": 1
      },
      {
        "id": 672,
        "content": "\"undefined method 'set color pair'\" 에러를 해결하기 위해 \"curses\"에서 \"init pair\" 메소드를 추가하여 초기화하는 것이 필요하다.",
        "shortcut": 3
      },
      {
        "id": 673,
        "content": "프로그램의 게임 루프가 구현되지 않아, 왼쪽이나 오른쪽 키를 눌렀을 때 프로그램이 종료되는 문제가 발생했다.",
        "shortcut": 10
      },
      {
        "id": 674,
        "content": "코드 명령어를 통해 입력을 받아들이고, 특정 키(Q)를 누르면 프로그램이 닫히도록 설정할 방안을 모색하고 있다.",
        "shortcut": 16
      },
      {
        "id": 675,
        "content": "최종적으로, 게임이 반복적으로 실행되도록 하기 위해 무한 루프 구성을 고려하고 있으며, 코드의 질이 좋지 않음을 인지하고 있다.",
        "shortcut": 23
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 132,
    "title": "23. 🖥️ Q 키 입력 처리와 Curses 모듈",
    "startTime": "01:25:28.000",
    "endTime": "01:28:28.000",
    "items": [
      {
        "id": 676,
        "content": "Q 키를 눌러 프로그램을 종료하려고 했지만, 초기화되지 않은 변수가 있어 혼란스러웠다.",
        "shortcut": 1
      },
      {
        "id": 677,
        "content": "Curses 모드에서 키 입력을 확인하는 방법을 찾고 있으며, Q 키를 확인하기 위한 get 함수가 필요할 것으로 보인다.",
        "shortcut": 5
      },
      {
        "id": 678,
        "content": "Q 키에 해당하는 상수를 정의하고, 이를 통해 프로그램을 종료하는 방법이 추가로 고려되고 있다.",
        "shortcut": 11
      },
      {
        "id": 679,
        "content": "Q 키와 대문자 Q 입력 모두 정상적으로 작동하지 않아, 해당 키의 실제 값을 알아내는 것이 필요하다고 판단되었다.",
        "shortcut": 25
      },
      {
        "id": 680,
        "content": "입력 키를 출력하기 위한 인터폴레이션 방법을 사용하려고 하고 있지만, 작동하지 않고 있어 원인을 찾기 위한 추가 검사 작업이 진행 중이다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 133,
    "title": "24. 🎮 터미널 게임 디버깅 과정",
    "startTime": "01:29:27.000",
    "endTime": "01:32:27.000",
    "items": [
      {
        "id": 681,
        "content": "사용자는 Code Whisper를 이용해 코드를 작성하려 하지만, 큰 기능을 작성하지 않기 때문에 도움이 되지 않는다고 언급한다.",
        "shortcut": 7
      },
      {
        "id": 682,
        "content": "화면이 제대로 지워지지 않고 입력한 문자가 출력되는 문제를 겪고 있으며, 이를 해결하기 위해 curses 라이브러리의 설정을 조정하려고 한다.",
        "shortcut": 32
      },
      {
        "id": 683,
        "content": "사용자는 여러 번 입력을 시도하지만, 원하는 대로 작동하지 않으며, 코드가 루프에 포함되지 않았기 때문에 문제가 발생할 것으로 보인다.",
        "shortcut": 29
      },
      {
        "id": 684,
        "content": "설정 변경을 통해 입력된 문자가 출력되지 않도록 하려지만, 결과적으로 여전히 원하는 동작이 이루어지지 않고 있다고 언급한다.",
        "shortcut": 31
      },
      {
        "id": 685,
        "content": "사용자는 최종적으로 게임에서 탈출하기 위해 Q 키를 눌러 종료를 시도하며, 게임의 결과가 긍정적이지 않음을 확인한다.",
        "shortcut": 42
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 134,
    "title": "25. 🖥️ Code Whisperer 경험과 CodeGuru 개요",
    "startTime": "01:33:25.000",
    "endTime": "01:36:25.000",
    "items": [
      {
        "id": 686,
        "content": "Code Whisperer는 코드 작성을 도와주는 도구이지만, 무료 버전을 사용시키면서 여러 문제점이 발생했으며, 이러한 경험에 대한 불만이 있다.",
        "shortcut": 16
      },
      {
        "id": 687,
        "content": "이 도구는 간단한 블랙잭 게임을 위한 코드 작성을 시도했으나, 초기에는 아무런 결과를 생성하지 못했다.",
        "shortcut": 4
      },
      {
        "id": 688,
        "content": "Code Whisperer는 무료로 사용할 수 있지만, 사용자는 결과에 만족하지 못할 수도 있으며, 다른 유사한 도구와 비교했을 때 더 나은 경험을 요구할 수 있다.",
        "shortcut": 21
      },
      {
        "id": 689,
        "content": "Amazon CodeGuru는 머신러닝 기반 코드 분석 서비스로, 코드 리뷰 및 품질 개선을 위한 변경 제안을 한다.",
        "shortcut": 31
      },
      {
        "id": 690,
        "content": "CodeGuru는 Java, JavaScript, Python, C, TypeScript, Ruby, Go 등의 언어를 지원하지만, 실제로는 Python과 Java에서 더 잘 작동한다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 135,
    "title": "26. 🖥️ Amazon CodeGuru 개요 및 분석 기능",
    "startTime": "01:37:11.000",
    "endTime": "01:41:11.000",
    "items": [
      {
        "id": 691,
        "content": "Amazon CodeGuru는 다양한 프로그래밍 언어를 지원하며, 초기에는 Java만 지원했으나 이제는 JavaScript, TypeScript, Python, Ruby로 확대되었다.",
        "shortcut": 2
      },
      {
        "id": 692,
        "content": "CodeGuru는 세 가지 서비스로 나뉘어 있으며, 그 중에서도 보안 서비스는 아직 미리보기 상태로 제공되고 있다.",
        "shortcut": 5
      },
      {
        "id": 693,
        "content": "사용자는 여러 레포지토리와 연결하여 CodeGuru의 리뷰어 기능을 활용할 수 있으며, 지원되는 레포지토리로는 CodeCommit, Bitbucket, GitHub 등이 있다.",
        "shortcut": 11
      },
      {
        "id": 694,
        "content": "분석 결과로는 총 39개의 추천 사항이 있으며, 사용자가 확인한 특정 코드 줄에 대해서 하드코딩된 파라미터가 사용되었다는 지적이 있다.",
        "shortcut": 32
      },
      {
        "id": 695,
        "content": "CodeGuru는 CI/CD 워크플로우에 통합할 수 있지만, 매번 푸시할 때마다 새로운 추천이 생성되는 방식은 사용자가 원하지 않을 수도 있다.",
        "shortcut": 39
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 136,
    "title": "27. 🛠️ 프로파일링 그룹 생성 및 보안 옵션 탐색",
    "startTime": "01:41:42.000",
    "endTime": "01:42:42.000",
    "items": [
      {
        "id": 696,
        "content": "프로파일링 그룹은 주로 마이크로서비스의 프로파일 구성 및 핫스팟을 찾기 위한 도구이다.",
        "shortcut": 2
      },
      {
        "id": 697,
        "content": "AWS Lambda 외의 다른 컴퓨팅 플랫폼에서 실행되는 애플리케이션과 관련이 있으며, 현재 작동 중인 애플리케이션이 없다고 언급한다.",
        "shortcut": 7
      },
      {
        "id": 698,
        "content": "Curator는 JVM 및 Python 애플리케이션에 사용할 수 있으나, 해당 사용자는 이 두 언어가 아닌 다른 언어를 사용하는 것으로 보인다.",
        "shortcut": 9
      },
      {
        "id": 699,
        "content": "프로파일러를 구성하여 해당 머신에서 자동으로 분석할 수 있는 가능성이 있지만, 현재 사용자의 필요에 맞지 않다고 판단된다.",
        "shortcut": 11
      },
      {
        "id": 700,
        "content": "보안 옵션을 점검하기 위해 모델과 아키텍처를 설정하고, CloudFormation **템플릿**을 열어 연결 작업을 진행할 예정이다.",
        "shortcut": 15
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 137,
    "title": "28. 🔧 GitHub 및 CodeDeploy 연결 관리",
    "startTime": "01:43:38.000",
    "endTime": "01:44:38.000",
    "items": [
      {
        "id": 701,
        "content": "OIDC 공급자는 일반적으로 CodeDeploy에 있으며, 롤 생성에는 시간이 소요된다.",
        "shortcut": 3
      },
      {
        "id": 702,
        "content": "연결을 찾기 위해 CodeDeploy로 이동했지만, 예상치 못한 문제가 있어 연결이 보이지 않는다.",
        "shortcut": 7
      },
      {
        "id": 703,
        "content": "GitHub와의 연결 수립을 위해 커스텀 워크플로우를 생성해야 한다.",
        "shortcut": 13
      },
      {
        "id": 704,
        "content": "코드 저장소에서 직접적인 코드를 다루지 않아도 리뷰어의 피드백은 유익하다고 언급한다.",
        "shortcut": 16
      },
      {
        "id": 705,
        "content": "최종적으로 코드 저장소를 삭제하고 연결을 해제할 것이다.",
        "shortcut": 20
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 138,
    "title": "29. 🛠️ Amazon Comprehend 개요",
    "startTime": "01:45:15.000",
    "endTime": "01:48:15.000",
    "items": [
      {
        "id": 706,
        "content": "Amazon Comprehend는 자연어 처리(NLP) 서비스로, 텍스트 간의 관계를 찾고 인사이트를 생산한다.",
        "shortcut": 2
      },
      {
        "id": 707,
        "content": "이 서비스는 고객 이메일, 지원 티켓, 소셜 미디어 데이터를 분석하여 예측을 수행할 수 있다.",
        "shortcut": 4
      },
      {
        "id": 708,
        "content": "사전 정의된 모델로는 엔터티, 주요 구문, 언어, 개인 식별 정보, 감정, 구문 등이 있으며, 사용자가 원하는 대로 맞춤형 예측도 가능하다.",
        "shortcut": 7
      },
      {
        "id": 709,
        "content": "Amazon Comprehend는 서버리스 모델로, 요청 크기에 따라 요금을 지불하고, 100자에 해당하는 1 단위로 측정된다.",
        "shortcut": 8
      },
      {
        "id": 710,
        "content": "이 서비스는 실시간 분석과 **배치 작업**을 지원하며, 사용자 정의 모델로도 분석을 수행할 수 있다.",
        "shortcut": 11
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 139,
    "title": "30. 🛠️ 코드 작성을 통한 감정 분석 수행",
    "startTime": "01:49:11.000",
    "endTime": "01:53:11.000",
    "items": [
      {
        "id": 711,
        "content": "Ruby를 사용하여 Comprehend 폴더를 생성하고 `main.rb`라는 새 파일을 만든다.",
        "shortcut": 1
      },
      {
        "id": 712,
        "content": "Bundler를 사용해 필수 라이브러리를 설치하기 위해 `bundle init`과 `bundle install` 명령어를 실행한다.",
        "shortcut": 8
      },
      {
        "id": 713,
        "content": "감정 분석을 수행하기 위해 \"Hello, world.\"라는 텍스트를 사용하고, `detect sentiment` 메소드를 호출하여 감정을 분석한다.",
        "shortcut": 18
      },
      {
        "id": 714,
        "content": "분석 결과가 중립적으로 나왔다가, 텍스트를 변경하여 부정적으로 평가됨을 확인한다.",
        "shortcut": 25
      },
      {
        "id": 715,
        "content": "Comprehend의 다른 기능으로는 언어 감지, 개체 감지, 구문 분석 등이 있으며, 사용법이 매우 간단하다고 언급한다.",
        "shortcut": 38
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 140,
    "title": "31. 🔍 Amazon Fraud Detector 개요",
    "startTime": "01:54:05.000",
    "endTime": "01:57:05.000",
    "items": [
      {
        "id": 716,
        "content": "Amazon Fraud Detector는 완전 관리형 서비스로 온라인에서의 사기 활동을 식별할 수 있다.",
        "shortcut": 4
      },
      {
        "id": 717,
        "content": "사기 탐지를 위한 여러 디자인된 모델이 있으며, 그 중 Online Fraud Insight는 적은 역사적 데이터로도 사기를 감지할 수 있도록 최적화되어 있다.",
        "shortcut": 6
      },
      {
        "id": 718,
        "content": "통합된 시스템을 구축하기 위해 SDK를 활용하여 실시간 사기 탐지 시스템을 만들 수 있다.",
        "shortcut": 9
      },
      {
        "id": 719,
        "content": "AI 서비스는 통합 방식에 중점을 두며, AWS의 여러 서비스(Lambda, Kinesis 등)와 연계해 사용할 수 있다.",
        "shortcut": 11
      },
      {
        "id": 720,
        "content": "사기 탐지 모델을 생성하기 위해서는 이벤트를 정의하고, 각각의 이벤트에는 라벨과 변수가 필요하다.",
        "shortcut": 25
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 141,
    "title": "32. 🤖 Kendra 개요 및 특성",
    "startTime": "01:58:02.000",
    "endTime": "02:02:02.000",
    "items": [
      {
        "id": 721,
        "content": "Kendra는 Amazon Lex 챗봇과 통합하여 사용할 수 있으며, 검색 엔진으로 자연어를 통한 검색을 가능하게 한다.",
        "shortcut": 1
      },
      {
        "id": 722,
        "content": "Kendra는 인덱스, 데이터 소스, 데이터 소스 **템플릿**, 스키마, 문서 편집 API의 구성 요소를 가지며, 다양한 데이터 소스 커넥터와 연결할 수 있다.",
        "shortcut": 2
      },
      {
        "id": 723,
        "content": "Kendra에서 결과는 주로 문서 형식(예: PDF, ePub, Word doc)으로 반환되며, 이는 예측보다 제한적일 수 있다.",
        "shortcut": 4
      },
      {
        "id": 724,
        "content": "Kendra는 개발자 및 엔터프라이즈 두 가지 버전을 제공하며, 개발자 버전은 5개 인덱스와 5개 데이터 소스를 지원하고, 무료 티어로 첫 30일 동안 750시간을 제공한다.",
        "shortcut": 11
      },
      {
        "id": 725,
        "content": "개발자 버전은 1개의 가용 영역(AZ)에서 운영되며, 엔터프라이즈 버전은 3개 AZ에서 운영된다.",
        "shortcut": 15
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 142,
    "title": "33. 📊 Kendra 역할 및 정책 설정",
    "startTime": "02:02:18.000",
    "endTime": "02:05:18.000",
    "items": [
      {
        "id": 726,
        "content": "Kendra 역할을 설정하기 위해 AR 역할이 필요하며, 정책을 통해 Kendra가 다양한 AWS 리소스에 접근할 수 있도록 해야 한다.",
        "shortcut": 2
      },
      {
        "id": 727,
        "content": "인덱스 데이터 소스를 생성할 때 Kendra가 접근해야 할 자원이 있으며, CloudWatch 로그와 함께 S3 버킷과 같은 데이터 소스에 대한 접근도 필요로 한다.",
        "shortcut": 10
      },
      {
        "id": 728,
        "content": "Kendra의 인덱스 정책은 사용자 계정 ID에 맞게 조정해야 하며, 정책 생성을 위해 콘솔을 사용하는 것이 더 편리하다고 언급된다.",
        "shortcut": 20
      },
      {
        "id": 729,
        "content": "정책을 정의하기 위해 JSON 형식으로 내용을 복사하고 붙여넣는 과정이 포함되며, 이를 통해 Kendra 인덱스 정책을 작성한다.",
        "shortcut": 27
      },
      {
        "id": 730,
        "content": "서비스 주체 이름을 알지 못하는 상황에서, 커스텀 신뢰 정책을 작성하여 Kendra 역할을 추가해야 할 수도 있다.",
        "shortcut": 31
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 143,
    "title": "34. 🗂️ 인덱스 생성과 삭제 과정의 어려움",
    "startTime": "02:05:59.000",
    "endTime": "02:09:59.000",
    "items": [
      {
        "id": 731,
        "content": "사용자는 간편한 편집기로부터 원하는 정보를 얻지 못해 좌절감을 느끼고 있다.",
        "shortcut": 1
      },
      {
        "id": 732,
        "content": "기존 조건에 있는 정책을 바탕으로 인덱스를 생성하려고 하지만, 몇 가지 잘못된 설정을 조정해야 함을 인지하고 있다.",
        "shortcut": 2
      },
      {
        "id": 733,
        "content": "AWS의 기본 설정이 Enterprise로 지정된 것에 대한 불만을 제기하며, 이로 인해 추가 비용이 발생할 것이라고 우려하고 있다.",
        "shortcut": 15
      },
      {
        "id": 734,
        "content": "생성 과정에서 삭제하기 어려운 인덱스가 생성되고 있으며, 문제가 발생하고 있는 상황에 대한 불만을 토로하고 있다.",
        "shortcut": 11
      },
      {
        "id": 735,
        "content": "사용자는 인덱스를 삭제하려고 하지만 불필요한 제약이 있다는 점에 헷갈리면서도 결국 정확한 인덱스를 삭제하려는 과정을 반복하고 있다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 144,
    "title": "35. 🗄️ 데이터 소스 생성 과정",
    "startTime": "02:10:37.000",
    "endTime": "02:14:37.000",
    "items": [
      {
        "id": 736,
        "content": "데이터 소스를 추가하기 위해 해당 메뉴를 클릭하여 예시를 확인한다.",
        "shortcut": 2
      },
      {
        "id": 737,
        "content": "인덱스 생성을 위한 데이터 소스가 필요하며, 이는 Kendra와 관련되어 있다.",
        "shortcut": 3
      },
      {
        "id": 738,
        "content": "S3 유형의 데이터를 소스 인덱스 ID로 생성하기 위해 구성 정보를 입력해야 한다.",
        "shortcut": 5
      },
      {
        "id": 739,
        "content": "S3 버킷 이름을 설정하고 지역을 US East 1으로 지정하였고, 아직 해당 버킷에 데이터는 없다.",
        "shortcut": 7
      },
      {
        "id": 740,
        "content": "Kendra는 S3와 상호작용하기 위해 버킷 정책 대신 IAM 역할을 사용한다.",
        "shortcut": 20
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 145,
    "title": "36. 🛠️ 데이터 소스 및 정책 설정 과정",
    "startTime": "02:15:05.000",
    "endTime": "02:18:05.000",
    "items": [
      {
        "id": 741,
        "content": "Kendra 데이터 소스를 생성하고 ARN을 확인한 뒤, 이를 데이터 정책에 붙여넣는다.",
        "shortcut": 2
      },
      {
        "id": 742,
        "content": "버킷 이름을 확인하고 임시로 사용하는 바구니에 이름을 입력한다.",
        "shortcut": 5
      },
      {
        "id": 743,
        "content": "지역을 US East 1으로 설정하고, 이를 시스템에 입력하려 시도하지만 오류가 발생한다.",
        "shortcut": 8
      },
      {
        "id": 744,
        "content": "정책의 문법에 문제가 있을 수 있으니, 짧은 문법으로 변경하려고 하며 이로 인해 문제 해결을 시도한다.",
        "shortcut": 15
      },
      {
        "id": 745,
        "content": "복잡한 문법 오류를 해결하기 위해 Chat GPT를 이용해 JSON 구성의 문법 수정을 요청한다.",
        "shortcut": 29
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 146,
    "title": "37. 📊 데이터 소스 생성 및 동기화 과정",
    "startTime": "02:18:56.000",
    "endTime": "02:22:56.000",
    "items": [
      {
        "id": 746,
        "content": "데이터 소스가 생성되었으나, 데이터가 아직 동기화되지 않은 상태이다.",
        "shortcut": 1
      },
      {
        "id": 747,
        "content": "Kendra의 작동을 위해 필요한 데이터 형식이 JSON, HTML, XML, CSV 등 여러 형식을 지원할 수 있음을 확인했다.",
        "shortcut": 3
      },
      {
        "id": 748,
        "content": "적절한 데이터를 확보하기 위해 다운로드 가능한 PDF 파일을 찾아야 한다고 언급하고 있으며.",
        "shortcut": 8
      },
      {
        "id": 749,
        "content": "찾고 있는 파일이 텍스트가 아닌 스캔된 형태일 경우 사용할 수 없음을 지적하고 있다.",
        "shortcut": 16
      },
      {
        "id": 750,
        "content": "Kendra의 데이터 소스 동기화를 시작하기 위해 데이터 소스 ID와 인덱스 ID를 입력해야 하며, 동기화 작업에서 오류가 발생하는 문제를 겪고 있다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 147,
    "title": "38. 📊 데이터 동기화 및 쿼리 실행 과정",
    "startTime": "02:23:35.000",
    "endTime": "02:26:35.000",
    "items": [
      {
        "id": 751,
        "content": "데이터가 동기화되는 과정에 있으며, 이는 완료될 때까지 기다려야 한다.",
        "shortcut": 1
      },
      {
        "id": 752,
        "content": "데이터 소스가 준비되었으므로, 쿼리를 실행하여 정보를 확인할 예정이다.",
        "shortcut": 4
      },
      {
        "id": 753,
        "content": "\"Oliver Twist\"의 등장 인물에 대한 질문을 하여 쿼리 결과를 확인해볼 예정이다.",
        "shortcut": 12
      },
      {
        "id": 754,
        "content": "Kendra의 기능에 대한 이해가 필요하며, 여러 문서가 있을 때 특정 문서를 찾도록 설계된 것으로 보인다.",
        "shortcut": 21
      },
      {
        "id": 755,
        "content": "문서의 페이지를 분할하는 방법을 프로그램적으로 확인해볼 예정이다.",
        "shortcut": 23
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 148,
    "title": "39. 📂 파일 분할 및 동기화 과정",
    "startTime": "02:26:48.000",
    "endTime": "02:30:48.000",
    "items": [
      {
        "id": 756,
        "content": "734페이지 이상의 파일을 10페이지씩 분할하여 작업하기로 결정하였다.",
        "shortcut": 1
      },
      {
        "id": 757,
        "content": "새로운 폴더인 \"split\"을 생성한 뒤, 필요한 파일을 동기화하기 위해 관련 명령어를 사용하였다.",
        "shortcut": 6
      },
      {
        "id": 758,
        "content": "Kendra 데이터 소스에 관련된 파일을 삭제한 후, 파일을 다시 동기화하여 필요한 정보를 최신 상태로 유지하고자 하였다.",
        "shortcut": 14
      },
      {
        "id": 759,
        "content": "마지막 동기화가 실패했음을 발견하고, 문제를 해결하기 위해 IAM 설정을 확인하여 권한이 충분하지 않음을 알게 되었다.",
        "shortcut": 29
      },
      {
        "id": 760,
        "content": "Kendra의 인덱스 ID를 추가하여 다시 동기화를 시도함으로써 문제를 해결할 예정이다.",
        "shortcut": 45
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 149,
    "title": "40. ⏳ 데이터 동기화 및 정리 과정",
    "startTime": "02:31:19.000",
    "endTime": "02:33:19.000",
    "items": [
      {
        "id": 761,
        "content": "명령어를 다시 실행하기 전에 30초의 대기 시간을 두고, 데이터가 전파되는 시간을 기다린다.",
        "shortcut": 2
      },
      {
        "id": 762,
        "content": "데이터 소스를 업데이트하고, Kendra로 이동하여 데이터 동기화를 진행한다.",
        "shortcut": 4
      },
      {
        "id": 763,
        "content": "데이터가 빠르게 동기화되었으며, 쿼리를 실행하여 결과를 확인한다.",
        "shortcut": 7
      },
      {
        "id": 764,
        "content": "반환된 텍스트는 관련 문서에서 발췌한 내용이며, 맞는 문서 번호를 표시한다.",
        "shortcut": 11
      },
      {
        "id": 765,
        "content": "데이터 소스를 삭제하고, S3 버킷을 정리하는 청소 작업을 진행한다.",
        "shortcut": 21
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 150,
    "title": "41. 📊 데이터 삭제와 Amazon Lex 소개",
    "startTime": "02:33:42.000",
    "endTime": "02:34:42.000",
    "items": [
      {
        "id": 766,
        "content": "데이터 소스가 삭제되지 않으면 인덱스를 삭제할 수 없으므로, 현재 데이터 소스의 삭제를 기다리고 있다는 내용이다.",
        "shortcut": 1
      },
      {
        "id": 767,
        "content": "데이터 소스를 삭제하는 데 오랜 시간이 걸리며, 현재 10분 이상 대기 중임을 언급하고 있다.",
        "shortcut": 4
      },
      {
        "id": 768,
        "content": "데이터 소스가 삭제되었으니 인덱스를 삭제할 준비가 되었음을 확인하고 있다.",
        "shortcut": 7
      },
      {
        "id": 769,
        "content": "Amazon Lex는 음성 및 텍스트 챗봇을 구축할 수 있는 대화형 인터페이스 서비스이다.",
        "shortcut": 9
      },
      {
        "id": 770,
        "content": "Lex는 자연어 이해와 자동 음성 인식 기능을 제공하며, 여러 산업에 대한 봇 **템플릿**을 제공하고 시작점으로 삼을 수 있다.",
        "shortcut": 13
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 151,
    "title": "42. 🤖 Amazon Lex와 AWS 서비스 통합",
    "startTime": "02:35:35.000",
    "endTime": "02:36:35.000",
    "items": [
      {
        "id": 771,
        "content": "Amazon Lex는 AWS Lambda와 통합되어 다양한 AWS 서비스와 연결할 수 있는 기능을 제공한다.",
        "shortcut": 1
      },
      {
        "id": 772,
        "content": "애플리케이션 통합 서비스로는 Step Functions, Kinesis Data Firehose, SQS, SNS 등이 있으며, 이를 통해 다른 서비스와 통합된다.",
        "shortcut": 3
      },
      {
        "id": 773,
        "content": "Amazon Lex의 네트워크 봇 기능은 여러 개의 봇을 하나의 네트워크에 추가하여 쿼리를 적절한 봇으로 지능적으로 라우팅한다.",
        "shortcut": 4
      },
      {
        "id": 774,
        "content": "봇은 사용자가 상호작용하는 **자동화**된 작업을 수행하며, 각각의 봇 모델은 버전을 가지고 있다.",
        "shortcut": 8
      },
      {
        "id": 775,
        "content": "봇의 의도는 수행하려는 행동을 나타내며, 슬롯은 사용자의 입력으로 필요로 하는 정보를 의미한다.",
        "shortcut": 12
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 152,
    "title": "43. 🚀 Amazon Personalize 구성 요소 및 데이터 세트",
    "startTime": "02:36:59.000",
    "endTime": "02:40:59.000",
    "items": [
      {
        "id": 776,
        "content": "Amazon Personalize는 실시간 추천 서비스로, Amazon 플랫폼에서 제품 추천에 사용되는 기술이다.",
        "shortcut": 4
      },
      {
        "id": 777,
        "content": "데이터 세트 그룹을 생성한 후, 세 가지 데이터 세트(사용자-항목 상호작용 데이터, 사용자 데이터, 항목 데이터)를 생성해야 하며, 사용자-항목 상호작용 데이터는 필수이다.",
        "shortcut": 6
      },
      {
        "id": 778,
        "content": "데이터는 CSV 형식의 파일로 S3에 저장하고, JSON 스키마 매핑을 제공해야 한다.",
        "shortcut": 9
      },
      {
        "id": 779,
        "content": "추천 생성을 위한 솔루션과 미리 정의된 레시피를 설정해야 하며, 레시피는 추천 알고리즘의 역할을 한다.",
        "shortcut": 11
      },
      {
        "id": 780,
        "content": "사용자-항목 상호작용 데이터는 사용자 ID와 항목 ID, 타임스탬프가 필수이며, 타임스탬프는 Unix 형식이어야 한다.",
        "shortcut": 16
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 153,
    "title": "44. 📊 CSV 파일 생성 및 데이터 확인",
    "startTime": "02:41:07.000",
    "endTime": "02:44:07.000",
    "items": [
      {
        "id": 781,
        "content": "사용자 ID, 아이템 ID, 타임스탬프가 필요한데, 현재 CSV 파일에는 아이템 ID와 타임스탬프가 없어서 데이터가 유용하지 않다고 판단된다.",
        "shortcut": 1
      },
      {
        "id": 782,
        "content": "사용자 데이터에는 사용자 ID, 나이, 성별 정보가 포함되어 있어 일부분은 유용하다고 설명한다.",
        "shortcut": 9
      },
      {
        "id": 783,
        "content": "사용자 아이템 상호작용 데이터 CSV 파일을 생성할 때, 이전에 생성한 사용자 데이터 CSV 파일을 참조해야 한다.",
        "shortcut": 12
      },
      {
        "id": 784,
        "content": "타임스탬프 생성에 오류가 있어서 데이터 프레임의 배열 크기가 일치하지 않는 문제를 발견하고 수정할 예정이다.",
        "shortcut": 27
      },
      {
        "id": 785,
        "content": "Unix 타임스탬프 형식이 사용되어야 하며, 이를 확인하기 위해 데이터를 다시 검토하고 수정할 계획이다.",
        "shortcut": 34
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 154,
    "title": "45. 📊 데이터 처리 및 생성 과정",
    "startTime": "02:44:59.000",
    "endTime": "02:48:59.000",
    "items": [
      {
        "id": 786,
        "content": "사용자 아이템 상호작용 데이터가 두 개의 데이터 세트 사이에 위치하여 순서를 바꿔 작업하는 것이 비효율적이라는 점을 언급했다.",
        "shortcut": 1
      },
      {
        "id": 787,
        "content": "아이템 데이터 CSV 세트를 생성할 때 다른 두 데이터 세트를 참조해야 하며, 이 과정에서 데이터의 정확성을 강조했다.",
        "shortcut": 5
      },
      {
        "id": 788,
        "content": "아이템 데이터가 단순히 카테고리로만 표시되어 유용하지 않다고 평가하며, 다시 시도할 것을 요청했다.",
        "shortcut": 16
      },
      {
        "id": 789,
        "content": "데이터 업데이트 후, 이전 데이터보다 훨씬 유용한 '노트북, 보드게임' 항목들이 포함되어 있었음을 확인했다.",
        "shortcut": 22
      },
      {
        "id": 790,
        "content": "Unix 코드 때문에 데이터 다운로드 시 문제가 발생할 수 있다고 우려하며 각 데이터 파일을 개별적으로 생성하기로 했다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 155,
    "title": "46. 🗂️ 데이터 가져오기와 스키마 수정 과정",
    "startTime": "02:49:02.000",
    "endTime": "02:52:02.000",
    "items": [
      {
        "id": 791,
        "content": "데이터 가져오기를 위해 Amazon으로 직접 아이템 데이터를 가져오고, 기존 스키마를 수정하여 새로운 도메인 스키마를 생성하고 있다.",
        "shortcut": 1
      },
      {
        "id": 792,
        "content": "아이템 데이터에 필요한 스키마 JSON을 요청하지만, 어떤 필드가 필수인지 불확실하다.",
        "shortcut": 5
      },
      {
        "id": 793,
        "content": "스키마에 카테고리 L1이 필요한데, 이는 레벨 1 카테고리를 나타내며, 데이터 구조에 대한 약간의 조정이 필요함을 의미한다.",
        "shortcut": 20
      },
      {
        "id": 794,
        "content": "데이터가 정확한지를 확인하기 위해 로컬 파일을 삭제하고 다시 다운로드하는 과정을 진행하고 있다.",
        "shortcut": 33
      },
      {
        "id": 795,
        "content": "S3 버킷을 생성하여 데이터를 올리는 과정을 준비 중이며, 지역 설정에 주의해야 함을 언급하고 있다.",
        "shortcut": 37
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 156,
    "title": "47. 📥 S3 버킷에 데이터 업로드 과정",
    "startTime": "02:52:58.000",
    "endTime": "02:56:58.000",
    "items": [
      {
        "id": 796,
        "content": "item data.csv 파일을 S3 버킷에 업로드 하고, 서비스 역할을 생성하는 과정이 진행된다.",
        "shortcut": 2
      },
      {
        "id": 797,
        "content": "권한 오류가 발생했지만, 서비스 역할을 생성했으므로 권한 설정을 확인하고 버킷 정책을 수정할 필요가 있다.",
        "shortcut": 9
      },
      {
        "id": 798,
        "content": "개인화 서비스인 personalize.amazon.com에 대한 버킷 정책을 첨부한 후, 데이터 세트가 문제 없이 가져와지는 것을 확인한다.",
        "shortcut": 20
      },
      {
        "id": 799,
        "content": "ChatDBT를 사용하여 사용자 데이터 세트의 스키마 JSON을 만드는 과정이 진행되며, 이를 통해 데이터 가져오기를 용이하게 한다.",
        "shortcut": 29
      },
      {
        "id": 800,
        "content": "사용자 데이터 파일을 개별적으로 업로드하며, 문제가 발생하지 않도록 주의하고 임포트를 진행하는 초기 단계가 있다.",
        "shortcut": 42
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 157,
    "title": "48. 📥 데이터 업로드 및 스키마 정의",
    "startTime": "02:57:49.000",
    "endTime": "02:57:49.000",
    "items": [
      {
        "id": 801,
        "content": "사용자는 아이템 데이터 상호작용을 업로드하기 위해 자신의 버킷으로 돌아간다.",
        "shortcut": 2
      },
      {
        "id": 802,
        "content": "버킷에 업로드할 데이터는 사용자 아이템 데이터 상호작용이다.",
        "shortcut": 3
      },
      {
        "id": 803,
        "content": "사용자는 해당 데이터에 대해 JSON 스키마를 작성할 것을 요청한다.",
        "shortcut": 4
      },
      {
        "id": 804,
        "content": "이 데이터는 Amazon Personalize로 가져오기 위한 사용자 상호작용 데이터 세트 파일로 불린다.",
        "shortcut": 5
      }
    ],
    "sourceIndex": 4
  },
  {
    "id": 158,
    "title": "1. 📊 데이터 임포트 및 오류 해결 과정",
    "startTime": "00:00:00.000",
    "endTime": "00:05:00.000",
    "items": [
      {
        "id": 805,
        "content": "데이터 임포트 작업에서 **사용자 ID**, 항목 ID, 타임스탬프, 이벤트 시간, 이벤트 값으로 이루어진 항목 상호작용 **데이터셋**을 설정한다.",
        "shortcut": 2
      },
      {
        "id": 806,
        "content": "타임스탬프 필드는 Unix 시간 형식으로 요구되며, 소수점이 포함될 경우 오류가 발생할 수 있는 것으로 보인다.",
        "shortcut": 25
      },
      {
        "id": 807,
        "content": "데이터를 수정하고 새 파일을 업로드하여 임포트 상태를 확인한 결과, 두 개의 작업이 활성 상태로 나타났으며 추가 진행 사항을 기다린다.",
        "shortcut": 46
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 159,
    "title": "2. 🚀 데이터 세트와 추천 시스템 설정",
    "startTime": "00:05:16.000",
    "endTime": "00:13:16.000",
    "items": [
      {
        "id": 808,
        "content": "데이터 세트가 완료되어 **추천 시스템**구성이 필요해졌다.",
        "shortcut": 1
      },
      {
        "id": 809,
        "content": "**추천 시스템**은 특정 사용 사례에 대한 추천을 제공하며, 실시간 생성이 가능하다.",
        "shortcut": 4
      },
      {
        "id": 810,
        "content": "**Amazon Personalize**에서 추천을 생성하기 전에 캠페인을 생성해야 하며, **데이터 분석**을 통해 데이터를 최적화할 필요가 있다.",
        "shortcut": 22
      },
      {
        "id": 811,
        "content": "추천기는 고객이 본 품목을 기반으로 추천을 제공하며, 다양한 기준으로 필터링할 수 있다.",
        "shortcut": 69
      },
      {
        "id": 812,
        "content": "**데이터 분석**후 10,000개 항목이 포함된 데이터 세트를 사용하며, 추천 전송 요청당 최소 하나의 추천을 수신할 수 있다.",
        "shortcut": 63
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 160,
    "title": "3. 🚀 캠페인 생성 과정",
    "startTime": "00:13:20.000",
    "endTime": "00:15:20.000",
    "items": [
      {
        "id": 813,
        "content": "**추천 시스템**을 위한 쿼리 실행이 다음 단계로 미뤄진다.",
        "shortcut": 1
      },
      {
        "id": 814,
        "content": "캠페인을 생성하기 위해서는 우선 솔루션을 선택해야 한다.",
        "shortcut": 5
      },
      {
        "id": 815,
        "content": "솔루션을 만들기 위해 \"아이템 추천\"을 선택하고, 유사 아이템 기능을 활용하는 것이 좋다.",
        "shortcut": 12
      },
      {
        "id": 816,
        "content": "**하이퍼파라미터 최적화**는 여러 반복을 통해 세분화하는 기능이나 현재는 관심이 없다.",
        "shortcut": 15
      },
      {
        "id": 817,
        "content": "솔루션 생성 후 캠페인을 만들 수 있으며, 이에 필요한 솔루션 버전이 활성화되어 있어야 한다.",
        "shortcut": 32
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 161,
    "title": "4. 🔄 코드 환경 복구 및 캠페인 삭제 과정",
    "startTime": "00:16:19.000",
    "endTime": "00:27:19.000",
    "items": [
      {
        "id": 818,
        "content": "코드 환경을 복구하기 위해 `pip install -r requirements.txt` 명령어를 사용하여 필요 라이브러리를 설치한다.",
        "shortcut": 12
      },
      {
        "id": 819,
        "content": "캠페인에 대한 user ID를 지정하기 위해 127이라는 ID를 선택하며, 이와 관련된 사용자 데이터가 충분한지 확인한다.",
        "shortcut": 17
      },
      {
        "id": 820,
        "content": "코드 실행 중 오류 메시지가 발생했으며, 이는 캠페인이 활성 상태가 아닐 때 발생하는 문제일 수 있다.",
        "shortcut": 32
      },
      {
        "id": 821,
        "content": "`CA Central 1` 지역을 설정하는 코드 변경 작업을 진행하며, 관련 설정은 Bodo 3 SDK를 통해 포함된다.",
        "shortcut": 37
      },
      {
        "id": 822,
        "content": "캠페인 삭제 과정이 지연되었으나, 결국 모든 데이터가 정리되는 상태로 마무리된다.",
        "shortcut": 138
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 162,
    "title": "4.1. 코드 환경 복구 과정",
    "startTime": "00:16:19.000",
    "endTime": "00:16:19.000",
    "items": [
      {
        "id": 823,
        "content": "코드 환경이 복원 중이라는 가정 하에 작업을 진행하고 있다.",
        "shortcut": 1
      },
      {
        "id": 824,
        "content": "개인화된 코드를 저장하고 다시 시작하여 작업하기 쉬운 상태로 만들 예정이다.",
        "shortcut": 4
      },
      {
        "id": 825,
        "content": "코드가 손실되지 않았는지 확인하고 있으며, 개인화된 코드가 존재함을 확인했다.",
        "shortcut": 6
      },
      {
        "id": 826,
        "content": "클라우드 개별 환경을 다시 시작하기 위해 해당 작업을 진행하고 있다.",
        "shortcut": 9
      },
      {
        "id": 827,
        "content": "환경이 정상적으로 작동 상태로 돌아온 것으로 보인다.",
        "shortcut": 11
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 163,
    "title": "4.2. ️ 파이썬 코드 수정 및 실행 과정",
    "startTime": "00:17:03.000",
    "endTime": "00:18:03.000",
    "items": [
      {
        "id": 828,
        "content": "최종적으로 필요한 라이브러리를 설치하기 위해 `pip install -r requirements.txt` 명령어를 사용한다.",
        "shortcut": 12
      },
      {
        "id": 829,
        "content": "코드에서 교체해야 할 사항들은 캠페인 AR 값과 사용자 ID를 포함하며, **사용자 ID**는 임의로 127을 선택한다.",
        "shortcut": 15
      },
      {
        "id": 830,
        "content": "**사용자 ID**는 문자열로 사용될 것으로 예상되며, 이를 코드에 입력한 후 실행할 준비를 한다.",
        "shortcut": 21
      },
      {
        "id": 831,
        "content": "코드의 가독성을 높이기 위해 \"client\"로 변경하며, 코드의 들여쓰기를 2로 수정한다.",
        "shortcut": 26
      },
      {
        "id": 832,
        "content": "파이썬의 권장 규칙에 따라 가독성을 개선하고, 수정된 코드를 다시 실행할 예정이다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 164,
    "title": "4.3. ️ Bodo 3에서 지역 설정 문제 해결",
    "startTime": "00:18:55.000",
    "endTime": "00:20:55.000",
    "items": [
      {
        "id": 833,
        "content": "오류 발생 시 \"캠페인이 존재하지 않거나 활성 캠페인이 아니다\"는 메시지가 나타난다.",
        "shortcut": 32
      },
      {
        "id": 834,
        "content": "코드에서 지역을 설정해야 하는 문제를 제기하며, 어떻게 이를 수행할 수 있을지 탐색 중이다.",
        "shortcut": 33
      },
      {
        "id": 835,
        "content": "Bodo 3 SDK에서 지역 설정 옵션을 찾으려 하지만, 확인되지 않았다. 따라서 클라이언트 측에서 해결할 수 있을 것으로 보인다.",
        "shortcut": 34
      },
      {
        "id": 836,
        "content": "CA Central 1에 관심을 두고 설정을 진행하며, 추가적인 구성이 필요할 것이라 예상된다.",
        "shortcut": 38
      },
      {
        "id": 837,
        "content": "캠페인이 생성 중이며, 생성 완료를 기다리는 상태로, 캠페인이 사라졌다가 다시 나타나는 불안정한 상황이 발생한다.",
        "shortcut": 48
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 165,
    "title": "4.4. ️ 캠페인 테스트 및 코드 수정",
    "startTime": "00:20:58.000",
    "endTime": "00:23:58.000",
    "items": [
      {
        "id": 838,
        "content": "캠페인을 프로그램적으로 테스트하고자 하며, 관련 아이템에는 단일 아이디가 필요하다고 주장한다.",
        "shortcut": 54
      },
      {
        "id": 839,
        "content": "**아이템 ID**를 코드 내에 위치시켜야 하며, 코드 작성을 위해 임의의 아이템을 사용한다고 한다.",
        "shortcut": 59
      },
      {
        "id": 840,
        "content": "현재의 **아이템 ID**는 유용하지 않지만, 전체 객체를 출력해볼 것이라고 언급한다.",
        "shortcut": 69
      },
      {
        "id": 841,
        "content": "데이터 포인트와 이벤트 타입이 매칭에 영향을 미치며, 더 많은 관련 데이터를 추가해야 한다고 설명한다.",
        "shortcut": 83
      },
      {
        "id": 842,
        "content": "최종적으로, 추천 엔진을 구축하기엔 많은 노력이 필요하다고 주장하고, 자신의 개인적 사용에는 부정적임을 밝힌다.",
        "shortcut": 94
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 166,
    "title": "4.5. ️ 데이터 삭제 과정",
    "startTime": "00:24:45.000",
    "endTime": "00:26:45.000",
    "items": [
      {
        "id": 843,
        "content": "**추천 시스템**의 설정을 위해 추천자를 먼저 삭제해야 한다.",
        "shortcut": 107
      },
      {
        "id": 844,
        "content": "**데이터셋**을 삭제하기 전에는 추천자를 먼저 삭제하는 절차가 필요하다.",
        "shortcut": 113
      },
      {
        "id": 845,
        "content": "추천자와 **데이터셋**삭제에 약간의 시간이 소요되며, 각 과정을 기다려야 한다.",
        "shortcut": 111
      },
      {
        "id": 846,
        "content": "추천자 및 **데이터셋**삭제가 완료되면, 데이터 정리가 끝난다.",
        "shortcut": 138
      },
      {
        "id": 847,
        "content": "최종적으로 모든 데이터가 삭제되었음을 확인하고 정리 과정을 마무리한다.",
        "shortcut": 139
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 167,
    "title": "5. 🎤 아마존 폴리의 텍스트-음성 변환 서비스",
    "startTime": "00:27:31.000",
    "endTime": "02:08:31.000",
    "items": [
      {
        "id": 848,
        "content": "아마존 폴리는 텍스트를 음성으로 변환하는 서비스로, 텍스트를 업로드하면 합성 음성으로 된 오디오 파일이 생성된다.",
        "shortcut": 1
      },
      {
        "id": 849,
        "content": "세 가지 엔티티 형태가 있으며, 표준, 롱폼, 뉴럴이 있다. 표준은 가장 자연스럽지 않지만 비용 효율적이며, 뉴럴은 가장 자연스러운 음성을 제공하지만 가격은 더 비쌌다.",
        "shortcut": 3
      },
      {
        "id": 850,
        "content": "뉴럴 음성에는 뉴스 캐스터 스타일이 추가되어 필요한 경우 지정할 수 있고, 이러한 차별화된 스타일은 **뉴럴 엔진**에서만 지원된다.",
        "shortcut": 6
      },
      {
        "id": 851,
        "content": "**SSML**(Speech Synthesis Markup Language)을 사용하여 발음 및 속도와 같은 것을 제어할 수 있다.",
        "shortcut": 21
      },
      {
        "id": 852,
        "content": "아마존 폴리는 MP3, AU, WAV와 같은 다양한 출력 형식을 지원하고, 사용자가 특정 발음을 원하는 경우 어휘 파일을 업로드하여 발음을 개선할 수 있도록 한다.",
        "shortcut": 13
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 168,
    "title": "5.1. ️ Amazon Polly 텍스트 음성 변환 서비스",
    "startTime": "00:27:31.000",
    "endTime": "00:28:31.000",
    "items": [
      {
        "id": 853,
        "content": "**Amazon Polly**는 텍스트를 업로드하면 합성 음성으로 오디오 파일을 생성하는 텍스트-투-스피치 서비스이다.",
        "shortcut": 1
      },
      {
        "id": 854,
        "content": "세 가지 Entity가 있으며, 표준, 롱폼, 뉴럴이 있다.",
        "shortcut": 2
      },
      {
        "id": 855,
        "content": "표준은 가장 자연스럽지 않지만 비용 효과적이며, 롱폼은 다소 개선된 음성을 제공하고, 뉴럴은 가장 좋은 음질을 가진다.",
        "shortcut": 3
      },
      {
        "id": 856,
        "content": "뉴럴은 뉴스 아나운서의 말투를 적용할 수 있으며, 이 기능을 사용하려면 명시적으로 요청해야 한다.",
        "shortcut": 5
      },
      {
        "id": 857,
        "content": "음성의 품질에는 변동성이 있으며, 특정 텍스트에 따라 속도가 다르게 설정된다.",
        "shortcut": 8
      },
      {
        "id": 858,
        "content": "출력을 위해 MP3 형식을 지정할 수 있으며, 다른 형식도 지원할 것으로 보인다.",
        "shortcut": 12
      },
      {
        "id": 859,
        "content": "특정 단어의 발음을 조정하기 위해 렉시콘 파일을 업로드할 수 있으며, 메타데이터인 스피치 마크스를 사용하여 발음을 세밀하게 조절할 수 있다.",
        "shortcut": 16
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 169,
    "title": "5.2. SSML과 Amazon의 태그 지원",
    "startTime": "00:28:44.000",
    "endTime": "00:29:44.000",
    "items": [
      {
        "id": 860,
        "content": "**SSML**(Speech Synthesis Markup Language)은 XML 기반의 마크업 언어로, 다양한 **음성 합성**기능을 제공한다.",
        "shortcut": 21
      },
      {
        "id": 861,
        "content": "Vimi와의 통합이 가능하지만, 특정 서드파티 서비스와의 통합 이유는 불분명하다.",
        "shortcut": 22
      },
      {
        "id": 862,
        "content": "**SSML**에서 지원하는 태그로는 speak, break, emphasis 등이 있으며, 음성 수정이나 속도 조절 등이 가능하다.",
        "shortcut": 32
      },
      {
        "id": 863,
        "content": "Amazon 관련 태그는 whispering, newscaster speaking style, dynamic range compression 등을 포함하여 고유한 음성 옵션을 추가한다.",
        "shortcut": 31
      },
      {
        "id": 864,
        "content": "태그를 통해 문장 간의 일시 정지나 특정 단어의 발음 조정이 가능하며, 크기 및 음조를 조절할 수 있다.",
        "shortcut": 36
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 170,
    "title": "5.3. 아마존 폴리 소개",
    "startTime": "00:30:24.000",
    "endTime": "00:31:24.000",
    "items": [
      {
        "id": 865,
        "content": "아마존 폴리는 텍스트를 음성으로 변환하는 도구이다.",
        "shortcut": 41
      },
      {
        "id": 866,
        "content": "시스템 사운드를 캡처하였기 때문에 사용자가 음성을 실제로 들을 수 있다.",
        "shortcut": 43
      },
      {
        "id": 867,
        "content": "다양한 목소리가 제공되며, 각각의 목소리는 옵션에 따라 다르게 변경된다.",
        "shortcut": 47
      },
      {
        "id": 868,
        "content": "'매튜'와 '그레고리'라는 두 가지 음성을 예로 들어, 음성이 얼마나 다른지 확인할 수 있다.",
        "shortcut": 45
      },
      {
        "id": 869,
        "content": "신경망 음성 모드에서는 더 자연스럽고 다양한 음성을 지원한다.",
        "shortcut": 54
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 171,
    "title": "5.4. SSML 태그와 TTS 활용 방법",
    "startTime": "00:31:38.000",
    "endTime": "00:44:38.000",
    "items": [
      {
        "id": 870,
        "content": "아마존 웹 서비스(AWS)에서 지원하는 **SSML**(Speech Synthesis Markup Language) 태그를 사용하여 **음성 합성**을 조정할 수 있다.",
        "shortcut": 59
      },
      {
        "id": 871,
        "content": "표준 **음성 합성**방식이 가장 저렴하며, 신경망 기반 **음성 합성**이 가장 비쌉니다.",
        "shortcut": 58
      },
      {
        "id": 872,
        "content": "특정 **SSML**태그는 특정 음성에서만 작동하기 때문에, 모든 음성에서 사용할 수 없음을 인지해야 한다.",
        "shortcut": 82
      },
      {
        "id": 873,
        "content": "복잡한 **SSML**구문이 유효하지 않은 경우가 있으며, 이로 인해 예상한 대로 음성이 출력되지 않을 수 있다.",
        "shortcut": 69
      },
      {
        "id": 874,
        "content": "Ruby를 활용하여 AWS Polly의 음성을 합성하고 MP3 파일로 저장하는 과정을 설명하며, 코드 작성에 있어 스스로 작성하는 것이 중요함을 강조한다.",
        "shortcut": 100
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 172,
    "title": "5.5. 아마존 레코그니션 소개",
    "startTime": "00:45:18.000",
    "endTime": "00:45:18.000",
    "items": [
      {
        "id": 875,
        "content": "아마존 레코그니션은 이미지와 비디오 인식 서비스로, 다양한 객체와 사람, 유명인사를 감지하고 레이블을 붙인다.",
        "shortcut": 194
      },
      {
        "id": 876,
        "content": "발표자는 이 슬라이드를 처음 만들 때 각 예시를 잘 보여주려고 했으나, 공동 창립자가 빈 버전을 업로드하여 작업이 사라진 상황이다.",
        "shortcut": 196
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 173,
    "title": "5.6. ️ 아마존 레코그니션 기능 소개",
    "startTime": "00:45:45.000",
    "endTime": "01:04:45.000",
    "items": [
      {
        "id": 877,
        "content": "아마존 레코그니션은 객체 탐지, 얼굴 탐지, 유명인 인식, 콘텐츠 모더레이션, 텍스트 탐지 등 다양한 사전 구축 모델을 제공한다.",
        "shortcut": 199
      },
      {
        "id": 878,
        "content": "이미지 요구 사항은 JPEG 또는 PNG 형식이며, Base64로 인코딩되어야 한다.",
        "shortcut": 200
      },
      {
        "id": 879,
        "content": "사용자 정의 레이블을 통해 사전 구축 모델을 사용하지 않고도 고유한 모델을 만들 수 있으며, 이는 더 특수한 객체 탐지에 유용하다.",
        "shortcut": 203
      },
      {
        "id": 880,
        "content": "레코그니션은 얼굴 분석 및 비교 기능을 제공하며, 이를 통해 사용자의 얼굴 특징을 분석할 수 있다.",
        "shortcut": 223
      },
      {
        "id": 881,
        "content": "아마존 레코그니션 사용 시에는 S3 버킷을 통해 파일에 접근할 수 있으며, 이때 필요한 정책 업데이트를 통해 접근 권한을 조정해야 할 수도 있다.",
        "shortcut": 202
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 174,
    "title": "5.7. Amazon Textract의 기능 및 활용",
    "startTime": "01:05:41.000",
    "endTime": "01:18:41.000",
    "items": [
      {
        "id": 882,
        "content": "Amazon Textract는 OCR(Optical Character Recognition) 서비스로, 스캔된 문서에서 텍스트를 추출하는 기능을 제공한다. 이 서비스를 통해 문서의 레이아웃을 유지하고, 데이터의 좌표를 변환하여 표 형태로 변환할 수 있다.",
        "shortcut": 397
      },
      {
        "id": 883,
        "content": "Textract는 서명 감지, 영수증, 신분증(운전 면허증, 여권) 분석을 위한 미리 정의된 모델을 포함하고 있다.",
        "shortcut": 401
      },
      {
        "id": 884,
        "content": "사용자는 자체적으로 커스텀 쿼리를 설정할 수 있으며, 업로드한 샘플로 맞춤형 모델을 훈련할 수 있는 기능을 제공한다.",
        "shortcut": 406
      },
      {
        "id": 885,
        "content": "Textract의 SEO 성능이 개선되어 다양한 사용 사례에서 유용할 것으로 예상되며, 과거에는 최적의 성능을 보이지 않았던 경험이 있다고 한다.",
        "shortcut": 415
      },
      {
        "id": 886,
        "content": "다양한 입력 문서 포맷(PNG, JPEG, PDF, TIFF)을 지원하며, 문서 분석을 통해 추출된 데이터를 프로그래밍적으로 활용할 수 있다.",
        "shortcut": 507
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 175,
    "title": "5.8. Amazon Translate 서비스 개요",
    "startTime": "01:19:10.000",
    "endTime": "01:26:10.000",
    "items": [
      {
        "id": 887,
        "content": "Amazon Translate는 신경망 기계 학습에 기반한 텍스트 번역 서비스로, 더 정확하고 자연스러운 번역을 제공한다.",
        "shortcut": 544
      },
      {
        "id": 888,
        "content": "이 서비스는 실시간과 비동기 배치 처리 두 가지 모드를 지원한다.",
        "shortcut": 546
      },
      {
        "id": 889,
        "content": "사용자는 텍스트와 언어를 입력하면 다른 언어로 번역된 결과를 받을 수 있다.",
        "shortcut": 554
      },
      {
        "id": 890,
        "content": "Ruby 프로그래밍 언어를 사용하여 Amazon Translate API를 통해 번역 기능을 구현하는 예시가 제공되며, 적절한 SDK 설치 과정이 포함된다.",
        "shortcut": 563
      },
      {
        "id": 891,
        "content": "번역의 출처 언어 코드와 목표 언어 코드 설정을 통해 다양한 번역 옵션을 제공하며, 설정에 따라 불쾌감을 주는 표현을 제거하는 기능도 있다.",
        "shortcut": 591
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 176,
    "title": "5.9. AI 관련 ISO 표준 및 법안 개요",
    "startTime": "01:27:01.000",
    "endTime": "01:34:01.000",
    "items": [
      {
        "id": 892,
        "content": "ISO 420001은 AI 관리 시스템을 설계, 구현 및 개선하기 위한 국제 표준으로, AI 기반 제품이나 서비스를 제공하는 조직에 적용된다.",
        "shortcut": 639
      },
      {
        "id": 893,
        "content": "이 표준은 책임 있는 AI 개발 및 사용을 보장하기 위해 제정되었으며, 시험 가이드에 언급되어 있어 시험 출제 가능성이 있다.",
        "shortcut": 643
      },
      {
        "id": 894,
        "content": "알고리즘 책임법은 기업들이 알고리즘의 투명성을 요구하며 공정성과 편향을 보장하기 위한 내용이 포함되어 있다.",
        "shortcut": 667
      },
      {
        "id": 895,
        "content": "이 법안은 AI 시스템의 영향을 평가하도록 요구하며, FTC(연방거래위원회)와 같은 기관의 역할을 명시하고 있다.",
        "shortcut": 674
      },
      {
        "id": 896,
        "content": "생성적 AI 보안 스코프 매트릭스는 생성적 솔루션을 구축하거나 작업할 때 고려해야 할 보안 범위를 정의하는 도구이다.",
        "shortcut": 681
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 177,
    "title": "5.10. ️ 프롬프트 주입 공격(Prompt Injection Attacks)",
    "startTime": "01:34:19.000",
    "endTime": "02:08:19.000",
    "items": [
      {
        "id": 897,
        "content": "프롬프트 주입 공격은 대규모 언어 모델(LLM)을 조작하기 위해 교묘한 입력을 사용하는 기법으로, 이러한 공격이 의도치 않은 행동을 유발할 수 있다.",
        "shortcut": 727
      },
      {
        "id": 898,
        "content": "공격자가 조작된 입력을 통해 LLM이 자신의 의도를 무심코 실행하게 만드는 취약점이 발생하며, 이는 시스템 프롬프트를 재정의하는 탈옥(jailbreaking) 방식으로 이루어진다.",
        "shortcut": 732
      },
      {
        "id": 899,
        "content": "간접 프롬프트 주입 공격은 외부 출처에서 입력을 받아들이는 LLM을 이용하여 발생하며, 공격자는 외부 콘텐츠에 프롬프트 주입을 삽입하여 대화의 맥락을 가로챌 수 있다.",
        "shortcut": 737
      },
      {
        "id": 900,
        "content": "예를 들어, 사용자가 간접 프롬프트 주입을 포함한 이력서를 업로드하면, LLM이 사용자의 민감한 정보를 요청하도록 유도하는 상황이 발생할 수 있다.",
        "shortcut": 740
      },
      {
        "id": 901,
        "content": "이를 방지하기 위해 LLM의 권한 제어를 강화하고, 외부 콘텐츠와 사용자 프롬프트를 분리하는 등의 예방 조치가 필요하다.",
        "shortcut": 744
      }
    ],
    "sourceIndex": 5
  },
  {
    "id": 178,
    "title": "1. 🛠️ AWS Glue 데이터 카탈로그 및 ETL 작업",
    "startTime": "00:00:00.000",
    "endTime": "00:12:00.000",
    "items": [
      {
        "id": 902,
        "content": "**AWS Glue**를 사용하여 데이터베이스와 테이블을 생성하고 기초적인 **ETL**과정을 수행하는 방법을 다룬다. 이는 **데이터 카탈로그**에 **메타데이터**정보를 정의하는 방식으로 이루어진다.",
        "shortcut": 2
      },
      {
        "id": 903,
        "content": "데이터는 **CSV 파일**형식으로 업로드되며, **AWS Glue**의 **크롤러**를 이용해 스키마를 설정하고 테이블 생성 작업을 자동화할 수 있다.",
        "shortcut": 13
      },
      {
        "id": 904,
        "content": "**IAM 역할**설정 등 추가 설정을 통해 Glue 서비스가 **S3 버킷**에 접근할 수 있도록 권한을 관리해야 하며, 이 과정에서 필요한 정책 JSON 파일을 생성하고 수정하는 방법도 설명된다.",
        "shortcut": 112
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 179,
    "title": "1.1. ️ AWS Glue ETL 프로세스 개요",
    "startTime": "00:00:00.000",
    "endTime": "00:01:00.000",
    "items": [
      {
        "id": 905,
        "content": "**AWS Glue**를 사용하여 **데이터 카탈로그**에 테이블을 생성하고 기본적인 **ETL**또는 ELT 프로세스를 실행할 계획이다.",
        "shortcut": 2
      },
      {
        "id": 906,
        "content": "이미 \"Glue\"라는 이름의 폴더가 있으며, AWS 예제 저장소를 사용하여 작업을 시작한다.",
        "shortcut": 5
      },
      {
        "id": 907,
        "content": "데이터를 저장할 N 폴더를 만들고, 데이터를 업로드한 후 Glue 데이터베이스를 생성할 예정이다.",
        "shortcut": 7
      },
      {
        "id": 908,
        "content": "이후 **크롤러**를 생성하여 자동으로 테이블을 생성하는 작업을 진행한다.",
        "shortcut": 8
      },
      {
        "id": 909,
        "content": "테이블을 먼저 생성하는 것이 필수적이므로, 이를 위해 필요한 스크립트를 복사하고 붙여넣을 준비를 한다.",
        "shortcut": 10
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 180,
    "title": "1.2. ️ 데이터 다운로드 및 업로드 과정",
    "startTime": "00:01:01.000",
    "endTime": "00:05:01.000",
    "items": [
      {
        "id": 910,
        "content": "전기차 인구 데이터는 catalog.data.gov에서 **CSV 파일**로 다운로드 받을 수 있다.",
        "shortcut": 13
      },
      {
        "id": 911,
        "content": "다운로드를 진행하기 위해서는 데이터 폴더를 만들고, 성공적으로 파일을 이동시켜야 한다.",
        "shortcut": 17
      },
      {
        "id": 912,
        "content": "업로드 시 비슷한 이름의 버킷 문제로 파일이 존재하지 않는다는 오류가 발생할 수 있으므로, 적절한 경로에서 작업해야 한다.",
        "shortcut": 37
      },
      {
        "id": 913,
        "content": "**CSV 파일**의 크기는 약 22메가바이트로, **메타데이터**정의를 위한 **데이터 카탈로그**설정이 필요하다.",
        "shortcut": 33
      },
      {
        "id": 914,
        "content": "Glue UI를 통해 데이터 테이블을 생성하려면 스키마 정의와 데이터 형식을 설정해야 하며, **크롤러**를 사용해 자동으로 추가하는 방식을 권장한다.",
        "shortcut": 50
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 181,
    "title": "1.3. Glue 데이터베이스 및 크롤러 생성 과정",
    "startTime": "00:05:52.000",
    "endTime": "00:08:52.000",
    "items": [
      {
        "id": 915,
        "content": "데이터베이스를 my database로 설정하여 생성하는 과정이 진행된다.",
        "shortcut": 67
      },
      {
        "id": 916,
        "content": "**크롤러**생성 시, 이름과 규칙, 데이터베이스(내 데이터베이스), S3 디렉토리의 경로를 설정해야 한다.",
        "shortcut": 75
      },
      {
        "id": 917,
        "content": "테이블 접두사 관련 정보가 명확하지 않아 ChatGPT에 도움을 요청하였고, 이를 기본값으로 설정하기로 했다.",
        "shortcut": 80
      },
      {
        "id": 918,
        "content": "**크롤러**는 온디맨드 작업으로 설정되어 있으며, 특정 스케줄 없이 실행될 예정이다.",
        "shortcut": 83
      },
      {
        "id": 919,
        "content": "이후에 데이터 소스 구성에서 S3를 선택하고, 생성된 테이블을 확인 후 추가하는 과정이 필요하다.",
        "shortcut": 94
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 182,
    "title": "1.4. IAM 역할 생성 및 설정",
    "startTime": "00:09:12.000",
    "endTime": "00:12:12.000",
    "items": [
      {
        "id": 920,
        "content": "**IAM 역할**을 생성해야 하며, 이는 Glue 콘솔에서만 업데이트할 수 있는 역할을 의미한다. 따라서 여기서 생성할 필요는 없으나, 가능하긴 하다.",
        "shortcut": 100
      },
      {
        "id": 921,
        "content": "대상 데이터베이스와 테이블 설정을 하며, 테이블 접두어를 제공할 필요는 없다.",
        "shortcut": 104
      },
      {
        "id": 922,
        "content": "신뢰 정책을 생성하기 위해 관련 코드를 복사하고 JSON 폴더에 붙여넣을 예정이다.",
        "shortcut": 116
      },
      {
        "id": 923,
        "content": "기존의 불필요한 정책을 삭제하고, 원하는 Adaba 서비스 역할을 활용하려 한다.",
        "shortcut": 121
      },
      {
        "id": 924,
        "content": "**S3 버킷** 전체에 대한 접근 권한을 허용하여 데이터를 동일한 버킷으로 출력할 수 있도록 설정할 예정이다.",
        "shortcut": 130
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 183,
    "title": "1.5. ️ IAM 역할 생성 절차",
    "startTime": "00:12:19.000",
    "endTime": "00:12:19.000",
    "items": [
      {
        "id": 925,
        "content": "**IAM 역할**을 추가해야 하며, create IAM role이라는 명령을 수행해야 한다.",
        "shortcut": 131
      },
      {
        "id": 926,
        "content": "이 **IAM 역할**은 IAM 섹션 내의 정책 아래에서 생성된 것으로 추정된다.",
        "shortcut": 132
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 184,
    "title": "2. 🛠️ ETL 작업 및 데이터 처리 과정",
    "startTime": "00:12:35.000",
    "endTime": "00:22:35.000",
    "items": [
      {
        "id": 927,
        "content": "코드 생성 및 정책 버전 생성에 대한 시간을 절약하기 위해 ChatGPT를 활용하여 필요한 코드를 빠르게 생성하는 전략이다.",
        "shortcut": 1
      },
      {
        "id": 928,
        "content": "S3 IAM 정책을 설정하고 관리 정책을 연결하여 서비스 역할이 제대로 구성되었는지를 확인하는 과정이다.",
        "shortcut": 12
      },
      {
        "id": 929,
        "content": "**크롤러**를 생성하고 실행하여 데이터 소스를 파악하고 데이터베이스에 테이블을 추가하는 작업이 성공적으로 수행되었다.",
        "shortcut": 26
      },
      {
        "id": 930,
        "content": "Glue **데이터 카탈로그**를 통해 **ETL**작업을 설정할 수 있으며, 시각적 **ETL**도구를 사용하면 작업이 간편해진다.",
        "shortcut": 69
      },
      {
        "id": 931,
        "content": "필터링 및 필드 삭제 등의 변환 작업을 통해 사용자가 필요로 하는 데이터만을 정제하여 UID를 추가하는 최종 단계로 진행된다.",
        "shortcut": 101
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 185,
    "title": "2.1. ️ 코드 생성 및 정책 설정 단계",
    "startTime": "00:12:35.000",
    "endTime": "00:13:35.000",
    "items": [
      {
        "id": 932,
        "content": "코드를 미리 가져오는 것은 시간 절약에 큰 도움이 된다.",
        "shortcut": 1
      },
      {
        "id": 933,
        "content": "ChatGPT를 사용하여 필요한 세 가지 컴포넌트를 생성했다고 언급한다.",
        "shortcut": 5
      },
      {
        "id": 934,
        "content": "필요한 코드가 있으면 복사 및 붙여넣기를 통해 많은 클릭 작업을 줄일 수 있다.",
        "shortcut": 7
      },
      {
        "id": 935,
        "content": "신뢰 정책을 사용하여 규칙을 먼저 생성하고, 그 다음으로 S3 IAM 정책을 설정한다고 계획한다.",
        "shortcut": 10
      },
      {
        "id": 936,
        "content": "설정된 서비스 역할이 정상적으로 작동하는지 여부를 확인하고, **AWS Glue**폴더에 대한 액세스를 제공한다고 언급한다.",
        "shortcut": 22
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 186,
    "title": "2.2. 크롤러 생성 과정",
    "startTime": "00:14:27.000",
    "endTime": "00:16:27.000",
    "items": [
      {
        "id": 937,
        "content": "실제 **크롤러**를 생성하는 것이 다음 단계이며, 간단하게 작동하기를 기대하고 있다.",
        "shortcut": 26
      },
      {
        "id": 938,
        "content": "예상보다 쉽게 작동하였으며, 만들어진 **크롤러**들을 살펴보고 있다.",
        "shortcut": 28
      },
      {
        "id": 939,
        "content": "기존의 오래된 **크롤러**를 삭제하고, 현재의 온디맨드 **크롤러**를 '기본 **크롤러**'로 이름을 변경하였다.",
        "shortcut": 32
      },
      {
        "id": 940,
        "content": "**크롤러**를 실행하기 위한 클릭 작업을 진행하며, 작동이 시작되었음을 확인하였다.",
        "shortcut": 37
      },
      {
        "id": 941,
        "content": "이 과정에는 **DPU**(데이터 처리 단위)이 사용되며, 비용이 발생할 수 있지만 구체적인 사양은 모르고 있다.",
        "shortcut": 45
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 187,
    "title": "2.3. 데이터 크롤러 결과 확인",
    "startTime": "00:16:28.000",
    "endTime": "00:17:28.000",
    "items": [
      {
        "id": 942,
        "content": "**크롤러**가 완료되었고, CloudWatch 로그에서는 생각보다 특별한 내용이 없음을 확인했다.",
        "shortcut": 52
      },
      {
        "id": 943,
        "content": "데이터 소스가 생성되었으나, 분류기가 없으므로 흥미로운 정보는 없었다.",
        "shortcut": 57
      },
      {
        "id": 944,
        "content": "데이터베이스에 접근하였고, 새로운 테이블이 생성되었음을 확인하였다.",
        "shortcut": 59
      },
      {
        "id": 945,
        "content": "테이블 이름이 \"Data\"인 점은 적절치 않지만, 그것이 현재 이름이다.",
        "shortcut": 60
      },
      {
        "id": 946,
        "content": "스키마에서 필드와 타입이 올바르게 변환됐음을 확인하였고, 예를 들어 문자열과 빅인트 타입이 포함되었다.",
        "shortcut": 61
      },
      {
        "id": 947,
        "content": "파티션 및 파티션 인덱스는 현재 사용되고 있지 않으나, 만약 사용된다면 확인할 수 있는 지점이다.",
        "shortcut": 63
      },
      {
        "id": 948,
        "content": "데이터 품질이 새로운 항목으로 등장했으며, 대량의 데이터 작업 시 가치가 있을 것으로 추정된다.",
        "shortcut": 66
      },
      {
        "id": 949,
        "content": "생성된 **데이터 카탈로그**는 **ETL**작업 및 여러 서비스에서 다양하게 활용될 수 있다.",
        "shortcut": 67
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 188,
    "title": "2.4. ️ ETL 작업 설정 과정",
    "startTime": "00:17:55.000",
    "endTime": "00:21:55.000",
    "items": [
      {
        "id": 950,
        "content": "**ETL**작업을 설정하는데 비주얼 **ETL** 도구가 유용하게 사용될 수 있다. 이를 통해 기본적인 작업을 간편하게 수행할 수 있다.",
        "shortcut": 69
      },
      {
        "id": 951,
        "content": "Glue Data Catalog를 선택하여 새로운 비주얼 **ETL**을 시작하였으나, CSV 형식으로 저장된 Amazon **S3 버킷**을 소스로 사용할 수도 있었던 점이 언급되었다.",
        "shortcut": 71
      },
      {
        "id": 952,
        "content": "데이터 필터링을 위해 조건을 추가하는 방법을 모색하였고, 이를 통해 특정 도시의 데이터를 필터링하려 하고 있다.",
        "shortcut": 76
      },
      {
        "id": 953,
        "content": "**S3 버킷**에 접근할 수 있는 서비스 역할을 선택하고, **ETL**작업이 진행 중임을 확인하였다. 이를 통해 데이터 프리뷰를 확인하는 과정이 중요하다는 점이 강조되었다.",
        "shortcut": 98
      },
      {
        "id": 954,
        "content": "데이터에서 불필요한 필드를 제거하고 UID를 추가하여 유사한 필드를 구별할 수 있도록 하고 있다.",
        "shortcut": 112
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 189,
    "title": "2.5. ETL 작업 설정 상세 설명",
    "startTime": "00:22:26.000",
    "endTime": "00:22:26.000",
    "items": [
      {
        "id": 955,
        "content": "**ETL**작업의 이름을 지정할 수 있으며, 예를 들어 '내 **ETL**작업'으로 설정할 수 있다.",
        "shortcut": 126
      },
      {
        "id": 956,
        "content": "사용 가능한 프로그래밍 언어로 **Python** 또는 **Scala**를 선택할 수 있으며, 사용하는 Glue 버전을 지정할 수 있다.",
        "shortcut": 128
      },
      {
        "id": 957,
        "content": "현재 사용 중인 Glue 버전은 4이며, 작업에 이용하는 작업자 유형도 설정할 수 있다.",
        "shortcut": 129
      },
      {
        "id": 958,
        "content": "작업자 유형으로 선택한 G1X는 적합한 옵션이며, 설정이 간단하다고 설명된다.",
        "shortcut": 130
      },
      {
        "id": 959,
        "content": "작업을 저장한 후에는 실행하여 실행 세부사항을 확인할 수 있다.",
        "shortcut": 131
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 190,
    "title": "3. 🔄 ETL 작업 모니터링 및 데이터 출력 설정",
    "startTime": "00:22:55.000",
    "endTime": "00:33:55.000",
    "items": [
      {
        "id": 960,
        "content": "**ETL**작업을 모니터링 중이며, 이전에 작업에서 권한 설정을 잊어버려 실패한 경험이 있다.",
        "shortcut": 2
      },
      {
        "id": 961,
        "content": "출력 폴더를 명시하지 않아 데이터 출력 위치를 확인하려고 시도하지만, 설정이 누락되어 데이터를 어디로 출력할지 정하지 않은 것으로 보인다.",
        "shortcut": 6
      },
      {
        "id": 962,
        "content": "데이터 형식을 JSON으로 설정하고 Glue 테이블을 선택한 후, **데이터 카탈로그**를 업데이트하지 않도록 설정하여 단순히 데이터를 전송할 예정이다.",
        "shortcut": 36
      },
      {
        "id": 963,
        "content": "**ETL**작업이 성공적으로 완료되었고, 실행 세부정보와 메트릭스를 확인하여 작업의 상태를 모니터링할 수 있다.",
        "shortcut": 45
      },
      {
        "id": 964,
        "content": "데이터 출력 결과를 확인하는 과정에서 출력된 파일이 압축된 형식으로 되어있어 직접 확인할 수 없었고, 다시 실행하여 압축 설정을 해제한 후 데이터를 확인하려는 시도가 이루어졌다.",
        "shortcut": 61
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 191,
    "title": "3.1. ️ 작업 실행 모니터링 및 출력 확인",
    "startTime": "00:22:55.000",
    "endTime": "00:24:55.000",
    "items": [
      {
        "id": 965,
        "content": "작업 실행 모니터링이 진행 중이며, 출력할 폴더가 지정되지 않아 출력 위치가 불확실하다.",
        "shortcut": 1
      },
      {
        "id": 966,
        "content": "이전 실행에서 권한을 제공하지 않아 작업이 실패한 경험이 있으며, Glue 테이블과 동일한 역할을 사용하려고 했다.",
        "shortcut": 2
      },
      {
        "id": 967,
        "content": "작업이 성공적으로 실행되었고, 10개의 **DPU**가 사용되었음을 확인하였다.",
        "shortcut": 13
      },
      {
        "id": 968,
        "content": "**S3 버킷**에서 출력된 데이터의 위치를 확인하고자 했으나, 기존 데이터를 대체했는지에 대한 불확실성이 있다.",
        "shortcut": 20
      },
      {
        "id": 969,
        "content": "출력 설정을 선택하지 않아 데이터가 올바르게 저장되지 않았음을 깨달았다.",
        "shortcut": 30
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 192,
    "title": "3.2. ETL 작업 및 데이터 처리 과정",
    "startTime": "00:25:44.000",
    "endTime": "00:30:44.000",
    "items": [
      {
        "id": 970,
        "content": "JSON 포맷을 선택하여 데이터 전송을 위한 SL 출력을 설정하고, **데이터 카탈로그**를 업데이트하지 않기로 결정했다.",
        "shortcut": 36
      },
      {
        "id": 971,
        "content": "**ETL**작업이 성공적으로 완료되었고, 이를 통해 작업의 결과를 확인할 수 있다.",
        "shortcut": 45
      },
      {
        "id": 972,
        "content": "Spark UI를 통해 **ETL**작업의 세부 사항, 단계 및 저장소와 관련된 정보를 살펴볼 수 있다.",
        "shortcut": 49
      },
      {
        "id": 973,
        "content": "파일이 압축되었기 때문에 열 수 없었고, 이후 압축 없이 저장하여 재 실행함으로써 데이터를 시각적으로 확인할 수 있었다.",
        "shortcut": 59
      },
      {
        "id": 974,
        "content": "데이터에 불필요한 필드가 포함된 이유를 조사한 결과, 필드를 선택하지 않아 나타난 것임을 알게 되었고, Abos Glue를 사용할 수 있는 방법에 대해 설명되었다.",
        "shortcut": 78
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 193,
    "title": "3.3. Amazon OpenSearch 및 Elasticsearch 개요",
    "startTime": "00:31:38.000",
    "endTime": "00:33:38.000",
    "items": [
      {
        "id": 975,
        "content": "Amazon OpenSearch는 사용자가 쉽게 배포하고 운영할 수 있는 전체 텍스트 검색 서비스를 제공한다.",
        "shortcut": 108
      },
      {
        "id": 976,
        "content": "OpenSearch는 기존의 Elasticsearch와 호환 가능하며, 사용자의 필요에 따라 선택할 수 있다.",
        "shortcut": 110
      },
      {
        "id": 977,
        "content": "2021년, Elastic이라는 회사의 라이선싱 계약 변경으로 인해, 8명이 Elasticsearch와 Kibana의 오픈 소스 프로젝트를 포크하여 OpenSearch를 시작하게 되었다.",
        "shortcut": 113
      },
      {
        "id": 978,
        "content": "Elastic search는 Lucene 라이브러리를 기반으로 하여 검색과 분석의 기능을 향상시킨 검색 엔진이다.",
        "shortcut": 117
      },
      {
        "id": 979,
        "content": "ELK 스택은 Elastic에서 만든 세 가지 소프트웨어(Elasticsearch, Logstash, Kibana)로, 애플리케이션의 분석 및 모니터링을 위해 일반적으로 함께 사용된다.",
        "shortcut": 120
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 194,
    "title": "3.4. Amazon OpenSearch 탐색하기",
    "startTime": "00:33:48.000",
    "endTime": "00:33:48.000",
    "items": [
      {
        "id": 980,
        "content": "앤드류 브라운은 Amazon OpenSearch에 대해 소개하고 있다.",
        "shortcut": 126
      },
      {
        "id": 981,
        "content": "그는 기존의 검색 엔진(Solar, Spanx, Elastic Search)을 수동으로 설정한 경험이 많다고 설명한다.",
        "shortcut": 127
      },
      {
        "id": 982,
        "content": "Elastic Search 기반으로 애플리케이션에서 전체 텍스트 검색을 구현하기 용이할 것으로 보인다.",
        "shortcut": 128
      },
      {
        "id": 983,
        "content": "이 탐색은 초보적인 접근으로 간주되며, 어렵지 않을 것이라고 예상하고 있다.",
        "shortcut": 129
      },
      {
        "id": 984,
        "content": "다양한 옵션으로는 도메인 생성, 예약 인스턴스 리스, 패키지, 그리고 플러그인 추가가 포함된다고 언급한다.",
        "shortcut": 130
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 195,
    "title": "4. 💻 OpenSearch 도메인 설정 과정",
    "startTime": "00:34:35.000",
    "endTime": "00:44:35.000",
    "items": [
      {
        "id": 985,
        "content": "서비스의 비용을 확인하고, 무료 기준으로 750시간을 활용할 수 있는 계획이 있다는 점을 언급한다.",
        "shortcut": 1
      },
      {
        "id": 986,
        "content": "여러 설정 옵션 중에서, 개발 테스트(Dav test) 도메인 생성을 선택하며, 안정성 목표에 따라 노드 배포 옵션을 설정한다.",
        "shortcut": 7
      },
      {
        "id": 987,
        "content": "사용 가능한 검색 엔진으로는 OpenSearch와 Elasticsearch가 있으며, 익숙한 Elasticsearch 대신 OpenSearch를 선택하기로 한다.",
        "shortcut": 10
      },
      {
        "id": 988,
        "content": "저렴한 인스턴스를 선택하기 위해 여러 가지 인스턴스 옵션을 검토한 후, T3 소형 검색 인스턴스를 선택한다.",
        "shortcut": 19
      },
      {
        "id": 989,
        "content": "공용 접근을 사용하기로 하여 구성의 복잡성을 줄이고, 클러스터와의 상호 작용을 위한 SDK 또는 API 호출 방식을 고려한다.",
        "shortcut": 35
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 196,
    "title": "4.1. 서비스 비용 및 도메인 생성 과정",
    "startTime": "00:34:35.000",
    "endTime": "00:34:35.000",
    "items": [
      {
        "id": 990,
        "content": "서비스의 비용이 얼마인지 궁금하여 확인하려는 행동이 있다.",
        "shortcut": 1
      },
      {
        "id": 991,
        "content": "서비스에 불편함이 있다면 시작하지 말아야 한다고 언급된다.",
        "shortcut": 2
      },
      {
        "id": 992,
        "content": "750시간의 무료 사용 옵션이 있으며, 작은 컴퓨팅으로 실행할 수 있다고 언급된다.",
        "shortcut": 3
      },
      {
        "id": 993,
        "content": "컴퓨팅을 프로비저닝한 후, 도메인 생성을 진행할 계획이 있다.",
        "shortcut": 4
      },
      {
        "id": 994,
        "content": "도메인 생성 시 표준 생성 옵션을 선택하여 다양한 선택지를 확인하고자 한다.",
        "shortcut": 5
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 197,
    "title": "4.2. ️ OpenSearch와 Elasticsearch 선택 과정",
    "startTime": "00:35:24.000",
    "endTime": "00:35:24.000",
    "items": [
      {
        "id": 995,
        "content": "최신 엔진으로 OpenSearch와 Elasticsearch 중에서 선택할 수 있는 옵션이 있는 상황이다.",
        "shortcut": 10
      },
      {
        "id": 996,
        "content": "사용법의 구문이 두 시스템 간에 다를지에 대한 의문이 제기된다.",
        "shortcut": 11
      },
      {
        "id": 997,
        "content": "Elasticsearch에 더 익숙하지만 오늘은 OpenSearch를 사용할 것이라고 결정했다.",
        "shortcut": 12
      },
      {
        "id": 998,
        "content": "Elasticsearch OSS 클라이언트, 예를 들어 LogStash 등을 활성화할 수 있는 가능성이 있다.",
        "shortcut": 13
      },
      {
        "id": 999,
        "content": "사용자는 저렴한 가격을 선호하며, 비용을 최소화하고자 한다.",
        "shortcut": 15
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 198,
    "title": "4.3. ️ EBS 설정 및 선택 과정",
    "startTime": "00:36:10.000",
    "endTime": "00:38:10.000",
    "items": [
      {
        "id": 1000,
        "content": "테스트와 개발 목적으로 단일 노드와 EBS를 사용한다고 언급한다.",
        "shortcut": 21
      },
      {
        "id": 1001,
        "content": "gp3의 사용이 가능하며, 최소 10의 EBS가 필요하다고 판단하여 이를 설정한다.",
        "shortcut": 24
      },
      {
        "id": 1002,
        "content": "IOPS를 낮추고, 전용 마스터 노드와 스냅샷 구성을 사용하지 않겠다고 결정한다.",
        "shortcut": 30
      },
      {
        "id": 1003,
        "content": "VPC 접근이 권장되며, 공용 접근을 설정하여 사용의 편리함을 도모한다고 설명한다.",
        "shortcut": 34
      },
      {
        "id": 1004,
        "content": "유용하지만 신뢰도가 낮은 서버리스 옵션보다는 관리형 서비스를 선택할 계획이다.",
        "shortcut": 59
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 199,
    "title": "4.4. OpenSearch와 SDK 탐색",
    "startTime": "00:39:00.000",
    "endTime": "00:42:00.000",
    "items": [
      {
        "id": 1005,
        "content": "OpenSearch와 상호작용하기 위해 SDK를 사용하는 것이 제안된다.",
        "shortcut": 63
      },
      {
        "id": 1006,
        "content": "Java 예제가 제시되지만, Java를 사용하지 않고 Ruby의 ADS SDK를 검토할 예정이다.",
        "shortcut": 64
      },
      {
        "id": 1007,
        "content": "OpenSearch 서비스와 상호작용하기 위한 호출을 찾고 있지만, 데이터 질의와 관련된 호출은 발견되지 않았다.",
        "shortcut": 67
      },
      {
        "id": 1008,
        "content": "OpenSearch 도메인 생성, 업데이트, 삭제에 대한 예제가 있지만, 사용자는 단순히 상호작용을 원한다.",
        "shortcut": 71
      },
      {
        "id": 1009,
        "content": "OpenSearch 클러스터와 상호작용 가능성을 탐색하고 있으며, AWS의 서비스일 수도 있다는 점을 언급한다.",
        "shortcut": 78
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 200,
    "title": "4.5. OpenSearch 설정 및 연결 과정",
    "startTime": "00:42:50.000",
    "endTime": "00:43:50.000",
    "items": [
      {
        "id": 1010,
        "content": "OpenSearch를 요구해야 하며, 외부 엔드포인트 URL을 통해 연결할 수 있을 것으로 예상된다.",
        "shortcut": 108
      },
      {
        "id": 1011,
        "content": "클라이언트와의 연결을 설정해야 하며, 이를 위해 헬스 체크를 할 수 있는 방법이 있다.",
        "shortcut": 110
      },
      {
        "id": 1012,
        "content": "구성에 따라 로깅을 활성화하고, 필요 없는 설정은 제거하는 것이 좋다.",
        "shortcut": 113
      },
      {
        "id": 1013,
        "content": "Amazon Open Source 서비스에 연결하기 위해 특정 젬(gem)이 필요하며, 이를 설치해야 할 것이다.",
        "shortcut": 116
      },
      {
        "id": 1014,
        "content": "필수 액세스 키와 비밀 키는 로컬에서 자동으로 감지되므로, 해당 정보는 입력할 필요가 없다.",
        "shortcut": 128
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 201,
    "title": "5. 🛠️ OpenSearch와 AWS IAM 역할 설정",
    "startTime": "00:44:51.000",
    "endTime": "00:56:51.000",
    "items": [
      {
        "id": 1015,
        "content": "OpenSearch에 대한 인덱스 생성 및 문서 삽입이 진행 중이지만, 도메인 정보가 아직 생성되지 않아 기능 사용이 제한적이다.",
        "shortcut": 2
      },
      {
        "id": 1016,
        "content": "스크립트에서 결과를 명확히 이해하기 위해 binding pry를 사용하여 검색 결과를 확인하려고 하며, 이에 따라 수정이 필요하다.",
        "shortcut": 12
      },
      {
        "id": 1017,
        "content": "AWS IAM에서 특정 사용자 권한 설정을 위해 기존의 \"deny\" 정책을 수정하고, 새로운 권한을 추가하는 과정이 필요하다.",
        "shortcut": 52
      },
      {
        "id": 1018,
        "content": "특정 리소스에 대한 \"deny\"가 있는 경우, 권한 수정 후 즉각 반영되지 않아 업데이트를 기다려야 하며, 추가적인 테스트가 필요하다.",
        "shortcut": 66
      },
      {
        "id": 1019,
        "content": "문서 삽입과 인덱스 삭제 후 결과를 확인하였고, OpenSearch와의 연결이 성공적으로 이루어졌지만, 보다 세밀한 권한 설정이 요구됨을 느꼈다.",
        "shortcut": 86
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 202,
    "title": "5.1. 인덱스 생성 및 데이터 처리 절차",
    "startTime": "00:44:51.000",
    "endTime": "00:45:51.000",
    "items": [
      {
        "id": 1020,
        "content": "현재 엔드포인트가 아직 생성되지 않아 진행이 제한적이다.",
        "shortcut": 2
      },
      {
        "id": 1021,
        "content": "인덱스 이름은 Prime으로 설정하고, 레코드 삽입을 진행하는 것으로 보인다.",
        "shortcut": 6
      },
      {
        "id": 1022,
        "content": "간단한 스크립트 구조로, 문서 검색, 삭제, 인덱스 삭제와 같은 기능을 포함한다.",
        "shortcut": 10
      },
      {
        "id": 1023,
        "content": "Binding pry를 이용하여 스크립트 실행 결과를 확인할 계획이다, 이는 결과를 확인하기 위함이다.",
        "shortcut": 12
      },
      {
        "id": 1024,
        "content": "인덱스 생성 및 문서 삽입 과정을 거쳐 최종적으로 완료 상태에서 기다리고 있다.",
        "shortcut": 19
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 203,
    "title": "5.2. ️ 접근 방식 및 문제 해결 과정",
    "startTime": "00:46:49.000",
    "endTime": "00:48:49.000",
    "items": [
      {
        "id": 1025,
        "content": "사용자가 필요한 엔드포인트에 접근하기 위해 확인 중이며, 이를 공용으로 설정했다는 점이 언급된다.",
        "shortcut": 23
      },
      {
        "id": 1026,
        "content": "IPv4가 더 간단하게 보이므로 선택하였지만, 해당 대시보드에 접근하는 데 어려움이 있다고 언급된다.",
        "shortcut": 25
      },
      {
        "id": 1027,
        "content": "대시보드에 접근하기 위한 추가 인증 정보 제공이 필요하다고 확인되며, 사용자는 환경 변수로 접근키와 비밀 접근 키를 설정하려고 시도한다.",
        "shortcut": 38
      },
      {
        "id": 1028,
        "content": "코드를 실행하는 과정에서 문법 오류가 발생하였고, 이를 수정하려고 노력하지만 여전히 문제가 발생하고 있다.",
        "shortcut": 48
      },
      {
        "id": 1029,
        "content": "결국, 정책에 명시적 거부가 있어서 행동이 허가되지 않는다고 진단된다.",
        "shortcut": 51
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 204,
    "title": "5.3. 권한 설정 및 자원 관리 과정",
    "startTime": "00:49:31.000",
    "endTime": "00:54:31.000",
    "items": [
      {
        "id": 1030,
        "content": "명시적인 거부 정책이 존재하여 필요한 권한을 부여하기 위해 접근 정책을 수정해야 한다.",
        "shortcut": 52
      },
      {
        "id": 1031,
        "content": "정책 수정 시, 명시적으로 모든 사용자에 대한 거부를 포함한 구문이 있었고, 이 부분을 변경해야 할 필요가 있다.",
        "shortcut": 55
      },
      {
        "id": 1032,
        "content": "특정 사용자에게 접근 권한을 부여하기 위해 \"allow\" 구문을 추가하게 되며, 이를 통해 권한 설정을 조정한다.",
        "shortcut": 57
      },
      {
        "id": 1033,
        "content": "설정 변경 후 즉각적인 결과가 나타나지 않으므로 구성 업데이트를 기다려야 한다.",
        "shortcut": 66
      },
      {
        "id": 1034,
        "content": "IAM 정책에서 \"deny\"와 \"allow\" 구문의 순서를 고려해야 하며, 이를 통해 권한 설정 방식이 달라질 수 있다.",
        "shortcut": 70
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 205,
    "title": "5.4. 데이터 레이크의 정의와 기능",
    "startTime": "00:54:50.000",
    "endTime": "00:55:50.000",
    "items": [
      {
        "id": 1035,
        "content": "데이터 레이크는 구조화된 및 반구조화된 데이터를 위한 중앙 집중식 데이터 저장소이다.",
        "shortcut": 113
      },
      {
        "id": 1036,
        "content": "데이터 레이크는 방대한 양의 데이터를 저장하기 위해 설계되었다.",
        "shortcut": 114
      },
      {
        "id": 1037,
        "content": "데이터 레이크는 일반적으로 객체나 파일을 저장 매체로 사용한다.",
        "shortcut": 115
      },
      {
        "id": 1038,
        "content": "다양한 출처에서 데이터를 가져와서 반구조화된 데이터로 변환할 수 있도록 설계되어 있다.",
        "shortcut": 117
      },
      {
        "id": 1039,
        "content": "최종적으로, 데이터는 프로그램, API를 통해 제공되거나 메타 카탈로그에 게시될 수 있다.",
        "shortcut": 118
      }
    ],
    "sourceIndex": 6
  },
  {
    "id": 206,
    "title": "5.5. ️ AWS Lake Formation 개요",
    "startTime": "00:56:00.000",
    "endTime": "00:57:00.000",
    "items": [
      {
        "id": 1040,
        "content": "AWS Lake Formation은 데이터를 중앙에서 관리하고 보안을 유지하며 전 세계적으로 공유할 수 있는 데이터 레이크 기능이다.",
        "shortcut": 126
      },
      {
        "id": 1041,
        "content": "사용자는 **Amazon S3**에서 데이터 레이크에 대한 세부적인 접근 제어를 관리하고, DataBrew Glue Data Catalog에서 **메타데이터**를 관리할 수 있다.",
        "shortcut": 127
      },
      {
        "id": 1042,
        "content": "Lake Formation은 IAM 권한 모델을 보강하는 자체 권한 모델을 제공하며, 이는 관계형 데이터베이스 관리 시스템과 유사한 방식으로 작동한다.",
        "shortcut": 128
      },
      {
        "id": 1043,
        "content": "데이터는 여러 계정을 통해 **IAM 역할**이나 다른 계정의 IAM 원칙으로 공유할 수 있다.",
        "shortcut": 129
      },
      {
        "id": 1044,
        "content": "Lake Formation은 Athena, QuickSight, Redshift Spectrum, EMR, Glue와 통합되어 사용된다.",
        "shortcut": 131
      }
    ],
    "sourceIndex": 6
  }
]